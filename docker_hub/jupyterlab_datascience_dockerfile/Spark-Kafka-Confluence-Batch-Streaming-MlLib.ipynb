{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8dc8402-9c6d-40cb-8650-72bc1cc599ec",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d6250-476c-4b3f-982f-e94a60ab5309",
   "metadata": {},
   "source": [
    "# START ZOOKEPER SERVICE\n",
    "### RUN THIS COMMAND IN A TERMINAL\n",
    "```\n",
    "/usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties\n",
    "\n",
    "```\n",
    "# START KAFKA BROKERS\n",
    "### RUN THIS COMMAND ON A DIFFERENT TERMINAL FOR EACH LINE\n",
    "```\n",
    "/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server1.properties\n",
    "/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server2.properties\n",
    "/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server3.properties\n",
    "/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server4.properties\n",
    "```\n",
    "# LIST AVALABLE BROKERS\n",
    "```\n",
    "/usr/local/kafka/bin/zookeeper-shell.sh localhost:2181 ls /brokers/ids\n",
    "```\n",
    "\n",
    "# CREATE GROUPS AND TOPICS AVALABLE GROUPS\n",
    "```\n",
    "/usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --group jorge-cardona-kafka-batch --topic animals-topic-batch\n",
    "/usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --group jorge-cardona-kafka-streaming --topic animals-topic-streaming\n",
    "```\n",
    "\n",
    "# LIST AVALABLE GROUPS\n",
    "```\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list\n",
    "```\n",
    "\n",
    "# LISTS TOPICS\n",
    "```\n",
    "/usr/local/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092\n",
    "```\n",
    "\n",
    "# LISTS CONSUMERS ASOCIATE TO GROUPS\n",
    "```\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group jorge-cardona-kafka-batch\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group jorge-cardona-kafka-streaming\n",
    "```\n",
    "\n",
    "# DELETE CONSUMER GROUP\n",
    "```\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group jorge-cardona-kafka-batch\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group jorge-cardona-kafka-streaming\n",
    "```\n",
    "\n",
    "# DELETE TOPICS\n",
    "```\n",
    "# all topics at same time\n",
    "/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic animals-topic-batch,animals-topic-streaming\n",
    "\n",
    "# or one by one topic\n",
    "/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic animals-topic-batch\n",
    "/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic animals-topic-streaming\n",
    "```\n",
    "\n",
    "# DELETE TOPICS\n",
    "```\n",
    "# all groups at same time\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group jorge-cardona-kafka-batch,jorge-cardona-kafka-streaming\n",
    "\n",
    "\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group jorge-cardona-kafka-batch\n",
    "/usr/local/kafka/bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --delete --group jorge-cardona-kafka-streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c1d103-cffb-4485-b0f8-63941bd64e97",
   "metadata": {},
   "source": [
    "# <center> PYTHON LIBRARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea906c-f40a-4513-97e2-e674ca6381c0",
   "metadata": {},
   "source": [
    "# EXECUTE COMMANDS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bbae095-c157-49ca-b60c-0a452319a60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "\n",
    "def execute_commands(commands):\n",
    "    for command in commands:\n",
    "        print(f\"Executing: {command}\")\n",
    "        try:\n",
    "            subprocess.Popen(command, shell=True)\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing command: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8a1ee5-b8c6-4e52-b4e6-120d6f191164",
   "metadata": {},
   "source": [
    "# START ZOOKEEPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b170d7-92cf-425b-9508-d9055cb96328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: /usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties\n",
      "\n",
      "[2024-11-17 05:44:20,937] INFO Reading configuration from: /usr/local/kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2024-11-17 05:44:20,940] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2024-11-17 05:44:20,940] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2024-11-17 05:44:20,940] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2024-11-17 05:44:20,940] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2024-11-17 05:44:20,942] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)\n",
      "[2024-11-17 05:44:20,942] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)\n",
      "[2024-11-17 05:44:20,942] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)\n",
      "[2024-11-17 05:44:20,942] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)\n",
      "[2024-11-17 05:44:20,943] INFO Log4j 1.2 jmx support not found; jmx disabled. (org.apache.zookeeper.jmx.ManagedUtil)\n",
      "[2024-11-17 05:44:20,944] INFO Reading configuration from: /usr/local/kafka/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2024-11-17 05:44:20,944] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2024-11-17 05:44:20,944] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2024-11-17 05:44:20,945] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2024-11-17 05:44:20,945] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)\n",
      "[2024-11-17 05:44:20,945] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)\n",
      "[2024-11-17 05:44:20,958] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@79ad8b2f (org.apache.zookeeper.server.ServerMetrics)\n",
      "[2024-11-17 05:44:20,962] INFO ACL digest algorithm is: SHA1 (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)\n",
      "[2024-11-17 05:44:20,962] INFO zookeeper.DigestAuthenticationProvider.enabled = true (org.apache.zookeeper.server.auth.DigestAuthenticationProvider)\n",
      "[2024-11-17 05:44:20,965] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)\n",
      "[2024-11-17 05:44:20,971] INFO  (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,971] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,972] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,972] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,972] INFO    / /    / _ \\   / _ \\  | |/ /  / _ \\  / _ \\ | '_ \\   / _ \\ | '__| (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,972] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,972] INFO  /_____|  \\___/   \\___/  |_|\\_\\  \\___|  \\___| | .__/   \\___| |_| (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,972] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,972] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,972] INFO  (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,973] INFO Server environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,973] INFO Server environment:host.name=63399d325201 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,974] INFO Server environment:java.version=21.0.5 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,974] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,974] INFO Server environment:java.home=/usr/lib/jvm/jdk-21.0.5-oracle-x64 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,974] INFO Server environment:java.class.path=/usr/local/kafka/bin/../libs/activation-1.1.1.jar:/usr/local/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/usr/local/kafka/bin/../libs/argparse4j-0.7.0.jar:/usr/local/kafka/bin/../libs/audience-annotations-0.12.0.jar:/usr/local/kafka/bin/../libs/caffeine-2.9.3.jar:/usr/local/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/usr/local/kafka/bin/../libs/commons-cli-1.4.jar:/usr/local/kafka/bin/../libs/commons-collections-3.2.2.jar:/usr/local/kafka/bin/../libs/commons-digester-2.1.jar:/usr/local/kafka/bin/../libs/commons-io-2.14.0.jar:/usr/local/kafka/bin/../libs/commons-lang3-3.12.0.jar:/usr/local/kafka/bin/../libs/commons-logging-1.2.jar:/usr/local/kafka/bin/../libs/commons-validator-1.7.jar:/usr/local/kafka/bin/../libs/connect-api-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-json-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-mirror-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-mirror-client-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-runtime-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-transforms-3.9.0.jar:/usr/local/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/usr/local/kafka/bin/../libs/hk2-api-2.6.1.jar:/usr/local/kafka/bin/../libs/hk2-locator-2.6.1.jar:/usr/local/kafka/bin/../libs/hk2-utils-2.6.1.jar:/usr/local/kafka/bin/../libs/jackson-annotations-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-core-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-databind-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-module-afterburner-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-module-scala_2.12-2.16.2.jar:/usr/local/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/usr/local/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/usr/local/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/usr/local/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/usr/local/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/usr/local/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/usr/local/kafka/bin/../libs/javassist-3.29.2-GA.jar:/usr/local/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/usr/local/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/usr/local/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/usr/local/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/usr/local/kafka/bin/../libs/jaxb-api-2.3.1.jar:/usr/local/kafka/bin/../libs/jersey-client-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-common-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-server-2.39.1.jar:/usr/local/kafka/bin/../libs/jetty-client-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-http-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-io-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-security-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-server-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-util-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jline-3.25.1.jar:/usr/local/kafka/bin/../libs/jopt-simple-5.0.4.jar:/usr/local/kafka/bin/../libs/jose4j-0.9.4.jar:/usr/local/kafka/bin/../libs/jsr305-3.0.2.jar:/usr/local/kafka/bin/../libs/kafka-clients-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-group-coordinator-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-metadata-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-raft-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-server-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-server-common-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-shell-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-storage-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-storage-api-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-examples-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-scala_2.12-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-tools-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-tools-api-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka_2.12-3.9.0.jar:/usr/local/kafka/bin/../libs/lz4-java-1.8.0.jar:/usr/local/kafka/bin/../libs/maven-artifact-3.9.6.jar:/usr/local/kafka/bin/../libs/metrics-core-2.2.0.jar:/usr/local/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/usr/local/kafka/bin/../libs/netty-buffer-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-codec-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-common-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-handler-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-resolver-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/usr/local/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/usr/local/kafka/bin/../libs/paranamer-2.8.jar:/usr/local/kafka/bin/../libs/pcollections-4.0.1.jar:/usr/local/kafka/bin/../libs/plexus-utils-3.5.1.jar:/usr/local/kafka/bin/../libs/protobuf-java-3.25.5.jar:/usr/local/kafka/bin/../libs/reflections-0.10.2.jar:/usr/local/kafka/bin/../libs/reload4j-1.2.25.jar:/usr/local/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/usr/local/kafka/bin/../libs/scala-collection-compat_2.12-2.10.0.jar:/usr/local/kafka/bin/../libs/scala-java8-compat_2.12-1.0.2.jar:/usr/local/kafka/bin/../libs/scala-library-2.12.19.jar:/usr/local/kafka/bin/../libs/scala-logging_2.12-3.9.5.jar:/usr/local/kafka/bin/../libs/scala-reflect-2.12.19.jar:/usr/local/kafka/bin/../libs/slf4j-api-1.7.36.jar:/usr/local/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/usr/local/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/usr/local/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/usr/local/kafka/bin/../libs/trogdor-3.9.0.jar:/usr/local/kafka/bin/../libs/zookeeper-3.8.4.jar:/usr/local/kafka/bin/../libs/zookeeper-jute-3.8.4.jar:/usr/local/kafka/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,974] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,975] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,975] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,975] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,975] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,975] INFO Server environment:os.version=5.10.16.3-microsoft-standard-WSL2 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,975] INFO Server environment:user.name=root (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,975] INFO Server environment:user.home=/root (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,976] INFO Server environment:user.dir=/notebooks (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,976] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,976] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,976] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,976] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,976] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,977] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,977] INFO zookeeper.flushDelay = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,977] INFO zookeeper.maxWriteQueuePollTime = 0 ms (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,977] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,978] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,979] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)\n",
      "[2024-11-17 05:44:20,980] INFO minSessionTimeout set to 6000 ms (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,980] INFO maxSessionTimeout set to 60000 ms (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,982] INFO getData response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)\n",
      "[2024-11-17 05:44:20,982] INFO getChildren response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)\n",
      "[2024-11-17 05:44:20,983] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)\n",
      "[2024-11-17 05:44:20,983] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)\n",
      "[2024-11-17 05:44:20,983] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)\n",
      "[2024-11-17 05:44:20,983] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)\n",
      "[2024-11-17 05:44:20,984] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)\n",
      "[2024-11-17 05:44:20,984] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)\n",
      "[2024-11-17 05:44:20,986] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,986] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:20,986] INFO zookeeper.enforce.auth.enabled = false (org.apache.zookeeper.server.AuthenticationHelper)\n",
      "[2024-11-17 05:44:20,987] INFO zookeeper.enforce.auth.schemes = [] (org.apache.zookeeper.server.AuthenticationHelper)\n",
      "[2024-11-17 05:44:20,987] INFO Created server with tickTime 3000 ms minSessionTimeout 6000 ms maxSessionTimeout 60000 ms clientPortListenBacklog -1 datadir /usr/local/kafka/data/zookeeper/version-2 snapdir /usr/local/kafka/data/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:21,004] INFO Logging initialized @539ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log)\n",
      "[2024-11-17 05:44:21,065] WARN o.e.j.s.ServletContextHandler@5fbe4146{/,null,STOPPED} contextPath ends with /* (org.eclipse.jetty.server.handler.ContextHandler)\n",
      "[2024-11-17 05:44:21,065] WARN Empty contextPath (org.eclipse.jetty.server.handler.ContextHandler)\n",
      "[2024-11-17 05:44:21,080] INFO jetty-9.4.56.v20240826; built: 2024-08-26T17:15:05.868Z; git: ec6782ff5ead824dabdcf47fa98f90a4aedff401; jvm 21.0.5+9-LTS-239 (org.eclipse.jetty.server.Server)\n",
      "[2024-11-17 05:44:21,107] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session)\n",
      "[2024-11-17 05:44:21,107] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session)\n",
      "[2024-11-17 05:44:21,108] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session)\n",
      "[2024-11-17 05:44:21,111] WARN ServletContext@o.e.j.s.ServletContextHandler@5fbe4146{/,null,STARTING} has uncovered http methods for path: /* (org.eclipse.jetty.security.SecurityHandler)\n",
      "[2024-11-17 05:44:21,121] INFO Started o.e.j.s.ServletContextHandler@5fbe4146{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler)\n",
      "[2024-11-17 05:44:21,132] INFO Started ServerConnector@74235045{HTTP/1.1, (http/1.1)}{0.0.0.0:9090} (org.eclipse.jetty.server.AbstractConnector)\n",
      "[2024-11-17 05:44:21,132] INFO Started @667ms (org.eclipse.jetty.server.Server)\n",
      "[2024-11-17 05:44:21,132] INFO Started AdminServer on address 0.0.0.0, port 9090 and command URL /commands (org.apache.zookeeper.server.admin.JettyAdminServer)\n",
      "[2024-11-17 05:44:21,136] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)\n",
      "[2024-11-17 05:44:21,137] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)\n",
      "[2024-11-17 05:44:21,138] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)\n",
      "[2024-11-17 05:44:21,139] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)\n",
      "[2024-11-17 05:44:21,149] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)\n",
      "[2024-11-17 05:44:21,150] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)\n",
      "[2024-11-17 05:44:21,150] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)\n",
      "[2024-11-17 05:44:21,150] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)\n",
      "[2024-11-17 05:44:21,154] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)\n",
      "[2024-11-17 05:44:21,155] INFO Snapshotting: 0x0 to /usr/local/kafka/data/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)\n",
      "[2024-11-17 05:44:21,158] INFO Snapshot loaded in 8 ms, highest zxid is 0x0, digest is 1371985504 (org.apache.zookeeper.server.ZKDatabase)\n",
      "[2024-11-17 05:44:21,159] INFO Snapshotting: 0x0 to /usr/local/kafka/data/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)\n",
      "[2024-11-17 05:44:21,160] INFO Snapshot taken in 1 ms (org.apache.zookeeper.server.ZooKeeperServer)\n",
      "[2024-11-17 05:44:21,167] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)\n",
      "[2024-11-17 05:44:21,167] INFO zookeeper.request_throttler.shutdownTimeout = 10000 ms (org.apache.zookeeper.server.RequestThrottler)\n",
      "[2024-11-17 05:44:21,181] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)\n",
      "[2024-11-17 05:44:21,182] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)\n"
     ]
    }
   ],
   "source": [
    "commands = [\n",
    "    \"/usr/local/kafka/bin/zookeeper-server-start.sh /usr/local/kafka/config/zookeeper.properties\"\n",
    "]\n",
    "\n",
    "execute_commands(commands=commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46934a18-8902-4764-a789-36761bbb3871",
   "metadata": {},
   "source": [
    "# START SECOND BROKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66cefd55-ad64-45b1-a84e-6591c1950f7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: /usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server2.properties\n",
      "\n",
      "[2024-11-17 05:44:22,561] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)\n",
      "[2024-11-17 05:44:22,767] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)\n",
      "[2024-11-17 05:44:22,854] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)\n",
      "[2024-11-17 05:44:22,857] INFO starting (kafka.server.KafkaServer)\n",
      "[2024-11-17 05:44:22,858] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)\n",
      "[2024-11-17 05:44:22,881] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)\n",
      "[2024-11-17 05:44:22,885] INFO Client environment:zookeeper.version=3.8.4-9316c2a7a97e1666d8f4593f34dd6fc36ecc436c, built on 2024-02-12 22:16 UTC (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,886] INFO Client environment:host.name=63399d325201 (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,886] INFO Client environment:java.version=21.0.5 (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,886] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,886] INFO Client environment:java.home=/usr/lib/jvm/jdk-21.0.5-oracle-x64 (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,886] INFO Client environment:java.class.path=/usr/local/kafka/bin/../libs/activation-1.1.1.jar:/usr/local/kafka/bin/../libs/aopalliance-repackaged-2.6.1.jar:/usr/local/kafka/bin/../libs/argparse4j-0.7.0.jar:/usr/local/kafka/bin/../libs/audience-annotations-0.12.0.jar:/usr/local/kafka/bin/../libs/caffeine-2.9.3.jar:/usr/local/kafka/bin/../libs/commons-beanutils-1.9.4.jar:/usr/local/kafka/bin/../libs/commons-cli-1.4.jar:/usr/local/kafka/bin/../libs/commons-collections-3.2.2.jar:/usr/local/kafka/bin/../libs/commons-digester-2.1.jar:/usr/local/kafka/bin/../libs/commons-io-2.14.0.jar:/usr/local/kafka/bin/../libs/commons-lang3-3.12.0.jar:/usr/local/kafka/bin/../libs/commons-logging-1.2.jar:/usr/local/kafka/bin/../libs/commons-validator-1.7.jar:/usr/local/kafka/bin/../libs/connect-api-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-basic-auth-extension-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-json-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-mirror-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-mirror-client-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-runtime-3.9.0.jar:/usr/local/kafka/bin/../libs/connect-transforms-3.9.0.jar:/usr/local/kafka/bin/../libs/error_prone_annotations-2.10.0.jar:/usr/local/kafka/bin/../libs/hk2-api-2.6.1.jar:/usr/local/kafka/bin/../libs/hk2-locator-2.6.1.jar:/usr/local/kafka/bin/../libs/hk2-utils-2.6.1.jar:/usr/local/kafka/bin/../libs/jackson-annotations-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-core-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-databind-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-dataformat-csv-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-datatype-jdk8-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-jaxrs-base-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-jaxrs-json-provider-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-module-afterburner-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-module-jaxb-annotations-2.16.2.jar:/usr/local/kafka/bin/../libs/jackson-module-scala_2.12-2.16.2.jar:/usr/local/kafka/bin/../libs/jakarta.activation-api-1.2.2.jar:/usr/local/kafka/bin/../libs/jakarta.annotation-api-1.3.5.jar:/usr/local/kafka/bin/../libs/jakarta.inject-2.6.1.jar:/usr/local/kafka/bin/../libs/jakarta.validation-api-2.0.2.jar:/usr/local/kafka/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/usr/local/kafka/bin/../libs/jakarta.xml.bind-api-2.3.3.jar:/usr/local/kafka/bin/../libs/javassist-3.29.2-GA.jar:/usr/local/kafka/bin/../libs/javax.activation-api-1.2.0.jar:/usr/local/kafka/bin/../libs/javax.annotation-api-1.3.2.jar:/usr/local/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/usr/local/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/usr/local/kafka/bin/../libs/jaxb-api-2.3.1.jar:/usr/local/kafka/bin/../libs/jersey-client-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-common-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-container-servlet-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-container-servlet-core-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-hk2-2.39.1.jar:/usr/local/kafka/bin/../libs/jersey-server-2.39.1.jar:/usr/local/kafka/bin/../libs/jetty-client-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-continuation-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-http-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-io-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-security-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-server-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-servlet-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-servlets-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-util-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jetty-util-ajax-9.4.56.v20240826.jar:/usr/local/kafka/bin/../libs/jline-3.25.1.jar:/usr/local/kafka/bin/../libs/jopt-simple-5.0.4.jar:/usr/local/kafka/bin/../libs/jose4j-0.9.4.jar:/usr/local/kafka/bin/../libs/jsr305-3.0.2.jar:/usr/local/kafka/bin/../libs/kafka-clients-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-group-coordinator-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-group-coordinator-api-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-metadata-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-raft-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-server-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-server-common-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-shell-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-storage-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-storage-api-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-examples-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-scala_2.12-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-streams-test-utils-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-tools-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-tools-api-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka-transaction-coordinator-3.9.0.jar:/usr/local/kafka/bin/../libs/kafka_2.12-3.9.0.jar:/usr/local/kafka/bin/../libs/lz4-java-1.8.0.jar:/usr/local/kafka/bin/../libs/maven-artifact-3.9.6.jar:/usr/local/kafka/bin/../libs/metrics-core-2.2.0.jar:/usr/local/kafka/bin/../libs/metrics-core-4.1.12.1.jar:/usr/local/kafka/bin/../libs/netty-buffer-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-codec-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-common-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-handler-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-resolver-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-classes-epoll-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-native-epoll-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/netty-transport-native-unix-common-4.1.111.Final.jar:/usr/local/kafka/bin/../libs/opentelemetry-proto-1.0.0-alpha.jar:/usr/local/kafka/bin/../libs/osgi-resource-locator-1.0.3.jar:/usr/local/kafka/bin/../libs/paranamer-2.8.jar:/usr/local/kafka/bin/../libs/pcollections-4.0.1.jar:/usr/local/kafka/bin/../libs/plexus-utils-3.5.1.jar:/usr/local/kafka/bin/../libs/protobuf-java-3.25.5.jar:/usr/local/kafka/bin/../libs/reflections-0.10.2.jar:/usr/local/kafka/bin/../libs/reload4j-1.2.25.jar:/usr/local/kafka/bin/../libs/rocksdbjni-7.9.2.jar:/usr/local/kafka/bin/../libs/scala-collection-compat_2.12-2.10.0.jar:/usr/local/kafka/bin/../libs/scala-java8-compat_2.12-1.0.2.jar:/usr/local/kafka/bin/../libs/scala-library-2.12.19.jar:/usr/local/kafka/bin/../libs/scala-logging_2.12-3.9.5.jar:/usr/local/kafka/bin/../libs/scala-reflect-2.12.19.jar:/usr/local/kafka/bin/../libs/slf4j-api-1.7.36.jar:/usr/local/kafka/bin/../libs/slf4j-reload4j-1.7.36.jar:/usr/local/kafka/bin/../libs/snappy-java-1.1.10.5.jar:/usr/local/kafka/bin/../libs/swagger-annotations-2.2.8.jar:/usr/local/kafka/bin/../libs/trogdor-3.9.0.jar:/usr/local/kafka/bin/../libs/zookeeper-3.8.4.jar:/usr/local/kafka/bin/../libs/zookeeper-jute-3.8.4.jar:/usr/local/kafka/bin/../libs/zstd-jni-1.5.6-4.jar (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,887] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,887] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,888] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,888] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,888] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,888] INFO Client environment:os.version=5.10.16.3-microsoft-standard-WSL2 (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,888] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,888] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,888] INFO Client environment:user.dir=/notebooks (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,888] INFO Client environment:os.memory.free=983MB (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,888] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,889] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,890] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3224a577 (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:44:22,895] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)\n",
      "[2024-11-17 05:44:22,901] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)\n",
      "[2024-11-17 05:44:22,903] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)\n",
      "[2024-11-17 05:44:22,904] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)\n",
      "[2024-11-17 05:44:22,907] INFO Socket connection established, initiating session, client: /127.0.0.1:41086, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)\n",
      "[2024-11-17 05:44:22,913] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)\n",
      "[2024-11-17 05:44:22,928] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100017ea8f10000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)\n",
      "[2024-11-17 05:44:22,930] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)\n",
      "[2024-11-17 05:44:23,214] INFO Cluster ID = w-LBP-c4QfOSySIWKOZfSQ (kafka.server.KafkaServer)\n",
      "[2024-11-17 05:44:23,301] INFO KafkaConfig values: \n",
      "\tadvertised.listeners = null\n",
      "\talter.config.policy.class.name = null\n",
      "\talter.log.dirs.replication.quota.window.num = 11\n",
      "\talter.log.dirs.replication.quota.window.size.seconds = 1\n",
      "\tauthorizer.class.name = \n",
      "\tauto.create.topics.enable = true\n",
      "\tauto.include.jmx.reporter = true\n",
      "\tauto.leader.rebalance.enable = true\n",
      "\tbackground.threads = 10\n",
      "\tbroker.heartbeat.interval.ms = 2000\n",
      "\tbroker.id = 2\n",
      "\tbroker.id.generation.enable = true\n",
      "\tbroker.rack = null\n",
      "\tbroker.session.timeout.ms = 9000\n",
      "\tclient.quota.callback.class = null\n",
      "\tcompression.gzip.level = -1\n",
      "\tcompression.lz4.level = 9\n",
      "\tcompression.type = producer\n",
      "\tcompression.zstd.level = 3\n",
      "\tconnection.failed.authentication.delay.ms = 100\n",
      "\tconnections.max.idle.ms = 600000\n",
      "\tconnections.max.reauth.ms = 0\n",
      "\tcontrol.plane.listener.name = null\n",
      "\tcontrolled.shutdown.enable = true\n",
      "\tcontrolled.shutdown.max.retries = 3\n",
      "\tcontrolled.shutdown.retry.backoff.ms = 5000\n",
      "\tcontroller.listener.names = null\n",
      "\tcontroller.quorum.append.linger.ms = 25\n",
      "\tcontroller.quorum.bootstrap.servers = []\n",
      "\tcontroller.quorum.election.backoff.max.ms = 1000\n",
      "\tcontroller.quorum.election.timeout.ms = 1000\n",
      "\tcontroller.quorum.fetch.timeout.ms = 2000\n",
      "\tcontroller.quorum.request.timeout.ms = 2000\n",
      "\tcontroller.quorum.retry.backoff.ms = 20\n",
      "\tcontroller.quorum.voters = []\n",
      "\tcontroller.quota.window.num = 11\n",
      "\tcontroller.quota.window.size.seconds = 1\n",
      "\tcontroller.socket.timeout.ms = 30000\n",
      "\tcreate.topic.policy.class.name = null\n",
      "\tdefault.replication.factor = 1\n",
      "\tdelegation.token.expiry.check.interval.ms = 3600000\n",
      "\tdelegation.token.expiry.time.ms = 86400000\n",
      "\tdelegation.token.master.key = null\n",
      "\tdelegation.token.max.lifetime.ms = 604800000\n",
      "\tdelegation.token.secret.key = null\n",
      "\tdelete.records.purgatory.purge.interval.requests = 1\n",
      "\tdelete.topic.enable = true\n",
      "\tearly.start.listeners = null\n",
      "\teligible.leader.replicas.enable = false\n",
      "\tfetch.max.bytes = 57671680\n",
      "\tfetch.purgatory.purge.interval.requests = 1000\n",
      "\tgroup.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.UniformAssignor, org.apache.kafka.coordinator.group.assignor.RangeAssignor]\n",
      "\tgroup.consumer.heartbeat.interval.ms = 5000\n",
      "\tgroup.consumer.max.heartbeat.interval.ms = 15000\n",
      "\tgroup.consumer.max.session.timeout.ms = 60000\n",
      "\tgroup.consumer.max.size = 2147483647\n",
      "\tgroup.consumer.migration.policy = disabled\n",
      "\tgroup.consumer.min.heartbeat.interval.ms = 5000\n",
      "\tgroup.consumer.min.session.timeout.ms = 45000\n",
      "\tgroup.consumer.session.timeout.ms = 45000\n",
      "\tgroup.coordinator.append.linger.ms = 10\n",
      "\tgroup.coordinator.new.enable = false\n",
      "\tgroup.coordinator.rebalance.protocols = [classic]\n",
      "\tgroup.coordinator.threads = 1\n",
      "\tgroup.initial.rebalance.delay.ms = 0\n",
      "\tgroup.max.session.timeout.ms = 1800000\n",
      "\tgroup.max.size = 2147483647\n",
      "\tgroup.min.session.timeout.ms = 6000\n",
      "\tgroup.share.delivery.count.limit = 5\n",
      "\tgroup.share.enable = false\n",
      "\tgroup.share.heartbeat.interval.ms = 5000\n",
      "\tgroup.share.max.groups = 10\n",
      "\tgroup.share.max.heartbeat.interval.ms = 15000\n",
      "\tgroup.share.max.record.lock.duration.ms = 60000\n",
      "\tgroup.share.max.session.timeout.ms = 60000\n",
      "\tgroup.share.max.size = 200\n",
      "\tgroup.share.min.heartbeat.interval.ms = 5000\n",
      "\tgroup.share.min.record.lock.duration.ms = 15000\n",
      "\tgroup.share.min.session.timeout.ms = 45000\n",
      "\tgroup.share.partition.max.record.locks = 200\n",
      "\tgroup.share.record.lock.duration.ms = 30000\n",
      "\tgroup.share.session.timeout.ms = 45000\n",
      "\tinitial.broker.registration.timeout.ms = 60000\n",
      "\tinter.broker.listener.name = null\n",
      "\tinter.broker.protocol.version = 3.9-IV0\n",
      "\tkafka.metrics.polling.interval.secs = 10\n",
      "\tkafka.metrics.reporters = []\n",
      "\tleader.imbalance.check.interval.seconds = 300\n",
      "\tleader.imbalance.per.broker.percentage = 10\n",
      "\tlistener.security.protocol.map = SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT\n",
      "\tlisteners = PLAINTEXT://:9092\n",
      "\tlog.cleaner.backoff.ms = 15000\n",
      "\tlog.cleaner.dedupe.buffer.size = 134217728\n",
      "\tlog.cleaner.delete.retention.ms = 86400000\n",
      "\tlog.cleaner.enable = true\n",
      "\tlog.cleaner.io.buffer.load.factor = 0.9\n",
      "\tlog.cleaner.io.buffer.size = 524288\n",
      "\tlog.cleaner.io.max.bytes.per.second = 1.7976931348623157E308\n",
      "\tlog.cleaner.max.compaction.lag.ms = 9223372036854775807\n",
      "\tlog.cleaner.min.cleanable.ratio = 0.5\n",
      "\tlog.cleaner.min.compaction.lag.ms = 0\n",
      "\tlog.cleaner.threads = 1\n",
      "\tlog.cleanup.policy = [delete]\n",
      "\tlog.dir = /tmp/kafka-logs\n",
      "\tlog.dir.failure.timeout.ms = 30000\n",
      "\tlog.dirs = /usr/local/kafka/data/logs/broker_2\n",
      "\tlog.flush.interval.messages = 9223372036854775807\n",
      "\tlog.flush.interval.ms = null\n",
      "\tlog.flush.offset.checkpoint.interval.ms = 60000\n",
      "\tlog.flush.scheduler.interval.ms = 9223372036854775807\n",
      "\tlog.flush.start.offset.checkpoint.interval.ms = 60000\n",
      "\tlog.index.interval.bytes = 4096\n",
      "\tlog.index.size.max.bytes = 10485760\n",
      "\tlog.initial.task.delay.ms = 30000\n",
      "\tlog.local.retention.bytes = -2\n",
      "\tlog.local.retention.ms = -2\n",
      "\tlog.message.downconversion.enable = true\n",
      "\tlog.message.format.version = 3.0-IV1\n",
      "\tlog.message.timestamp.after.max.ms = 9223372036854775807\n",
      "\tlog.message.timestamp.before.max.ms = 9223372036854775807\n",
      "\tlog.message.timestamp.difference.max.ms = 9223372036854775807\n",
      "\tlog.message.timestamp.type = CreateTime\n",
      "\tlog.preallocate = false\n",
      "\tlog.retention.bytes = -1\n",
      "\tlog.retention.check.interval.ms = 300000\n",
      "\tlog.retention.hours = 168\n",
      "\tlog.retention.minutes = null\n",
      "\tlog.retention.ms = null\n",
      "\tlog.roll.hours = 168\n",
      "\tlog.roll.jitter.hours = 0\n",
      "\tlog.roll.jitter.ms = null\n",
      "\tlog.roll.ms = null\n",
      "\tlog.segment.bytes = 1073741824\n",
      "\tlog.segment.delete.delay.ms = 60000\n",
      "\tmax.connection.creation.rate = 2147483647\n",
      "\tmax.connections = 2147483647\n",
      "\tmax.connections.per.ip = 2147483647\n",
      "\tmax.connections.per.ip.overrides = \n",
      "\tmax.incremental.fetch.session.cache.slots = 1000\n",
      "\tmax.request.partition.size.limit = 2000\n",
      "\tmessage.max.bytes = 1048588\n",
      "\tmetadata.log.dir = null\n",
      "\tmetadata.log.max.record.bytes.between.snapshots = 20971520\n",
      "\tmetadata.log.max.snapshot.interval.ms = 3600000\n",
      "\tmetadata.log.segment.bytes = 1073741824\n",
      "\tmetadata.log.segment.min.bytes = 8388608\n",
      "\tmetadata.log.segment.ms = 604800000\n",
      "\tmetadata.max.idle.interval.ms = 500\n",
      "\tmetadata.max.retention.bytes = 104857600\n",
      "\tmetadata.max.retention.ms = 604800000\n",
      "\tmetric.reporters = []\n",
      "\tmetrics.num.samples = 2\n",
      "\tmetrics.recording.level = INFO\n",
      "\tmetrics.sample.window.ms = 30000\n",
      "\tmin.insync.replicas = 1\n",
      "\tnode.id = 2\n",
      "\tnum.io.threads = 8\n",
      "\tnum.network.threads = 3\n",
      "\tnum.partitions = 1\n",
      "\tnum.recovery.threads.per.data.dir = 1\n",
      "\tnum.replica.alter.log.dirs.threads = null\n",
      "\tnum.replica.fetchers = 1\n",
      "\toffset.metadata.max.bytes = 4096\n",
      "\toffsets.commit.required.acks = -1\n",
      "\toffsets.commit.timeout.ms = 5000\n",
      "\toffsets.load.buffer.size = 5242880\n",
      "\toffsets.retention.check.interval.ms = 600000\n",
      "\toffsets.retention.minutes = 10080\n",
      "\toffsets.topic.compression.codec = 0\n",
      "\toffsets.topic.num.partitions = 50\n",
      "\toffsets.topic.replication.factor = 1\n",
      "\toffsets.topic.segment.bytes = 104857600\n",
      "\tpassword.encoder.cipher.algorithm = AES/CBC/PKCS5Padding\n",
      "\tpassword.encoder.iterations = 4096\n",
      "\tpassword.encoder.key.length = 128\n",
      "\tpassword.encoder.keyfactory.algorithm = null\n",
      "\tpassword.encoder.old.secret = null\n",
      "\tpassword.encoder.secret = null\n",
      "\tprincipal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder\n",
      "\tprocess.roles = []\n",
      "\tproducer.id.expiration.check.interval.ms = 600000\n",
      "\tproducer.id.expiration.ms = 86400000\n",
      "\tproducer.purgatory.purge.interval.requests = 1000\n",
      "\tqueued.max.request.bytes = -1\n",
      "\tqueued.max.requests = 500\n",
      "\tquota.window.num = 11\n",
      "\tquota.window.size.seconds = 1\n",
      "\tremote.fetch.max.wait.ms = 500\n",
      "\tremote.log.index.file.cache.total.size.bytes = 1073741824\n",
      "\tremote.log.manager.copier.thread.pool.size = -1\n",
      "\tremote.log.manager.copy.max.bytes.per.second = 9223372036854775807\n",
      "\tremote.log.manager.copy.quota.window.num = 11\n",
      "\tremote.log.manager.copy.quota.window.size.seconds = 1\n",
      "\tremote.log.manager.expiration.thread.pool.size = -1\n",
      "\tremote.log.manager.fetch.max.bytes.per.second = 9223372036854775807\n",
      "\tremote.log.manager.fetch.quota.window.num = 11\n",
      "\tremote.log.manager.fetch.quota.window.size.seconds = 1\n",
      "\tremote.log.manager.task.interval.ms = 30000\n",
      "\tremote.log.manager.task.retry.backoff.max.ms = 30000\n",
      "\tremote.log.manager.task.retry.backoff.ms = 500\n",
      "\tremote.log.manager.task.retry.jitter = 0.2\n",
      "\tremote.log.manager.thread.pool.size = 10\n",
      "\tremote.log.metadata.custom.metadata.max.bytes = 128\n",
      "\tremote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager\n",
      "\tremote.log.metadata.manager.class.path = null\n",
      "\tremote.log.metadata.manager.impl.prefix = rlmm.config.\n",
      "\tremote.log.metadata.manager.listener.name = null\n",
      "\tremote.log.reader.max.pending.tasks = 100\n",
      "\tremote.log.reader.threads = 10\n",
      "\tremote.log.storage.manager.class.name = null\n",
      "\tremote.log.storage.manager.class.path = null\n",
      "\tremote.log.storage.manager.impl.prefix = rsm.config.\n",
      "\tremote.log.storage.system.enable = false\n",
      "\treplica.fetch.backoff.ms = 1000\n",
      "\treplica.fetch.max.bytes = 1048576\n",
      "\treplica.fetch.min.bytes = 1\n",
      "\treplica.fetch.response.max.bytes = 10485760\n",
      "\treplica.fetch.wait.max.ms = 500\n",
      "\treplica.high.watermark.checkpoint.interval.ms = 5000\n",
      "\treplica.lag.time.max.ms = 30000\n",
      "\treplica.selector.class = null\n",
      "\treplica.socket.receive.buffer.bytes = 65536\n",
      "\treplica.socket.timeout.ms = 30000\n",
      "\treplication.quota.window.num = 11\n",
      "\treplication.quota.window.size.seconds = 1\n",
      "\trequest.timeout.ms = 30000\n",
      "\treserved.broker.max.id = 1000\n",
      "\tsasl.client.callback.handler.class = null\n",
      "\tsasl.enabled.mechanisms = [GSSAPI]\n",
      "\tsasl.jaas.config = null\n",
      "\tsasl.kerberos.kinit.cmd = /usr/bin/kinit\n",
      "\tsasl.kerberos.min.time.before.relogin = 60000\n",
      "\tsasl.kerberos.principal.to.local.rules = [DEFAULT]\n",
      "\tsasl.kerberos.service.name = null\n",
      "\tsasl.kerberos.ticket.renew.jitter = 0.05\n",
      "\tsasl.kerberos.ticket.renew.window.factor = 0.8\n",
      "\tsasl.login.callback.handler.class = null\n",
      "\tsasl.login.class = null\n",
      "\tsasl.login.connect.timeout.ms = null\n",
      "\tsasl.login.read.timeout.ms = null\n",
      "\tsasl.login.refresh.buffer.seconds = 300\n",
      "\tsasl.login.refresh.min.period.seconds = 60\n",
      "\tsasl.login.refresh.window.factor = 0.8\n",
      "\tsasl.login.refresh.window.jitter = 0.05\n",
      "\tsasl.login.retry.backoff.max.ms = 10000\n",
      "\tsasl.login.retry.backoff.ms = 100\n",
      "\tsasl.mechanism.controller.protocol = GSSAPI\n",
      "\tsasl.mechanism.inter.broker.protocol = GSSAPI\n",
      "\tsasl.oauthbearer.clock.skew.seconds = 30\n",
      "\tsasl.oauthbearer.expected.audience = null\n",
      "\tsasl.oauthbearer.expected.issuer = null\n",
      "\tsasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000\n",
      "\tsasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000\n",
      "\tsasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100\n",
      "\tsasl.oauthbearer.jwks.endpoint.url = null\n",
      "\tsasl.oauthbearer.scope.claim.name = scope\n",
      "\tsasl.oauthbearer.sub.claim.name = sub\n",
      "\tsasl.oauthbearer.token.endpoint.url = null\n",
      "\tsasl.server.callback.handler.class = null\n",
      "\tsasl.server.max.receive.size = 524288\n",
      "\tsecurity.inter.broker.protocol = PLAINTEXT\n",
      "\tsecurity.providers = null\n",
      "\tserver.max.startup.time.ms = 9223372036854775807\n",
      "\tsocket.connection.setup.timeout.max.ms = 30000\n",
      "\tsocket.connection.setup.timeout.ms = 10000\n",
      "\tsocket.listen.backlog.size = 50\n",
      "\tsocket.receive.buffer.bytes = 102400\n",
      "\tsocket.request.max.bytes = 104857600\n",
      "\tsocket.send.buffer.bytes = 102400\n",
      "\tssl.allow.dn.changes = false\n",
      "\tssl.allow.san.changes = false\n",
      "\tssl.cipher.suites = []\n",
      "\tssl.client.auth = none\n",
      "\tssl.enabled.protocols = [TLSv1.2, TLSv1.3]\n",
      "\tssl.endpoint.identification.algorithm = https\n",
      "\tssl.engine.factory.class = null\n",
      "\tssl.key.password = null\n",
      "\tssl.keymanager.algorithm = SunX509\n",
      "\tssl.keystore.certificate.chain = null\n",
      "\tssl.keystore.key = null\n",
      "\tssl.keystore.location = null\n",
      "\tssl.keystore.password = null\n",
      "\tssl.keystore.type = JKS\n",
      "\tssl.principal.mapping.rules = DEFAULT\n",
      "\tssl.protocol = TLSv1.3\n",
      "\tssl.provider = null\n",
      "\tssl.secure.random.implementation = null\n",
      "\tssl.trustmanager.algorithm = PKIX\n",
      "\tssl.truststore.certificates = null\n",
      "\tssl.truststore.location = null\n",
      "\tssl.truststore.password = null\n",
      "\tssl.truststore.type = JKS\n",
      "\ttelemetry.max.bytes = 1048576\n",
      "\ttransaction.abort.timed.out.transaction.cleanup.interval.ms = 10000\n",
      "\ttransaction.max.timeout.ms = 900000\n",
      "\ttransaction.partition.verification.enable = true\n",
      "\ttransaction.remove.expired.transaction.cleanup.interval.ms = 3600000\n",
      "\ttransaction.state.log.load.buffer.size = 5242880\n",
      "\ttransaction.state.log.min.isr = 1\n",
      "\ttransaction.state.log.num.partitions = 50\n",
      "\ttransaction.state.log.replication.factor = 1\n",
      "\ttransaction.state.log.segment.bytes = 104857600\n",
      "\ttransactional.id.expiration.ms = 604800000\n",
      "\tunclean.leader.election.enable = false\n",
      "\tunclean.leader.election.interval.ms = 300000\n",
      "\tunstable.api.versions.enable = false\n",
      "\tunstable.feature.versions.enable = false\n",
      "\tzookeeper.clientCnxnSocket = null\n",
      "\tzookeeper.connect = localhost:2181\n",
      "\tzookeeper.connection.timeout.ms = 18000\n",
      "\tzookeeper.max.in.flight.requests = 10\n",
      "\tzookeeper.metadata.migration.enable = false\n",
      "\tzookeeper.metadata.migration.min.batch.size = 200\n",
      "\tzookeeper.session.timeout.ms = 18000\n",
      "\tzookeeper.set.acl = false\n",
      "\tzookeeper.ssl.cipher.suites = null\n",
      "\tzookeeper.ssl.client.enable = false\n",
      "\tzookeeper.ssl.crl.enable = false\n",
      "\tzookeeper.ssl.enabled.protocols = null\n",
      "\tzookeeper.ssl.endpoint.identification.algorithm = HTTPS\n",
      "\tzookeeper.ssl.keystore.location = null\n",
      "\tzookeeper.ssl.keystore.password = null\n",
      "\tzookeeper.ssl.keystore.type = null\n",
      "\tzookeeper.ssl.ocsp.enable = false\n",
      "\tzookeeper.ssl.protocol = TLSv1.2\n",
      "\tzookeeper.ssl.truststore.location = null\n",
      "\tzookeeper.ssl.truststore.password = null\n",
      "\tzookeeper.ssl.truststore.type = null\n",
      " (kafka.server.KafkaConfig)\n",
      "[2024-11-17 05:44:23,336] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:44:23,337] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:44:23,338] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:44:23,341] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:44:23,346] INFO [KafkaServer id=2] Rewriting /usr/local/kafka/data/logs/broker_2/meta.properties (kafka.server.KafkaServer)\n",
      "[2024-11-17 05:44:23,407] INFO Loading logs from log dirs ArrayBuffer(/usr/local/kafka/data/logs/broker_2) (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:23,412] INFO No logs found to be loaded in /usr/local/kafka/data/logs/broker_2 (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:23,424] INFO Loaded 0 logs in 15ms (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:23,426] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:23,428] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:23,464] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)\n",
      "[2024-11-17 05:44:23,473] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)\n",
      "[2024-11-17 05:44:23,481] INFO Feature ZK node at path: /feature does not exist (kafka.server.FinalizedFeatureChangeListener)\n",
      "[2024-11-17 05:44:23,498] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)\n",
      "[2024-11-17 05:44:23,781] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)\n",
      "[2024-11-17 05:44:23,807] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)\n",
      "[2024-11-17 05:44:23,812] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Starting (kafka.server.NodeToControllerRequestThread)\n",
      "[2024-11-17 05:44:23,831] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:44:23,832] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:44:23,833] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:44:23,834] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:44:23,835] INFO [ExpirationReaper-2-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:44:23,846] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)\n",
      "[2024-11-17 05:44:23,846] INFO [AddPartitionsToTxnSenderThread-2]: Starting (kafka.server.AddPartitionsToTxnManager)\n",
      "[2024-11-17 05:44:23,885] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)\n",
      "[2024-11-17 05:44:23,906] INFO Stat of the created znode at /brokers/ids/2 is: 25,25,1731822263897,1731822263897,1,0,0,72059237549801472,208,0,25\n",
      " (kafka.zk.KafkaZkClient)\n",
      "[2024-11-17 05:44:23,906] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://63399d325201:9092, czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)\n",
      "[2024-11-17 05:44:23,941] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:44:23,948] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:44:23,948] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:44:23,952] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)\n",
      "[2024-11-17 05:44:23,965] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:23,971] INFO Feature ZK node created at path: /feature (kafka.server.FinalizedFeatureChangeListener)\n",
      "[2024-11-17 05:44:23,974] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:23,986] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)\n",
      "[2024-11-17 05:44:23,991] INFO [TxnMarkerSenderThread-2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)\n",
      "[2024-11-17 05:44:23,992] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)\n",
      "[2024-11-17 05:44:23,994] INFO [MetadataCache brokerId=2] Updated cache from existing None to latest Features(metadataVersion=3.9-IV0, finalizedFeatures={}, finalizedFeaturesEpoch=0). (kafka.server.metadata.ZkMetadataCache)\n",
      "[2024-11-17 05:44:24,023] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:44:24,058] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)\n",
      "[2024-11-17 05:44:24,068] INFO [Controller id=2, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)\n",
      "[2024-11-17 05:44:24,074] WARN [Controller id=2, targetBrokerId=2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "[2024-11-17 05:44:24,078] INFO [Controller id=2, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)\n",
      "[2024-11-17 05:44:24,082] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Enabling request processing. (kafka.network.SocketServer)\n",
      "[2024-11-17 05:44:24,085] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)\n",
      "[2024-11-17 05:44:24,096] INFO [KafkaServer id=2] Start processing authorizer futures (kafka.server.KafkaServer)\n",
      "[2024-11-17 05:44:24,097] INFO [KafkaServer id=2] End processing authorizer futures (kafka.server.KafkaServer)\n",
      "[2024-11-17 05:44:24,098] INFO [KafkaServer id=2] Start processing enable request processing future (kafka.server.KafkaServer)\n",
      "[2024-11-17 05:44:24,098] INFO [KafkaServer id=2] End processing enable request processing future (kafka.server.KafkaServer)\n",
      "[2024-11-17 05:44:24,104] INFO Kafka version: 3.9.0 (org.apache.kafka.common.utils.AppInfoParser)\n",
      "[2024-11-17 05:44:24,104] INFO Kafka commitId: a60e31147e6b01ee (org.apache.kafka.common.utils.AppInfoParser)\n",
      "[2024-11-17 05:44:24,104] INFO Kafka startTimeMs: 1731822264098 (org.apache.kafka.common.utils.AppInfoParser)\n",
      "[2024-11-17 05:44:24,106] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)\n",
      "[2024-11-17 05:44:24,215] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Recorded new ZK controller, from now on will use node 63399d325201:9092 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)\n",
      "[2024-11-17 05:44:24,304] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Recorded new ZK controller, from now on will use node 63399d325201:9092 (id: 2 rack: null) (kafka.server.NodeToControllerRequestThread)\n",
      "[2024-11-17 05:44:36,555] INFO Creating topic animals-topic-batch-classic-way with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)\n",
      "[2024-11-17 05:44:36,633] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(animals-topic-batch-classic-way-0) (kafka.server.ReplicaFetcherManager)\n",
      "[2024-11-17 05:44:36,677] INFO [LogLoader partition=animals-topic-batch-classic-way-0, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:36,687] INFO Created log for partition animals-topic-batch-classic-way-0 in /usr/local/kafka/data/logs/broker_2/animals-topic-batch-classic-way-0 with properties {} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:36,689] INFO [Partition animals-topic-batch-classic-way-0 broker=2] No checkpointed highwatermark is found for partition animals-topic-batch-classic-way-0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:36,690] INFO [Partition animals-topic-batch-classic-way-0 broker=2] Log loaded for partition animals-topic-batch-classic-way-0 with initial high watermark 0 (kafka.cluster.Partition)\n"
     ]
    }
   ],
   "source": [
    "commands = [\n",
    "    \"/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server2.properties\"\n",
    "]\n",
    "\n",
    "execute_commands(commands=commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522cc9a0-0b48-4423-a8d5-5a4289337692",
   "metadata": {},
   "source": [
    "# PRODUCE MESSAGES CLASIC WAY\n",
    "### COPY, PASTE, AND RUN THE FOLLOWING CODE IN ANOTHER NOTEBOOK TO OBSERVE STREAMING READING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce26a2-ffbf-48e8-ac7e-237e8ddae262",
   "metadata": {},
   "source": [
    "```python\n",
    "from confluent_kafka import Producer\n",
    "import json\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import random\n",
    "\n",
    "def get_dataset():\n",
    "    # Create a sample list with animal data\n",
    "    dataset = [(\"lion\", \"mammal\"), (\"elephant\", \"mammal\"), (\"tiger\", \"feline\"), (\"whale\", \"mammal\"), (\"penguin\", \"bird\"), (\"gorilla\", \"primate\"), (\"leopard\", \"feline\"), (\"crocodile\", \"reptile\"), (\"rhinoceros\", \"mammal\"), \n",
    "            (\"zebra\", \"mammal\"), (\"hippopotamus\", \"mammal\"), (\"eagle\", \"bird\"), (\"orangutan\", \"primate\"), (\"grizzly bear\", \"mammal\"), (\"owl\", \"bird\"), (\"polar bear\", \"mammal\"), (\"python\", \"reptile\"), (\"hawk\", \"bird\"), \n",
    "            (\"wolf\", \"mammal\"), (\"tortoise\", \"reptile\"), (\"swan\", \"bird\"), (\"cheetah\", \"feline\"), (\"seagull\", \"bird\"), (\"giraffe\", \"mammal\"), (\"deer\", \"mammal\"), (\"giraffe\", \"mammal\"), (\"lizard\", \"reptile\"), (\"flamingo\", \"bird\"),\n",
    "            (\"chimp\", \"primate\"), (\"buffalo\", \"mammal\"), (\"vulture\", \"bird\"), (\"bear\", \"mammal\"), (\"anaconda\", \"reptile\"), (\"pigeon\", \"bird\"), (\"coyote\", \"mammal\"), (\"chameleon\", \"reptile\"), (\"ostrich\", \"bird\"), (\"jaguar\", \"feline\"), \n",
    "            (\"owl\", \"bird\"), (\"beetle\", \"insect\"), (\"snail\", \"invertebrate\"), (\"octopus\", \"cephalopod\"), (\"lobster\", \"crustacean\"), (\"koala\", \"marsupial\"), (\"crane\", \"bird\"), (\"iguana\", \"reptile\"), (\"lemur\", \"primate\"), (\"sloth\", \"mammal\"), \n",
    "            (\"gazelle\", \"mammal\"), (\"wombat\", \"marsupial\"), (\"hummingbird\", \"bird\"), (\"porcupine\", \"mammal\"), (\"macaw\", \"bird\"), (\"hyena\", \"mammal\"), (\"dolphin\", \"mammal\"), (\"seahorse\", \"fish\"), (\"orca\", \"mammal\"), (\"kangaroo\", \"marsupial\"), \n",
    "            (\"shark\", \"fish\"), (\"beaver\", \"mammal\"), (\"platypus\", \"mammal\"), (\"armadillo\", \"mammal\"), (\"rabbit\", \"mammal\"), (\"camel\", \"mammal\"), (\"squirrel\", \"mammal\"), (\"peacock\", \"bird\"), (\"crow\", \"bird\"), (\"frog\", \"amphibian\"), \n",
    "            (\"toad\", \"amphibian\"), (\"newt\", \"amphibian\"), (\"axolotl\", \"amphibian\"), (\"butterfly\", \"insect\"), (\"dragonfly\", \"insect\"), (\"grasshopper\", \"insect\"), (\"mantis\", \"insect\"), (\"beetle\", \"insect\"), (\"ant\", \"insect\"), (\"termite\", \"insect\"),\n",
    "            (\"spider\", \"arachnid\"), (\"scorpion\", \"arachnid\"), (\"tick\", \"arachnid\"), (\"bee\", \"insect\"), (\"wasp\", \"insect\"), (\"hornet\", \"insect\"), (\"fly\", \"insect\"), (\"mosquito\", \"insect\"), (\"cockroach\", \"insect\"), (\"ladybug\", \"insect\"), \n",
    "            (\"firefly\", \"insect\"), (\"millipede\", \"arthropod\"), (\"centipede\", \"arthropod\"), (\"crab\", \"crustacean\"), (\"shrimp\", \"crustacean\"), (\"barnacle\", \"crustacean\"), (\"clam\", \"mollusk\"), (\"oyster\", \"mollusk\"), (\"mussel\", \"mollusk\"), \n",
    "            (\"snail\", \"mollusk\"), (\"slug\", \"mollusk\"), (\"squid\", \"cephalopod\"), (\"cuttlefish\", \"cephalopod\"), (\"nautilus\", \"cephalopod\"), (\"jellyfish\", \"cnidarian\"), (\"coral\", \"cnidarian\"), (\"hydra\", \"cnidarian\"), (\"anemone\", \"cnidarian\"), \n",
    "            (\"sponge\", \"porifera\"), (\"sea cucumber\", \"echinoderm\"), (\"starfish\", \"echinoderm\"), (\"sand dollar\", \"echinoderm\"), (\"sea urchin\", \"echinoderm\"), (\"brittle star\", \"echinoderm\"), (\"sea star\", \"echinoderm\"), (\"sea lily\", \"echinoderm\"), \n",
    "            (\"feather star\", \"echinoderm\"), (\"black widow\", \"arachnid\"), (\"brown recluse\", \"arachnid\"), (\"tarantula\", \"arachnid\"), (\"daddy longlegs\", \"arachnid\"), (\"wolf spider\", \"arachnid\"), (\"jumping spider\", \"arachnid\"), \n",
    "            (\"huntsman spider\", \"arachnid\"), (\"tarantula hawk\", \"insect\"), (\"assassin bug\", \"insect\"), (\"lacewing\", \"insect\"), (\"stink bug\", \"insect\"), (\"cicada\", \"insect\"), (\"walking stick\", \"insect\"), (\"scorpionfly\", \"insect\"), \n",
    "            (\"flower mantis\", \"insect\"), (\"praying mantis\", \"insect\"), (\"earwig\", \"insect\"), (\"flea\", \"insect\"), (\"leaf insect\", \"insect\"), (\"planthopper\", \"insect\"), (\"scale insect\", \"insect\"), (\"aphid\", \"insect\"), (\"mealybug\", \"insect\"), \n",
    "            (\"thrips\", \"insect\"), (\"whitefly\", \"insect\"), (\"beetle\", \"insect\"), (\"antlion\", \"insect\"), (\"snakefly\", \"insect\"), (\"dobsonfly\", \"insect\"), (\"webspinner\", \"insect\"), (\"mayfly\", \"insect\"), (\"stonefly\", \"insect\"), \n",
    "            (\"silverfish\", \"insect\"), (\"firebrat\", \"insect\"), (\"bristletail\", \"insect\"), (\"thysanuran\", \"insect\"), (\"dragonfly\", \"insect\"), (\"damselfly\", \"insect\"), (\"bluet\", \"insect\"), (\"darner\", \"insect\"), (\"adder\", \"insect\"), \n",
    "            (\"basker\", \"insect\"), (\"biter\", \"insect\"), (\"blister beetle\", \"insect\"), (\"bomber\", \"insect\"), (\"bristle beetle\", \"insect\"), (\"burrower\", \"insect\"), (\"carrier\", \"insect\"), (\"caterpillar\", \"insect\"), (\"chafers\", \"insect\"), \n",
    "            (\"chewer\", \"insect\"), (\"click beetle\", \"insect\"), (\"cobblers\", \"insect\"), (\"cobweb spider\", \"arachnid\"), (\"cockroaches\", \"insect\"), (\"coil worm\", \"insect\"), (\"creeper\", \"insect\"), (\"cuckoo wasp\", \"insect\"), (\"cutworm\", \"insect\"), \n",
    "            (\"digger\", \"insect\"), (\"dor beetle\", \"insect\"), (\"earthworms\", \"insect\"), (\"eggfly\", \"insect\"), (\"elaters\", \"insect\"), (\"emperor\", \"insect\"), (\"gadfly\", \"insect\"), (\"gnat\", \"insect\"), (\"grasshopper\", \"insect\"), (\"grazer\", \"insect\"), \n",
    "            (\"ground beetle\", \"insect\"), (\"harvester\", \"insect\"), (\"hornet\", \"insect\"), (\"hornworm\", \"insect\"), (\"humblebee\", \"insect\"), (\"humpbacked fly\", \"insect\"), (\"hoverfly\", \"insect\"), (\"hunter\", \"insect\"), (\"jumper\", \"insect\"), \n",
    "            (\"katydid\", \"insect\"), (\"lacewing\", \"insect\"), (\"leafcutter\", \"insect\"), (\"leafhopper\", \"insect\"), (\"leafroller\", \"insect\"), (\"louse\", \"insect\"), (\"maggot\", \"insect\"), (\"mantisfly\", \"insect\"), (\"marsh fly\", \"insect\"), \n",
    "            (\"marsh beetle\", \"insect\"), (\"mason wasp\", \"insect\"), (\"mealybug\", \"insect\"), (\"miner\", \"insect\"), (\"mite\", \"insect\"), (\"mole cricket\", \"insect\"), (\"moth\", \"insect\"), (\"nemesis\", \"insect\"), (\"net-winged insect\", \"insect\"), \n",
    "            (\"nightcrawler\", \"insect\"), (\"nit\", \"insect\"), (\"nymph\", \"insect\"), (\"odorous ant\", \"insect\"), (\"oracle\", \"insect\"), (\"orb weaver\", \"arachnid\"), (\"orcus\", \"insect\"), (\"ostracod\", \"insect\"), (\"outlaw\", \"insect\"), \n",
    "            (\"peacock butterfly\", \"insect\"), (\"pharaoh ant\", \"insect\"), (\"pillbug\", \"insect\"), (\"plankton\", \"insect\"), (\"pollinator\", \"insect\"), (\"potter wasp\", \"insect\"), (\"praying mantis\", \"insect\"), (\"predator\", \"insect\"),\n",
    "            (\"proboscis\", \"insect\"), (\"prophet\", \"insect\"), (\"pruner\", \"insect\"), (\"pseudoscorpion\", \"arachnid\"), (\"psycho\", \"insect\"), (\"psycho fly\", \"insect\"), (\"psychodid\", \"insect\"), (\"pupa\", \"insect\"), (\"purple martin\", \"insect\"), \n",
    "            (\"putter\", \"insect\"), (\"ranger\", \"insect\"), (\"recluse\", \"insect\"), (\"reducer\", \"insect\"), (\"repeater\", \"insect\"), (\"riffle bug\", \"insect\"), (\"robber fly\", \"insect\"), (\"rootworm\", \"insect\"), (\"rover\", \"insect\"), (\"saber wasp\", \"insect\"),\n",
    "            (\"sawfly\", \"insect\"), (\"scarab\", \"insect\"), (\"scorpionfly\", \"insect\"), (\"scourge\", \"insect\"), (\"scout\", \"insect\"), (\"scuttle fly\", \"insect\"), (\"silk spinner\", \"insect\"), (\"silverfish\", \"insect\"), (\"skipper butterfly\", \"insect\"), \n",
    "            (\"snout butterfly\", \"insect\"), (\"snout beetle\", \"insect\"), (\"snout moth\", \"insect\"), (\"sow bug\", \"insect\"),(\"spider mite\", \"insect\"), (\"spider wasp\", \"insect\"), (\"sphinx moth\", \"insect\"), (\"spider\", \"arachnid\"), (\"spinner\", \"insect\"),\n",
    "            (\"spittlebug\", \"insect\"), (\"spook\", \"insect\"), (\"springtail\", \"insect\"), (\"stag beetle\", \"insect\"), (\"stealer\", \"insect\"), (\"stinger\", \"insect\"), (\"stink bug\", \"insect\"), (\"stinging ant\", \"insect\"), (\"stonefly\", \"insect\"), \n",
    "            (\"strangler\", \"insect\"), (\"sucking louse\", \"insect\"), (\"sweat bee\", \"insect\"), (\"tailor\", \"insect\"), (\"tanglefoot\", \"insect\"), (\"tarantula\", \"arachnid\"), (\"tarantula hawk\", \"insect\"), (\"tick\", \"arachnid\"), (\"tiger beetle\", \"insect\"), \n",
    "            (\"tiger moth\", \"insect\"), (\"tiphiid wasp\", \"insect\"), (\"titan beetle\", \"insect\"), (\"toad bug\", \"insect\"), (\"torchbearer\", \"insect\"), (\"torpedo bug\", \"insect\"), (\"tortoise beetle\", \"insect\"), (\"trapper\", \"insect\"), \n",
    "            (\"tree cricket\", \"insect\"), (\"trilobite beetle\", \"insect\"), (\"trogonoptera\", \"insect\"), (\"twig borer\", \"insect\"), (\"vampire\", \"insect\"), (\"victorious\", \"insect\"), (\"vinegar fly\", \"insect\"), (\"vine (weevil\", \"insect\"), \n",
    "            (\"wanderer\", \"insect\"), (\"wasps\", \"insect\"), (\"weaver\", \"insect\"), (\"webworm moth\", \"insect\"), (\"weta\", \"insect\"), (\"whirligig beetle\", \"insect\"), (\"whisperer\", \"insect\"), (\"whitefly\", \"insect\"), (\"widow spider\", \"arachnid\"),\n",
    "            (\"willow fly\", \"insect\"), (\"winged ant\", \"insect\"), (\"wood wasp\", \"insect\"), (\"woodworm\", \"insect\"), (\"woolly bear\", \"insect\"), (\"worm\", \"insect\"),(\"wrestler\", \"insect\"), (\"yucca moth\", \"insect\"), (\"zebra butterfly\", \"insect\"),(\"zebra\", \"mammal\"), \n",
    "            (\"koala\", \"marsupial\"), (\"cheetah\", \"feline\"),(\"dolphin\", \"mammal\"),(\"parrot\", \"bird\"), (\"rhino\", \"mammal\"), (\"panda\", \"mammal\"), (\"kangaroo\", \"marsupial\"),(\"panther\", \"feline\"), (\"chimpanzee\", \"primate\"), (\"hippo\", \"mammal\"), (\"eagle\", \"bird\"),\n",
    "            (\"orangutan\", \"primate\"), (\"bear\", \"mammal\"), (\"owl\", \"bird\"), (\"polar bear\", \"mammal\"),(\"snake\", \"reptile\"), (\"hawk\", \"bird\"), (\"fox\", \"mammal\"), (\"turtle\", \"reptile\"), (\"swan\", \"bird\"), (\"jaguar\", \"feline\"), (\"seagull\", \"bird\"), (\"gazelle\", \"mammal\")]\n",
    "    return dataset\n",
    "    \n",
    "def produce_messages(kafka_bootstrap_servers, topic, dataset, iterations=1, empty=0, random_sample=20):\n",
    "    \"\"\"\n",
    "    Generate sample animal data and write it to a Kafka topic.\n",
    "\n",
    "    Args:\n",
    "        kafka_bootstrap_servers (str): Kafka bootstrap servers in the format \"host:port\".\n",
    "        topic (str): Kafka topic to which the data will be written.\n",
    "        iterations (int, optional): Number of iterations to write data. Defaults to 1.\n",
    "        empty (int, optional): Flag to indicate whether to write empty data. Defaults to 0.\n",
    "    \"\"\"\n",
    " \n",
    "    # Kafka Producer configuration\n",
    "    conf = {\n",
    "        'bootstrap.servers': kafka_bootstrap_servers,\n",
    "    }\n",
    "\n",
    "    # Create Kafka Producer\n",
    "    producer = Producer(conf)\n",
    "\n",
    "    try:\n",
    "        for iteration in range(iterations):\n",
    "            # Select random elements from the data list\n",
    "            selected_data = random.sample(dataset, random_sample)\n",
    "            \n",
    "            # Write data to Kafka\n",
    "            local_timezone = pytz.timezone('America/New_York')  # Set the local timezone\n",
    "            date_created = datetime.now(local_timezone).strftime('%Y-%m-%d %H:%M:%S %Z')  # Get current timestamp in the desired format\n",
    "            for name, animal_type in selected_data:\n",
    "                animal_data = {'name': name, 'type': animal_type, 'iteration': iteration + 1, 'date_created': date_created}\n",
    "                producer.produce(topic, key='Animal', value=json.dumps(animal_data))  # Eliminé .encode('utf-8')\n",
    "            # Print a message indicating that the data has been written to the Kafka topic\n",
    "            print(f\"Iteration {iteration + 1} , Data written to Kafka topic ({topic}).\")    \n",
    "            # delaying seconds for next batch\n",
    "            sleep(iteration %2 + 1)  # Fixed iteration + 1 seconds wait between iterations\n",
    "            \n",
    "        # Flush any remaining messages\n",
    "        producer.flush()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    finally:\n",
    "        # Close the producer\n",
    "        producer.flush()  # Flush any remaining messages before closing\n",
    "        producer.poll(0)  # Poll to handle any message delivery callbacks\n",
    "        del producer\n",
    "\n",
    "# Example usage:\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "topic = \"animals-topic-batch-classic-way\"\n",
    "dataset = get_dataset()\n",
    "produce_messages(kafka_bootstrap_servers=kafka_bootstrap_servers, dataset=dataset, topic=topic, iterations=12, random_sample = 27)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da53e17-dd68-442c-80aa-6a723baafea7",
   "metadata": {},
   "source": [
    "# CONSUME MESSAGES CLASIC WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9e5dd5-a233-42e7-afec-ec2a3ab466fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-17 05:44:38,810] INFO Creating topic __consumer_offsets with configuration {compression.type=producer, cleanup.policy=compact, segment.bytes=104857600} and initial partition assignment Map(23 -> ArrayBuffer(2), 32 -> ArrayBuffer(2), 41 -> ArrayBuffer(2), 17 -> ArrayBuffer(2), 8 -> ArrayBuffer(2), 35 -> ArrayBuffer(2), 44 -> ArrayBuffer(2), 26 -> ArrayBuffer(2), 11 -> ArrayBuffer(2), 29 -> ArrayBuffer(2), 38 -> ArrayBuffer(2), 47 -> ArrayBuffer(2), 20 -> ArrayBuffer(2), 2 -> ArrayBuffer(2), 5 -> ArrayBuffer(2), 14 -> ArrayBuffer(2), 46 -> ArrayBuffer(2), 49 -> ArrayBuffer(2), 40 -> ArrayBuffer(2), 13 -> ArrayBuffer(2), 4 -> ArrayBuffer(2), 22 -> ArrayBuffer(2), 31 -> ArrayBuffer(2), 16 -> ArrayBuffer(2), 7 -> ArrayBuffer(2), 43 -> ArrayBuffer(2), 25 -> ArrayBuffer(2), 34 -> ArrayBuffer(2), 10 -> ArrayBuffer(2), 37 -> ArrayBuffer(2), 1 -> ArrayBuffer(2), 19 -> ArrayBuffer(2), 28 -> ArrayBuffer(2), 45 -> ArrayBuffer(2), 27 -> ArrayBuffer(2), 36 -> ArrayBuffer(2), 18 -> ArrayBuffer(2), 9 -> ArrayBuffer(2), 21 -> ArrayBuffer(2), 48 -> ArrayBuffer(2), 3 -> ArrayBuffer(2), 12 -> ArrayBuffer(2), 30 -> ArrayBuffer(2), 39 -> ArrayBuffer(2), 15 -> ArrayBuffer(2), 42 -> ArrayBuffer(2), 24 -> ArrayBuffer(2), 6 -> ArrayBuffer(2), 33 -> ArrayBuffer(2), 0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)\n",
      "[2024-11-17 05:44:38,958] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)\n",
      "[2024-11-17 05:44:38,964] INFO [LogLoader partition=__consumer_offsets-0, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:38,965] INFO Created log for partition __consumer_offsets-0 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-0 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:38,966] INFO [Partition __consumer_offsets-0 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:38,966] INFO [Partition __consumer_offsets-0 broker=2] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:38,981] INFO [LogLoader partition=__consumer_offsets-29, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:38,982] INFO Created log for partition __consumer_offsets-29 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-29 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:38,982] INFO [Partition __consumer_offsets-29 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:38,982] INFO [Partition __consumer_offsets-29 broker=2] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:38,997] INFO [LogLoader partition=__consumer_offsets-48, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:38,998] INFO Created log for partition __consumer_offsets-48 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-48 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:38,998] INFO [Partition __consumer_offsets-48 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:38,998] INFO [Partition __consumer_offsets-48 broker=2] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,014] INFO [LogLoader partition=__consumer_offsets-10, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,015] INFO Created log for partition __consumer_offsets-10 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-10 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,015] INFO [Partition __consumer_offsets-10 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,015] INFO [Partition __consumer_offsets-10 broker=2] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,032] INFO [LogLoader partition=__consumer_offsets-45, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,033] INFO Created log for partition __consumer_offsets-45 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-45 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,033] INFO [Partition __consumer_offsets-45 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,033] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,048] INFO [LogLoader partition=__consumer_offsets-26, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,049] INFO Created log for partition __consumer_offsets-26 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-26 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,050] INFO [Partition __consumer_offsets-26 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,050] INFO [Partition __consumer_offsets-26 broker=2] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,064] INFO [LogLoader partition=__consumer_offsets-7, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,065] INFO Created log for partition __consumer_offsets-7 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-7 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,065] INFO [Partition __consumer_offsets-7 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,065] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,080] INFO [LogLoader partition=__consumer_offsets-42, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,081] INFO Created log for partition __consumer_offsets-42 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-42 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,081] INFO [Partition __consumer_offsets-42 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,081] INFO [Partition __consumer_offsets-42 broker=2] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,096] INFO [LogLoader partition=__consumer_offsets-4, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,096] INFO Created log for partition __consumer_offsets-4 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-4 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,097] INFO [Partition __consumer_offsets-4 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,097] INFO [Partition __consumer_offsets-4 broker=2] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,111] INFO [LogLoader partition=__consumer_offsets-23, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,112] INFO Created log for partition __consumer_offsets-23 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-23 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,112] INFO [Partition __consumer_offsets-23 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,112] INFO [Partition __consumer_offsets-23 broker=2] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,127] INFO [LogLoader partition=__consumer_offsets-1, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,128] INFO Created log for partition __consumer_offsets-1 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-1 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,128] INFO [Partition __consumer_offsets-1 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,128] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,143] INFO [LogLoader partition=__consumer_offsets-20, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,143] INFO Created log for partition __consumer_offsets-20 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-20 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,143] INFO [Partition __consumer_offsets-20 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,144] INFO [Partition __consumer_offsets-20 broker=2] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,159] INFO [LogLoader partition=__consumer_offsets-39, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,159] INFO Created log for partition __consumer_offsets-39 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-39 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,159] INFO [Partition __consumer_offsets-39 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,159] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,174] INFO [LogLoader partition=__consumer_offsets-17, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,175] INFO Created log for partition __consumer_offsets-17 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-17 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,175] INFO [Partition __consumer_offsets-17 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,176] INFO [Partition __consumer_offsets-17 broker=2] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,190] INFO [LogLoader partition=__consumer_offsets-36, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,191] INFO Created log for partition __consumer_offsets-36 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-36 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,191] INFO [Partition __consumer_offsets-36 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,191] INFO [Partition __consumer_offsets-36 broker=2] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,206] INFO [LogLoader partition=__consumer_offsets-14, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,206] INFO Created log for partition __consumer_offsets-14 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-14 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,206] INFO [Partition __consumer_offsets-14 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,206] INFO [Partition __consumer_offsets-14 broker=2] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,221] INFO [LogLoader partition=__consumer_offsets-33, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,222] INFO Created log for partition __consumer_offsets-33 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-33 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,222] INFO [Partition __consumer_offsets-33 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,222] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,237] INFO [LogLoader partition=__consumer_offsets-49, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,237] INFO Created log for partition __consumer_offsets-49 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-49 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,237] INFO [Partition __consumer_offsets-49 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,237] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,251] INFO [LogLoader partition=__consumer_offsets-11, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,252] INFO Created log for partition __consumer_offsets-11 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-11 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,252] INFO [Partition __consumer_offsets-11 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,252] INFO [Partition __consumer_offsets-11 broker=2] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,271] INFO [LogLoader partition=__consumer_offsets-30, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,271] INFO Created log for partition __consumer_offsets-30 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-30 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,271] INFO [Partition __consumer_offsets-30 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,272] INFO [Partition __consumer_offsets-30 broker=2] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,287] INFO [LogLoader partition=__consumer_offsets-46, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,288] INFO Created log for partition __consumer_offsets-46 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-46 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,288] INFO [Partition __consumer_offsets-46 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,288] INFO [Partition __consumer_offsets-46 broker=2] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,302] INFO [LogLoader partition=__consumer_offsets-27, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,303] INFO Created log for partition __consumer_offsets-27 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-27 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,303] INFO [Partition __consumer_offsets-27 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,303] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,318] INFO [LogLoader partition=__consumer_offsets-8, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,318] INFO Created log for partition __consumer_offsets-8 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-8 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,319] INFO [Partition __consumer_offsets-8 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,319] INFO [Partition __consumer_offsets-8 broker=2] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,336] INFO [LogLoader partition=__consumer_offsets-24, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,337] INFO Created log for partition __consumer_offsets-24 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-24 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,337] INFO [Partition __consumer_offsets-24 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,337] INFO [Partition __consumer_offsets-24 broker=2] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,370] INFO [LogLoader partition=__consumer_offsets-43, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,371] INFO Created log for partition __consumer_offsets-43 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-43 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,371] INFO [Partition __consumer_offsets-43 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,371] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,388] INFO [LogLoader partition=__consumer_offsets-5, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,389] INFO Created log for partition __consumer_offsets-5 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-5 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,389] INFO [Partition __consumer_offsets-5 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,389] INFO [Partition __consumer_offsets-5 broker=2] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,405] INFO [LogLoader partition=__consumer_offsets-21, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,405] INFO Created log for partition __consumer_offsets-21 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-21 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,406] INFO [Partition __consumer_offsets-21 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,406] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,420] INFO [LogLoader partition=__consumer_offsets-40, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,421] INFO Created log for partition __consumer_offsets-40 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-40 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,421] INFO [Partition __consumer_offsets-40 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,421] INFO [Partition __consumer_offsets-40 broker=2] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,437] INFO [LogLoader partition=__consumer_offsets-2, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,438] INFO Created log for partition __consumer_offsets-2 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-2 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,438] INFO [Partition __consumer_offsets-2 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,438] INFO [Partition __consumer_offsets-2 broker=2] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,454] INFO [LogLoader partition=__consumer_offsets-37, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,454] INFO Created log for partition __consumer_offsets-37 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-37 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,455] INFO [Partition __consumer_offsets-37 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,455] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,471] INFO [LogLoader partition=__consumer_offsets-18, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,472] INFO Created log for partition __consumer_offsets-18 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-18 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,472] INFO [Partition __consumer_offsets-18 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,472] INFO [Partition __consumer_offsets-18 broker=2] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,488] INFO [LogLoader partition=__consumer_offsets-34, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,489] INFO Created log for partition __consumer_offsets-34 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-34 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,489] INFO [Partition __consumer_offsets-34 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,489] INFO [Partition __consumer_offsets-34 broker=2] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,505] INFO [LogLoader partition=__consumer_offsets-15, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,505] INFO Created log for partition __consumer_offsets-15 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-15 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,505] INFO [Partition __consumer_offsets-15 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,506] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,520] INFO [LogLoader partition=__consumer_offsets-12, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,521] INFO Created log for partition __consumer_offsets-12 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-12 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,521] INFO [Partition __consumer_offsets-12 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,521] INFO [Partition __consumer_offsets-12 broker=2] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,537] INFO [LogLoader partition=__consumer_offsets-31, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,538] INFO Created log for partition __consumer_offsets-31 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-31 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,538] INFO [Partition __consumer_offsets-31 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,538] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,553] INFO [LogLoader partition=__consumer_offsets-9, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,554] INFO Created log for partition __consumer_offsets-9 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-9 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,554] INFO [Partition __consumer_offsets-9 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,554] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,568] INFO [LogLoader partition=__consumer_offsets-47, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,569] INFO Created log for partition __consumer_offsets-47 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-47 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,569] INFO [Partition __consumer_offsets-47 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,569] INFO [Partition __consumer_offsets-47 broker=2] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,583] INFO [LogLoader partition=__consumer_offsets-19, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,584] INFO Created log for partition __consumer_offsets-19 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-19 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,584] INFO [Partition __consumer_offsets-19 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,584] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,599] INFO [LogLoader partition=__consumer_offsets-28, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,600] INFO Created log for partition __consumer_offsets-28 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-28 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,600] INFO [Partition __consumer_offsets-28 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,600] INFO [Partition __consumer_offsets-28 broker=2] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,614] INFO [LogLoader partition=__consumer_offsets-38, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,615] INFO Created log for partition __consumer_offsets-38 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-38 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,615] INFO [Partition __consumer_offsets-38 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,615] INFO [Partition __consumer_offsets-38 broker=2] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,629] INFO [LogLoader partition=__consumer_offsets-35, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,630] INFO Created log for partition __consumer_offsets-35 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-35 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,630] INFO [Partition __consumer_offsets-35 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,630] INFO [Partition __consumer_offsets-35 broker=2] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,645] INFO [LogLoader partition=__consumer_offsets-6, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,645] INFO Created log for partition __consumer_offsets-6 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-6 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,646] INFO [Partition __consumer_offsets-6 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,646] INFO [Partition __consumer_offsets-6 broker=2] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,661] INFO [LogLoader partition=__consumer_offsets-44, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,661] INFO Created log for partition __consumer_offsets-44 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-44 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,661] INFO [Partition __consumer_offsets-44 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,661] INFO [Partition __consumer_offsets-44 broker=2] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,676] INFO [LogLoader partition=__consumer_offsets-25, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,677] INFO Created log for partition __consumer_offsets-25 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-25 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,677] INFO [Partition __consumer_offsets-25 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,677] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,692] INFO [LogLoader partition=__consumer_offsets-16, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,693] INFO Created log for partition __consumer_offsets-16 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-16 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,693] INFO [Partition __consumer_offsets-16 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,693] INFO [Partition __consumer_offsets-16 broker=2] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,707] INFO [LogLoader partition=__consumer_offsets-22, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,708] INFO Created log for partition __consumer_offsets-22 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-22 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,708] INFO [Partition __consumer_offsets-22 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,708] INFO [Partition __consumer_offsets-22 broker=2] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,722] INFO [LogLoader partition=__consumer_offsets-41, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,723] INFO Created log for partition __consumer_offsets-41 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-41 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,723] INFO [Partition __consumer_offsets-41 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,723] INFO [Partition __consumer_offsets-41 broker=2] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,737] INFO [LogLoader partition=__consumer_offsets-32, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,737] INFO Created log for partition __consumer_offsets-32 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-32 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,737] INFO [Partition __consumer_offsets-32 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,738] INFO [Partition __consumer_offsets-32 broker=2] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,752] INFO [LogLoader partition=__consumer_offsets-3, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,752] INFO Created log for partition __consumer_offsets-3 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-3 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,752] INFO [Partition __consumer_offsets-3 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,752] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,767] INFO [LogLoader partition=__consumer_offsets-13, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:44:39,768] INFO Created log for partition __consumer_offsets-13 in /usr/local/kafka/data/logs/broker_2/__consumer_offsets-13 with properties {cleanup.policy=compact, compression.type=\"producer\", segment.bytes=104857600} (kafka.log.LogManager)\n",
      "[2024-11-17 05:44:39,768] INFO [Partition __consumer_offsets-13 broker=2] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,768] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:44:39,780] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 22 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,781] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 28 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 34 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 40 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 46 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 41 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,782] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 44 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 47 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 4 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 10 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 16 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 2 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,783] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 5 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 8 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 11 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 14 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 17 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 20 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 23 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 26 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 29 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 32 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 35 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 38 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 0 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 6 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 12 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,784] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 18 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 24 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 30 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 36 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,785] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,786] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 42 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,786] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,786] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,786] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,786] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 48 in epoch 0 (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,786] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,786] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-22 in 4 milliseconds for epoch 0, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,786] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 4 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,787] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-28 in 5 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,787] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,787] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-34 in 5 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,788] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 6 milliseconds for epoch 0, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,788] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-40 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,788] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,788] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-46 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,789] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,789] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-41 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,789] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-44 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,789] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-47 in 6 milliseconds for epoch 0, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,790] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,790] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-4 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,790] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,790] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-10 in 7 milliseconds for epoch 0, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,791] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,791] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-16 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,791] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,791] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-2 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,792] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-5 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,792] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-8 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,792] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-11 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,792] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-14 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,793] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-17 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,793] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-20 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,793] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-23 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,793] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-26 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,793] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-29 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,794] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-32 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,794] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-35 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,794] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-38 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,794] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-0 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,794] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,795] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-6 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,795] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,795] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-12 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,795] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,795] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-18 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,796] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,796] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-24 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,796] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,796] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-30 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,796] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,797] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-36 in 12 milliseconds for epoch 0, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,797] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,797] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-42 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,797] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "[2024-11-17 05:44:39,797] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-48 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)\n",
      "Producer will disconnect due to inactivity in 9 Seconds.\n",
      "[2024-11-17 05:44:39,924] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group my_consumer_group in Empty state. Created a new member id rdkafka-7f346216-8c53-4bc9-bcd9-afb147a19fa9 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,936] INFO [GroupCoordinator 2]: Preparing to rebalance group my_consumer_group in state PreparingRebalance with old generation 0 (__consumer_offsets-35) (reason: Adding new member rdkafka-7f346216-8c53-4bc9-bcd9-afb147a19fa9 with group instance id None; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,943] INFO [GroupCoordinator 2]: Stabilized group my_consumer_group generation 1 (__consumer_offsets-35) with 1 members (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:44:39,953] INFO [GroupCoordinator 2]: Assignment received from leader rdkafka-7f346216-8c53-4bc9-bcd9-afb147a19fa9 for group my_consumer_group for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)\n",
      "Batch index: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"spider\", \"type\": \"arachnid\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"rootworm\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"seagull\", \"type\": \"bird\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lemur\", \"type\": \"primate\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snail\", \"type\": \"mollusk\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cobweb spider\", \"type\": \"arachnid\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"click beetle\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lion\", \"type\": \"mammal\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"grasshopper\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sea urchin\", \"type\": \"echinoderm\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafroller\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"oracle\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"humpbacked fly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"barnacle\", \"type\": \"crustacean\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crow\", \"type\": \"bird\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                       Value  \\\n",
       "0          {\"name\": \"spider\", \"type\": \"arachnid\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "1          {\"name\": \"rootworm\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "2             {\"name\": \"seagull\", \"type\": \"bird\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "3            {\"name\": \"lemur\", \"type\": \"primate\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "4            {\"name\": \"snail\", \"type\": \"mollusk\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "5   {\"name\": \"cobweb spider\", \"type\": \"arachnid\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "6      {\"name\": \"click beetle\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "7              {\"name\": \"lion\", \"type\": \"mammal\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "8       {\"name\": \"grasshopper\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "9    {\"name\": \"sea urchin\", \"type\": \"echinoderm\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "10       {\"name\": \"leafroller\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "11           {\"name\": \"oracle\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "12   {\"name\": \"humpbacked fly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "13     {\"name\": \"barnacle\", \"type\": \"crustacean\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "14               {\"name\": \"crow\", \"type\": \"bird\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0       0  2024-11-17 05:44:35  \n",
       "1   animals-topic-batch-classic-way          0       1  2024-11-17 05:44:35  \n",
       "2   animals-topic-batch-classic-way          0       2  2024-11-17 05:44:35  \n",
       "3   animals-topic-batch-classic-way          0       3  2024-11-17 05:44:35  \n",
       "4   animals-topic-batch-classic-way          0       4  2024-11-17 05:44:35  \n",
       "5   animals-topic-batch-classic-way          0       5  2024-11-17 05:44:35  \n",
       "6   animals-topic-batch-classic-way          0       6  2024-11-17 05:44:35  \n",
       "7   animals-topic-batch-classic-way          0       7  2024-11-17 05:44:35  \n",
       "8   animals-topic-batch-classic-way          0       8  2024-11-17 05:44:35  \n",
       "9   animals-topic-batch-classic-way          0       9  2024-11-17 05:44:35  \n",
       "10  animals-topic-batch-classic-way          0      10  2024-11-17 05:44:35  \n",
       "11  animals-topic-batch-classic-way          0      11  2024-11-17 05:44:35  \n",
       "12  animals-topic-batch-classic-way          0      12  2024-11-17 05:44:35  \n",
       "13  animals-topic-batch-classic-way          0      13  2024-11-17 05:44:35  \n",
       "14  animals-topic-batch-classic-way          0      14  2024-11-17 05:44:35  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 0\n",
      "\n",
      "Batch index: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"zebra butterfly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"gnat\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"jaguar\", \"type\": \"feline\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"whirligig beetle\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"vampire\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"octopus\", \"type\": \"cephalopod\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"elaters\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"thysanuran\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"digger\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"maggot\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"clam\", \"type\": \"mollusk\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2024-11-17 05:44:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"psycho fly\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"firebrat\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stinger\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                        Value  \\\n",
       "0    {\"name\": \"zebra butterfly\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "1               {\"name\": \"gnat\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "2             {\"name\": \"jaguar\", \"type\": \"feline\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "3   {\"name\": \"whirligig beetle\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "4            {\"name\": \"vampire\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "5        {\"name\": \"octopus\", \"type\": \"cephalopod\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "6            {\"name\": \"elaters\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "7         {\"name\": \"thysanuran\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "8             {\"name\": \"digger\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "9             {\"name\": \"maggot\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "10        {\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "11             {\"name\": \"clam\", \"type\": \"mollusk\", \"iteration\": 1, \"date_created\": \"2024-11-17 00:44:35 EST\"}   \n",
       "12        {\"name\": \"psycho fly\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "13          {\"name\": \"firebrat\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "14           {\"name\": \"stinger\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0      15  2024-11-17 05:44:35  \n",
       "1   animals-topic-batch-classic-way          0      16  2024-11-17 05:44:35  \n",
       "2   animals-topic-batch-classic-way          0      17  2024-11-17 05:44:35  \n",
       "3   animals-topic-batch-classic-way          0      18  2024-11-17 05:44:35  \n",
       "4   animals-topic-batch-classic-way          0      19  2024-11-17 05:44:35  \n",
       "5   animals-topic-batch-classic-way          0      20  2024-11-17 05:44:35  \n",
       "6   animals-topic-batch-classic-way          0      21  2024-11-17 05:44:35  \n",
       "7   animals-topic-batch-classic-way          0      22  2024-11-17 05:44:35  \n",
       "8   animals-topic-batch-classic-way          0      23  2024-11-17 05:44:35  \n",
       "9   animals-topic-batch-classic-way          0      24  2024-11-17 05:44:35  \n",
       "10  animals-topic-batch-classic-way          0      25  2024-11-17 05:44:35  \n",
       "11  animals-topic-batch-classic-way          0      26  2024-11-17 05:44:35  \n",
       "12  animals-topic-batch-classic-way          0      27  2024-11-17 05:44:36  \n",
       "13  animals-topic-batch-classic-way          0      28  2024-11-17 05:44:36  \n",
       "14  animals-topic-batch-classic-way          0      29  2024-11-17 05:44:36  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 1\n",
      "\n",
      "Batch index: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"robber fly\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"barnacle\", \"type\": \"crustacean\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crow\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"swan\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crab\", \"type\": \"crustacean\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hawk\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scorpion\", \"type\": \"arachnid\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"owl\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cutworm\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"vine (weevil\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stink bug\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"chewer\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"eagle\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"dolphin\", \"type\": \"mammal\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crane\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                    Value  \\\n",
       "0     {\"name\": \"robber fly\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "1   {\"name\": \"barnacle\", \"type\": \"crustacean\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "2             {\"name\": \"crow\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "3             {\"name\": \"swan\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "4       {\"name\": \"crab\", \"type\": \"crustacean\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "5             {\"name\": \"hawk\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "6     {\"name\": \"scorpion\", \"type\": \"arachnid\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "7              {\"name\": \"owl\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "8        {\"name\": \"cutworm\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "9   {\"name\": \"vine (weevil\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "10     {\"name\": \"stink bug\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "11        {\"name\": \"chewer\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "12           {\"name\": \"eagle\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "13       {\"name\": \"dolphin\", \"type\": \"mammal\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "14           {\"name\": \"crane\", \"type\": \"bird\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0      30  2024-11-17 05:44:36  \n",
       "1   animals-topic-batch-classic-way          0      31  2024-11-17 05:44:36  \n",
       "2   animals-topic-batch-classic-way          0      32  2024-11-17 05:44:36  \n",
       "3   animals-topic-batch-classic-way          0      33  2024-11-17 05:44:36  \n",
       "4   animals-topic-batch-classic-way          0      34  2024-11-17 05:44:36  \n",
       "5   animals-topic-batch-classic-way          0      35  2024-11-17 05:44:36  \n",
       "6   animals-topic-batch-classic-way          0      36  2024-11-17 05:44:36  \n",
       "7   animals-topic-batch-classic-way          0      37  2024-11-17 05:44:36  \n",
       "8   animals-topic-batch-classic-way          0      38  2024-11-17 05:44:36  \n",
       "9   animals-topic-batch-classic-way          0      39  2024-11-17 05:44:36  \n",
       "10  animals-topic-batch-classic-way          0      40  2024-11-17 05:44:36  \n",
       "11  animals-topic-batch-classic-way          0      41  2024-11-17 05:44:36  \n",
       "12  animals-topic-batch-classic-way          0      42  2024-11-17 05:44:36  \n",
       "13  animals-topic-batch-classic-way          0      43  2024-11-17 05:44:36  \n",
       "14  animals-topic-batch-classic-way          0      44  2024-11-17 05:44:36  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 2\n",
      "\n",
      "Batch index: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"bristletail\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"elaters\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafroller\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"nit\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lizard\", \"type\": \"reptile\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stinging ant\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stealer\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"humblebee\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"jaguar\", \"type\": \"feline\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>2024-11-17 05:44:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snout moth\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"strangler\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mantisfly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lacewing\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"seagull\", \"type\": \"bird\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                    Value  \\\n",
       "0    {\"name\": \"bristletail\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "1        {\"name\": \"elaters\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "2     {\"name\": \"leafroller\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "3            {\"name\": \"nit\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "4        {\"name\": \"lizard\", \"type\": \"reptile\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "5   {\"name\": \"stinging ant\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "6        {\"name\": \"stealer\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "7      {\"name\": \"humblebee\", \"type\": \"insect\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "8         {\"name\": \"jaguar\", \"type\": \"feline\", \"iteration\": 2, \"date_created\": \"2024-11-17 00:44:36 EST\"}   \n",
       "9     {\"name\": \"snout moth\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "10     {\"name\": \"strangler\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "11       {\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "12     {\"name\": \"mantisfly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "13      {\"name\": \"lacewing\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "14         {\"name\": \"seagull\", \"type\": \"bird\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0      45  2024-11-17 05:44:36  \n",
       "1   animals-topic-batch-classic-way          0      46  2024-11-17 05:44:36  \n",
       "2   animals-topic-batch-classic-way          0      47  2024-11-17 05:44:36  \n",
       "3   animals-topic-batch-classic-way          0      48  2024-11-17 05:44:36  \n",
       "4   animals-topic-batch-classic-way          0      49  2024-11-17 05:44:36  \n",
       "5   animals-topic-batch-classic-way          0      50  2024-11-17 05:44:36  \n",
       "6   animals-topic-batch-classic-way          0      51  2024-11-17 05:44:36  \n",
       "7   animals-topic-batch-classic-way          0      52  2024-11-17 05:44:36  \n",
       "8   animals-topic-batch-classic-way          0      53  2024-11-17 05:44:36  \n",
       "9   animals-topic-batch-classic-way          0      54  2024-11-17 05:44:38  \n",
       "10  animals-topic-batch-classic-way          0      55  2024-11-17 05:44:38  \n",
       "11  animals-topic-batch-classic-way          0      56  2024-11-17 05:44:38  \n",
       "12  animals-topic-batch-classic-way          0      57  2024-11-17 05:44:38  \n",
       "13  animals-topic-batch-classic-way          0      58  2024-11-17 05:44:38  \n",
       "14  animals-topic-batch-classic-way          0      59  2024-11-17 05:44:38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 3\n",
      "\n",
      "Batch index: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"aphid\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lemur\", \"type\": \"primate\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"basker\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"chameleon\", \"type\": \"reptile\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"eagle\", \"type\": \"bird\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"pupa\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"gadfly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"platypus\", \"type\": \"mammal\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafcutter\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scarab\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"blister beetle\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"termite\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beaver\", \"type\": \"mammal\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"antlion\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cuttlefish\", \"type\": \"cephalopod\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                      Value  \\\n",
       "0            {\"name\": \"aphid\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "1           {\"name\": \"lemur\", \"type\": \"primate\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "2           {\"name\": \"basker\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "3       {\"name\": \"chameleon\", \"type\": \"reptile\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "4              {\"name\": \"eagle\", \"type\": \"bird\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "5             {\"name\": \"pupa\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "6           {\"name\": \"gadfly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "7         {\"name\": \"platypus\", \"type\": \"mammal\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "8       {\"name\": \"leafcutter\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "9           {\"name\": \"scarab\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "10  {\"name\": \"blister beetle\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "11         {\"name\": \"termite\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "12          {\"name\": \"beaver\", \"type\": \"mammal\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "13         {\"name\": \"antlion\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "14  {\"name\": \"cuttlefish\", \"type\": \"cephalopod\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0      60  2024-11-17 05:44:38  \n",
       "1   animals-topic-batch-classic-way          0      61  2024-11-17 05:44:38  \n",
       "2   animals-topic-batch-classic-way          0      62  2024-11-17 05:44:38  \n",
       "3   animals-topic-batch-classic-way          0      63  2024-11-17 05:44:38  \n",
       "4   animals-topic-batch-classic-way          0      64  2024-11-17 05:44:38  \n",
       "5   animals-topic-batch-classic-way          0      65  2024-11-17 05:44:38  \n",
       "6   animals-topic-batch-classic-way          0      66  2024-11-17 05:44:38  \n",
       "7   animals-topic-batch-classic-way          0      67  2024-11-17 05:44:38  \n",
       "8   animals-topic-batch-classic-way          0      68  2024-11-17 05:44:38  \n",
       "9   animals-topic-batch-classic-way          0      69  2024-11-17 05:44:38  \n",
       "10  animals-topic-batch-classic-way          0      70  2024-11-17 05:44:38  \n",
       "11  animals-topic-batch-classic-way          0      71  2024-11-17 05:44:38  \n",
       "12  animals-topic-batch-classic-way          0      72  2024-11-17 05:44:38  \n",
       "13  animals-topic-batch-classic-way          0      73  2024-11-17 05:44:38  \n",
       "14  animals-topic-batch-classic-way          0      74  2024-11-17 05:44:38  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 4\n",
      "\n",
      "Batch index: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"starfish\", \"type\": \"echinoderm\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"robber fly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"fly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"buffalo\", \"type\": \"mammal\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"porcupine\", \"type\": \"mammal\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"millipede\", \"type\": \"arthropod\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>2024-11-17 05:44:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"vinegar fly\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"oyster\", \"type\": \"mollusk\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"springtail\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"peacock\", \"type\": \"bird\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"giraffe\", \"type\": \"mammal\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"buffalo\", \"type\": \"mammal\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"praying mantis\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"digger\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"anaconda\", \"type\": \"reptile\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                      Value  \\\n",
       "0     {\"name\": \"starfish\", \"type\": \"echinoderm\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "1       {\"name\": \"robber fly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "2              {\"name\": \"fly\", \"type\": \"insect\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "3          {\"name\": \"buffalo\", \"type\": \"mammal\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "4        {\"name\": \"porcupine\", \"type\": \"mammal\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "5     {\"name\": \"millipede\", \"type\": \"arthropod\", \"iteration\": 3, \"date_created\": \"2024-11-17 00:44:38 EST\"}   \n",
       "6      {\"name\": \"vinegar fly\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "7          {\"name\": \"oyster\", \"type\": \"mollusk\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "8       {\"name\": \"springtail\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "9            {\"name\": \"peacock\", \"type\": \"bird\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "10         {\"name\": \"giraffe\", \"type\": \"mammal\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "11         {\"name\": \"buffalo\", \"type\": \"mammal\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "12  {\"name\": \"praying mantis\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "13          {\"name\": \"digger\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "14       {\"name\": \"anaconda\", \"type\": \"reptile\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0      75  2024-11-17 05:44:38  \n",
       "1   animals-topic-batch-classic-way          0      76  2024-11-17 05:44:38  \n",
       "2   animals-topic-batch-classic-way          0      77  2024-11-17 05:44:38  \n",
       "3   animals-topic-batch-classic-way          0      78  2024-11-17 05:44:38  \n",
       "4   animals-topic-batch-classic-way          0      79  2024-11-17 05:44:38  \n",
       "5   animals-topic-batch-classic-way          0      80  2024-11-17 05:44:38  \n",
       "6   animals-topic-batch-classic-way          0      81  2024-11-17 05:44:39  \n",
       "7   animals-topic-batch-classic-way          0      82  2024-11-17 05:44:39  \n",
       "8   animals-topic-batch-classic-way          0      83  2024-11-17 05:44:39  \n",
       "9   animals-topic-batch-classic-way          0      84  2024-11-17 05:44:39  \n",
       "10  animals-topic-batch-classic-way          0      85  2024-11-17 05:44:39  \n",
       "11  animals-topic-batch-classic-way          0      86  2024-11-17 05:44:39  \n",
       "12  animals-topic-batch-classic-way          0      87  2024-11-17 05:44:39  \n",
       "13  animals-topic-batch-classic-way          0      88  2024-11-17 05:44:39  \n",
       "14  animals-topic-batch-classic-way          0      89  2024-11-17 05:44:39  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 5\n",
      "\n",
      "Batch index: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"firebrat\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"porcupine\", \"type\": \"mammal\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mole cricket\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tick\", \"type\": \"arachnid\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crow\", \"type\": \"bird\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafcutter\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"black widow\", \"type\": \"arachnid\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tarantula hawk\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tanglefoot\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"creeper\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"caterpillar\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"kangaroo\", \"type\": \"marsupial\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"flower mantis\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"orb weaver\", \"type\": \"arachnid\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                      Value  \\\n",
       "0         {\"name\": \"firebrat\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "1        {\"name\": \"porcupine\", \"type\": \"mammal\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "2     {\"name\": \"mole cricket\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "3           {\"name\": \"tick\", \"type\": \"arachnid\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "4               {\"name\": \"crow\", \"type\": \"bird\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "5       {\"name\": \"leafcutter\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "6           {\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "7    {\"name\": \"black widow\", \"type\": \"arachnid\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "8   {\"name\": \"tarantula hawk\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "9       {\"name\": \"tanglefoot\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "10         {\"name\": \"creeper\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "11     {\"name\": \"caterpillar\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "12     {\"name\": \"kangaroo\", \"type\": \"marsupial\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "13   {\"name\": \"flower mantis\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "14    {\"name\": \"orb weaver\", \"type\": \"arachnid\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0      90  2024-11-17 05:44:39  \n",
       "1   animals-topic-batch-classic-way          0      91  2024-11-17 05:44:39  \n",
       "2   animals-topic-batch-classic-way          0      92  2024-11-17 05:44:39  \n",
       "3   animals-topic-batch-classic-way          0      93  2024-11-17 05:44:39  \n",
       "4   animals-topic-batch-classic-way          0      94  2024-11-17 05:44:39  \n",
       "5   animals-topic-batch-classic-way          0      95  2024-11-17 05:44:39  \n",
       "6   animals-topic-batch-classic-way          0      96  2024-11-17 05:44:39  \n",
       "7   animals-topic-batch-classic-way          0      97  2024-11-17 05:44:39  \n",
       "8   animals-topic-batch-classic-way          0      98  2024-11-17 05:44:39  \n",
       "9   animals-topic-batch-classic-way          0      99  2024-11-17 05:44:39  \n",
       "10  animals-topic-batch-classic-way          0     100  2024-11-17 05:44:39  \n",
       "11  animals-topic-batch-classic-way          0     101  2024-11-17 05:44:39  \n",
       "12  animals-topic-batch-classic-way          0     102  2024-11-17 05:44:39  \n",
       "13  animals-topic-batch-classic-way          0     103  2024-11-17 05:44:39  \n",
       "14  animals-topic-batch-classic-way          0     104  2024-11-17 05:44:39  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 6\n",
      "\n",
      "Producer will disconnect due to inactivity in 9 Seconds.\n",
      "Batch index: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hippopotamus\", \"type\": \"mammal\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"jumper\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"riffle bug\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>2024-11-17 05:44:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"titan beetle\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"shark\", \"type\": \"fish\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scorpionfly\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cutworm\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tarantula\", \"type\": \"arachnid\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"trilobite beetle\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"aphid\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"fly\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sea cucumber\", \"type\": \"echinoderm\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"bomber\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"vulture\", \"type\": \"bird\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                        Value  \\\n",
       "0       {\"name\": \"hippopotamus\", \"type\": \"mammal\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "1             {\"name\": \"jumper\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "2         {\"name\": \"riffle bug\", \"type\": \"insect\", \"iteration\": 4, \"date_created\": \"2024-11-17 00:44:39 EST\"}   \n",
       "3       {\"name\": \"titan beetle\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "4                {\"name\": \"shark\", \"type\": \"fish\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "5        {\"name\": \"scorpionfly\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "6            {\"name\": \"cutworm\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "7        {\"name\": \"tarantula\", \"type\": \"arachnid\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "8   {\"name\": \"trilobite beetle\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "9              {\"name\": \"aphid\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "10               {\"name\": \"fly\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "11  {\"name\": \"sea cucumber\", \"type\": \"echinoderm\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "12        {\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "13            {\"name\": \"bomber\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "14             {\"name\": \"vulture\", \"type\": \"bird\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     105  2024-11-17 05:44:39  \n",
       "1   animals-topic-batch-classic-way          0     106  2024-11-17 05:44:39  \n",
       "2   animals-topic-batch-classic-way          0     107  2024-11-17 05:44:39  \n",
       "3   animals-topic-batch-classic-way          0     108  2024-11-17 05:44:41  \n",
       "4   animals-topic-batch-classic-way          0     109  2024-11-17 05:44:41  \n",
       "5   animals-topic-batch-classic-way          0     110  2024-11-17 05:44:41  \n",
       "6   animals-topic-batch-classic-way          0     111  2024-11-17 05:44:41  \n",
       "7   animals-topic-batch-classic-way          0     112  2024-11-17 05:44:41  \n",
       "8   animals-topic-batch-classic-way          0     113  2024-11-17 05:44:41  \n",
       "9   animals-topic-batch-classic-way          0     114  2024-11-17 05:44:41  \n",
       "10  animals-topic-batch-classic-way          0     115  2024-11-17 05:44:41  \n",
       "11  animals-topic-batch-classic-way          0     116  2024-11-17 05:44:41  \n",
       "12  animals-topic-batch-classic-way          0     117  2024-11-17 05:44:41  \n",
       "13  animals-topic-batch-classic-way          0     118  2024-11-17 05:44:41  \n",
       "14  animals-topic-batch-classic-way          0     119  2024-11-17 05:44:41  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 7\n",
      "\n",
      "Batch index: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cicada\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"chimp\", \"type\": \"primate\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"dor beetle\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"spider\", \"type\": \"arachnid\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"net-winged insect\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"koala\", \"type\": \"marsupial\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stinging ant\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"miner\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"parrot\", \"type\": \"bird\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"darner\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stink bug\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"pupa\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"chameleon\", \"type\": \"reptile\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tiger\", \"type\": \"feline\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"odorous ant\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>2024-11-17 05:44:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                         Value  \\\n",
       "0              {\"name\": \"cicada\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "1              {\"name\": \"chimp\", \"type\": \"primate\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "2          {\"name\": \"dor beetle\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "3            {\"name\": \"spider\", \"type\": \"arachnid\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "4   {\"name\": \"net-winged insect\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "5            {\"name\": \"koala\", \"type\": \"marsupial\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "6        {\"name\": \"stinging ant\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "7               {\"name\": \"miner\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "8                {\"name\": \"parrot\", \"type\": \"bird\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "9              {\"name\": \"darner\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "10          {\"name\": \"stink bug\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "11               {\"name\": \"pupa\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "12         {\"name\": \"chameleon\", \"type\": \"reptile\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "13              {\"name\": \"tiger\", \"type\": \"feline\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "14        {\"name\": \"odorous ant\", \"type\": \"insect\", \"iteration\": 5, \"date_created\": \"2024-11-17 00:44:41 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     120  2024-11-17 05:44:41  \n",
       "1   animals-topic-batch-classic-way          0     121  2024-11-17 05:44:41  \n",
       "2   animals-topic-batch-classic-way          0     122  2024-11-17 05:44:41  \n",
       "3   animals-topic-batch-classic-way          0     123  2024-11-17 05:44:41  \n",
       "4   animals-topic-batch-classic-way          0     124  2024-11-17 05:44:41  \n",
       "5   animals-topic-batch-classic-way          0     125  2024-11-17 05:44:41  \n",
       "6   animals-topic-batch-classic-way          0     126  2024-11-17 05:44:41  \n",
       "7   animals-topic-batch-classic-way          0     127  2024-11-17 05:44:41  \n",
       "8   animals-topic-batch-classic-way          0     128  2024-11-17 05:44:41  \n",
       "9   animals-topic-batch-classic-way          0     129  2024-11-17 05:44:41  \n",
       "10  animals-topic-batch-classic-way          0     130  2024-11-17 05:44:41  \n",
       "11  animals-topic-batch-classic-way          0     131  2024-11-17 05:44:41  \n",
       "12  animals-topic-batch-classic-way          0     132  2024-11-17 05:44:41  \n",
       "13  animals-topic-batch-classic-way          0     133  2024-11-17 05:44:41  \n",
       "14  animals-topic-batch-classic-way          0     134  2024-11-17 05:44:41  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 8\n",
      "\n",
      "Batch index: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"coyote\", \"type\": \"mammal\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"koala\", \"type\": \"marsupial\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"praying mantis\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"gadfly\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lacewing\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stag beetle\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"moth\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sweat bee\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"yucca moth\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stonefly\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scourge\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mole cricket\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"pupa\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"ranger\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tree cricket\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                      Value  \\\n",
       "0           {\"name\": \"coyote\", \"type\": \"mammal\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "1         {\"name\": \"koala\", \"type\": \"marsupial\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "2   {\"name\": \"praying mantis\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "3           {\"name\": \"gadfly\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "4         {\"name\": \"lacewing\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "5      {\"name\": \"stag beetle\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "6             {\"name\": \"moth\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "7        {\"name\": \"sweat bee\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "8       {\"name\": \"yucca moth\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "9         {\"name\": \"stonefly\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "10         {\"name\": \"scourge\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "11    {\"name\": \"mole cricket\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "12            {\"name\": \"pupa\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "13          {\"name\": \"ranger\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "14    {\"name\": \"tree cricket\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     135  2024-11-17 05:44:42  \n",
       "1   animals-topic-batch-classic-way          0     136  2024-11-17 05:44:42  \n",
       "2   animals-topic-batch-classic-way          0     137  2024-11-17 05:44:42  \n",
       "3   animals-topic-batch-classic-way          0     138  2024-11-17 05:44:42  \n",
       "4   animals-topic-batch-classic-way          0     139  2024-11-17 05:44:42  \n",
       "5   animals-topic-batch-classic-way          0     140  2024-11-17 05:44:42  \n",
       "6   animals-topic-batch-classic-way          0     141  2024-11-17 05:44:42  \n",
       "7   animals-topic-batch-classic-way          0     142  2024-11-17 05:44:42  \n",
       "8   animals-topic-batch-classic-way          0     143  2024-11-17 05:44:42  \n",
       "9   animals-topic-batch-classic-way          0     144  2024-11-17 05:44:42  \n",
       "10  animals-topic-batch-classic-way          0     145  2024-11-17 05:44:42  \n",
       "11  animals-topic-batch-classic-way          0     146  2024-11-17 05:44:42  \n",
       "12  animals-topic-batch-classic-way          0     147  2024-11-17 05:44:42  \n",
       "13  animals-topic-batch-classic-way          0     148  2024-11-17 05:44:42  \n",
       "14  animals-topic-batch-classic-way          0     149  2024-11-17 05:44:42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 9\n",
      "\n",
      "Producer will disconnect due to inactivity in 9 Seconds.\n",
      "Batch index: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sphinx moth\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"skipper butterfly\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"thrips\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sucking louse\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"firebrat\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"turtle\", \"type\": \"reptile\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"net-winged insect\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tailor\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lobster\", \"type\": \"crustacean\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snout butterfly\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"flamingo\", \"type\": \"bird\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"webspinner\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>2024-11-17 05:44:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"riffle bug\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cutworm\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"daddy longlegs\", \"type\": \"arachnid\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                         Value  \\\n",
       "0         {\"name\": \"sphinx moth\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "1   {\"name\": \"skipper butterfly\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "2              {\"name\": \"thrips\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "3       {\"name\": \"sucking louse\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "4            {\"name\": \"firebrat\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "5             {\"name\": \"turtle\", \"type\": \"reptile\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "6   {\"name\": \"net-winged insect\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "7              {\"name\": \"tailor\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "8         {\"name\": \"lobster\", \"type\": \"crustacean\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "9     {\"name\": \"snout butterfly\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "10             {\"name\": \"flamingo\", \"type\": \"bird\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "11         {\"name\": \"webspinner\", \"type\": \"insect\", \"iteration\": 6, \"date_created\": \"2024-11-17 00:44:42 EST\"}   \n",
       "12         {\"name\": \"riffle bug\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "13            {\"name\": \"cutworm\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "14   {\"name\": \"daddy longlegs\", \"type\": \"arachnid\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     150  2024-11-17 05:44:42  \n",
       "1   animals-topic-batch-classic-way          0     151  2024-11-17 05:44:42  \n",
       "2   animals-topic-batch-classic-way          0     152  2024-11-17 05:44:42  \n",
       "3   animals-topic-batch-classic-way          0     153  2024-11-17 05:44:42  \n",
       "4   animals-topic-batch-classic-way          0     154  2024-11-17 05:44:42  \n",
       "5   animals-topic-batch-classic-way          0     155  2024-11-17 05:44:42  \n",
       "6   animals-topic-batch-classic-way          0     156  2024-11-17 05:44:42  \n",
       "7   animals-topic-batch-classic-way          0     157  2024-11-17 05:44:42  \n",
       "8   animals-topic-batch-classic-way          0     158  2024-11-17 05:44:42  \n",
       "9   animals-topic-batch-classic-way          0     159  2024-11-17 05:44:42  \n",
       "10  animals-topic-batch-classic-way          0     160  2024-11-17 05:44:42  \n",
       "11  animals-topic-batch-classic-way          0     161  2024-11-17 05:44:42  \n",
       "12  animals-topic-batch-classic-way          0     162  2024-11-17 05:44:44  \n",
       "13  animals-topic-batch-classic-way          0     163  2024-11-17 05:44:44  \n",
       "14  animals-topic-batch-classic-way          0     164  2024-11-17 05:44:44  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 10\n",
      "\n",
      "Batch index: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"rootworm\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hummingbird\", \"type\": \"bird\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"whisperer\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"spider mite\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"chafers\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"silk spinner\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"termite\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scuttle fly\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"orangutan\", \"type\": \"primate\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sea star\", \"type\": \"echinoderm\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"whirligig beetle\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"wasps\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"carrier\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hunter\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hyena\", \"type\": \"mammal\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                        Value  \\\n",
       "0           {\"name\": \"rootworm\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "1          {\"name\": \"hummingbird\", \"type\": \"bird\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "2          {\"name\": \"whisperer\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "3        {\"name\": \"spider mite\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "4            {\"name\": \"chafers\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "5       {\"name\": \"silk spinner\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "6            {\"name\": \"termite\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "7        {\"name\": \"scuttle fly\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "8         {\"name\": \"orangutan\", \"type\": \"primate\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "9       {\"name\": \"sea star\", \"type\": \"echinoderm\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "10  {\"name\": \"whirligig beetle\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "11             {\"name\": \"wasps\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "12           {\"name\": \"carrier\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "13            {\"name\": \"hunter\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "14             {\"name\": \"hyena\", \"type\": \"mammal\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     165  2024-11-17 05:44:44  \n",
       "1   animals-topic-batch-classic-way          0     166  2024-11-17 05:44:44  \n",
       "2   animals-topic-batch-classic-way          0     167  2024-11-17 05:44:44  \n",
       "3   animals-topic-batch-classic-way          0     168  2024-11-17 05:44:44  \n",
       "4   animals-topic-batch-classic-way          0     169  2024-11-17 05:44:44  \n",
       "5   animals-topic-batch-classic-way          0     170  2024-11-17 05:44:44  \n",
       "6   animals-topic-batch-classic-way          0     171  2024-11-17 05:44:44  \n",
       "7   animals-topic-batch-classic-way          0     172  2024-11-17 05:44:44  \n",
       "8   animals-topic-batch-classic-way          0     173  2024-11-17 05:44:44  \n",
       "9   animals-topic-batch-classic-way          0     174  2024-11-17 05:44:44  \n",
       "10  animals-topic-batch-classic-way          0     175  2024-11-17 05:44:44  \n",
       "11  animals-topic-batch-classic-way          0     176  2024-11-17 05:44:44  \n",
       "12  animals-topic-batch-classic-way          0     177  2024-11-17 05:44:44  \n",
       "13  animals-topic-batch-classic-way          0     178  2024-11-17 05:44:44  \n",
       "14  animals-topic-batch-classic-way          0     179  2024-11-17 05:44:44  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 11\n",
      "\n",
      "Batch index: 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"ostrich\", \"type\": \"bird\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cockroach\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"emperor\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tick\", \"type\": \"arachnid\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sea lily\", \"type\": \"echinoderm\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"bristle beetle\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"dolphin\", \"type\": \"mammal\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>186</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"nautilus\", \"type\": \"cephalopod\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"widow spider\", \"type\": \"arachnid\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>2024-11-17 05:44:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"wood wasp\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"orangutan\", \"type\": \"primate\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"zebra\", \"type\": \"mammal\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"anemone\", \"type\": \"cnidarian\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"prophet\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                      Value  \\\n",
       "0            {\"name\": \"ostrich\", \"type\": \"bird\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "1        {\"name\": \"cockroach\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "2          {\"name\": \"emperor\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "3           {\"name\": \"tick\", \"type\": \"arachnid\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "4     {\"name\": \"sea lily\", \"type\": \"echinoderm\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "5   {\"name\": \"bristle beetle\", \"type\": \"insect\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "6          {\"name\": \"dolphin\", \"type\": \"mammal\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "7     {\"name\": \"nautilus\", \"type\": \"cephalopod\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "8   {\"name\": \"widow spider\", \"type\": \"arachnid\", \"iteration\": 7, \"date_created\": \"2024-11-17 00:44:44 EST\"}   \n",
       "9        {\"name\": \"wood wasp\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "10      {\"name\": \"orangutan\", \"type\": \"primate\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "11         {\"name\": \"cheetah\", \"type\": \"feline\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "12           {\"name\": \"zebra\", \"type\": \"mammal\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "13      {\"name\": \"anemone\", \"type\": \"cnidarian\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "14         {\"name\": \"prophet\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     180  2024-11-17 05:44:44  \n",
       "1   animals-topic-batch-classic-way          0     181  2024-11-17 05:44:44  \n",
       "2   animals-topic-batch-classic-way          0     182  2024-11-17 05:44:44  \n",
       "3   animals-topic-batch-classic-way          0     183  2024-11-17 05:44:44  \n",
       "4   animals-topic-batch-classic-way          0     184  2024-11-17 05:44:44  \n",
       "5   animals-topic-batch-classic-way          0     185  2024-11-17 05:44:44  \n",
       "6   animals-topic-batch-classic-way          0     186  2024-11-17 05:44:44  \n",
       "7   animals-topic-batch-classic-way          0     187  2024-11-17 05:44:44  \n",
       "8   animals-topic-batch-classic-way          0     188  2024-11-17 05:44:44  \n",
       "9   animals-topic-batch-classic-way          0     189  2024-11-17 05:44:45  \n",
       "10  animals-topic-batch-classic-way          0     190  2024-11-17 05:44:45  \n",
       "11  animals-topic-batch-classic-way          0     191  2024-11-17 05:44:45  \n",
       "12  animals-topic-batch-classic-way          0     192  2024-11-17 05:44:45  \n",
       "13  animals-topic-batch-classic-way          0     193  2024-11-17 05:44:45  \n",
       "14  animals-topic-batch-classic-way          0     194  2024-11-17 05:44:45  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 12\n",
      "\n",
      "Batch index: 13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"caterpillar\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stinger\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stink bug\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"woolly bear\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snail\", \"type\": \"mollusk\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"harvester\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"walking stick\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"willow fly\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"termite\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"toad bug\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>204</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"jaguar\", \"type\": \"feline\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>205</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"bomber\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tarantula\", \"type\": \"arachnid\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mealybug\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"miner\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                     Value  \\\n",
       "0     {\"name\": \"caterpillar\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "1         {\"name\": \"stinger\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "2       {\"name\": \"stink bug\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "3     {\"name\": \"woolly bear\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "4          {\"name\": \"snail\", \"type\": \"mollusk\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "5       {\"name\": \"harvester\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "6   {\"name\": \"walking stick\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "7      {\"name\": \"willow fly\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "8         {\"name\": \"termite\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "9        {\"name\": \"toad bug\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "10         {\"name\": \"jaguar\", \"type\": \"feline\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "11         {\"name\": \"bomber\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "12    {\"name\": \"tarantula\", \"type\": \"arachnid\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "13       {\"name\": \"mealybug\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "14          {\"name\": \"miner\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     195  2024-11-17 05:44:45  \n",
       "1   animals-topic-batch-classic-way          0     196  2024-11-17 05:44:45  \n",
       "2   animals-topic-batch-classic-way          0     197  2024-11-17 05:44:45  \n",
       "3   animals-topic-batch-classic-way          0     198  2024-11-17 05:44:45  \n",
       "4   animals-topic-batch-classic-way          0     199  2024-11-17 05:44:45  \n",
       "5   animals-topic-batch-classic-way          0     200  2024-11-17 05:44:45  \n",
       "6   animals-topic-batch-classic-way          0     201  2024-11-17 05:44:45  \n",
       "7   animals-topic-batch-classic-way          0     202  2024-11-17 05:44:45  \n",
       "8   animals-topic-batch-classic-way          0     203  2024-11-17 05:44:45  \n",
       "9   animals-topic-batch-classic-way          0     204  2024-11-17 05:44:45  \n",
       "10  animals-topic-batch-classic-way          0     205  2024-11-17 05:44:45  \n",
       "11  animals-topic-batch-classic-way          0     206  2024-11-17 05:44:45  \n",
       "12  animals-topic-batch-classic-way          0     207  2024-11-17 05:44:45  \n",
       "13  animals-topic-batch-classic-way          0     208  2024-11-17 05:44:45  \n",
       "14  animals-topic-batch-classic-way          0     209  2024-11-17 05:44:45  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 13\n",
      "\n",
      "Producer will disconnect due to inactivity in 9 Seconds.\n",
      "Batch index: 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"axolotl\", \"type\": \"amphibian\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>210</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"webspinner\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"emperor\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scorpion\", \"type\": \"arachnid\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"buffalo\", \"type\": \"mammal\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>2024-11-17 05:44:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tarantula hawk\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"net-winged insect\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"humblebee\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"oyster\", \"type\": \"mollusk\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tick\", \"type\": \"arachnid\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"thrips\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scarab\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sawfly\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"nightcrawler\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                         Value  \\\n",
       "0          {\"name\": \"axolotl\", \"type\": \"amphibian\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "1          {\"name\": \"webspinner\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "2              {\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "3             {\"name\": \"emperor\", \"type\": \"insect\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "4          {\"name\": \"scorpion\", \"type\": \"arachnid\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "5             {\"name\": \"buffalo\", \"type\": \"mammal\", \"iteration\": 8, \"date_created\": \"2024-11-17 00:44:45 EST\"}   \n",
       "6      {\"name\": \"tarantula hawk\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "7   {\"name\": \"net-winged insect\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "8           {\"name\": \"humblebee\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "9             {\"name\": \"oyster\", \"type\": \"mollusk\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "10             {\"name\": \"tick\", \"type\": \"arachnid\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "11             {\"name\": \"thrips\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "12             {\"name\": \"scarab\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "13             {\"name\": \"sawfly\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "14       {\"name\": \"nightcrawler\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     210  2024-11-17 05:44:45  \n",
       "1   animals-topic-batch-classic-way          0     211  2024-11-17 05:44:45  \n",
       "2   animals-topic-batch-classic-way          0     212  2024-11-17 05:44:45  \n",
       "3   animals-topic-batch-classic-way          0     213  2024-11-17 05:44:45  \n",
       "4   animals-topic-batch-classic-way          0     214  2024-11-17 05:44:45  \n",
       "5   animals-topic-batch-classic-way          0     215  2024-11-17 05:44:45  \n",
       "6   animals-topic-batch-classic-way          0     216  2024-11-17 05:44:47  \n",
       "7   animals-topic-batch-classic-way          0     217  2024-11-17 05:44:47  \n",
       "8   animals-topic-batch-classic-way          0     218  2024-11-17 05:44:47  \n",
       "9   animals-topic-batch-classic-way          0     219  2024-11-17 05:44:47  \n",
       "10  animals-topic-batch-classic-way          0     220  2024-11-17 05:44:47  \n",
       "11  animals-topic-batch-classic-way          0     221  2024-11-17 05:44:47  \n",
       "12  animals-topic-batch-classic-way          0     222  2024-11-17 05:44:47  \n",
       "13  animals-topic-batch-classic-way          0     223  2024-11-17 05:44:47  \n",
       "14  animals-topic-batch-classic-way          0     224  2024-11-17 05:44:47  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 14\n",
      "\n",
      "Batch index: 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"anemone\", \"type\": \"cnidarian\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hawk\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"black widow\", \"type\": \"arachnid\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hoverfly\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"swan\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>229</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"owl\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"bear\", \"type\": \"mammal\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snake\", \"type\": \"reptile\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"pillbug\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"whitefly\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"fox\", \"type\": \"mammal\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"vulture\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>236</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"flea\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"harvester\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crane\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                     Value  \\\n",
       "0      {\"name\": \"anemone\", \"type\": \"cnidarian\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "1              {\"name\": \"hawk\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "2   {\"name\": \"black widow\", \"type\": \"arachnid\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "3        {\"name\": \"hoverfly\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "4              {\"name\": \"swan\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "5               {\"name\": \"owl\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "6            {\"name\": \"bear\", \"type\": \"mammal\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "7          {\"name\": \"snake\", \"type\": \"reptile\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "8         {\"name\": \"pillbug\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "9        {\"name\": \"whitefly\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "10            {\"name\": \"fox\", \"type\": \"mammal\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "11          {\"name\": \"vulture\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "12           {\"name\": \"flea\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "13      {\"name\": \"harvester\", \"type\": \"insect\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "14            {\"name\": \"crane\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     225  2024-11-17 05:44:47  \n",
       "1   animals-topic-batch-classic-way          0     226  2024-11-17 05:44:47  \n",
       "2   animals-topic-batch-classic-way          0     227  2024-11-17 05:44:47  \n",
       "3   animals-topic-batch-classic-way          0     228  2024-11-17 05:44:47  \n",
       "4   animals-topic-batch-classic-way          0     229  2024-11-17 05:44:47  \n",
       "5   animals-topic-batch-classic-way          0     230  2024-11-17 05:44:47  \n",
       "6   animals-topic-batch-classic-way          0     231  2024-11-17 05:44:47  \n",
       "7   animals-topic-batch-classic-way          0     232  2024-11-17 05:44:47  \n",
       "8   animals-topic-batch-classic-way          0     233  2024-11-17 05:44:47  \n",
       "9   animals-topic-batch-classic-way          0     234  2024-11-17 05:44:47  \n",
       "10  animals-topic-batch-classic-way          0     235  2024-11-17 05:44:47  \n",
       "11  animals-topic-batch-classic-way          0     236  2024-11-17 05:44:47  \n",
       "12  animals-topic-batch-classic-way          0     237  2024-11-17 05:44:47  \n",
       "13  animals-topic-batch-classic-way          0     238  2024-11-17 05:44:47  \n",
       "14  animals-topic-batch-classic-way          0     239  2024-11-17 05:44:47  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 15\n",
      "\n",
      "Batch index: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"rhinoceros\", \"type\": \"mammal\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"frog\", \"type\": \"amphibian\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"seagull\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>2024-11-17 05:44:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"jaguar\", \"type\": \"feline\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>243</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lacewing\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"owl\", \"type\": \"bird\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tanglefoot\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"grasshopper\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"spittlebug\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"chewer\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"jumping spider\", \"type\": \"arachnid\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"turtle\", \"type\": \"reptile\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snake\", \"type\": \"reptile\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>252</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"octopus\", \"type\": \"cephalopod\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"armadillo\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                         Value  \\\n",
       "0          {\"name\": \"rhinoceros\", \"type\": \"mammal\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "1             {\"name\": \"frog\", \"type\": \"amphibian\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "2               {\"name\": \"seagull\", \"type\": \"bird\", \"iteration\": 9, \"date_created\": \"2024-11-17 00:44:47 EST\"}   \n",
       "3             {\"name\": \"jaguar\", \"type\": \"feline\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "4           {\"name\": \"lacewing\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "5                  {\"name\": \"owl\", \"type\": \"bird\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "6         {\"name\": \"tanglefoot\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "7        {\"name\": \"grasshopper\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "8         {\"name\": \"spittlebug\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "9             {\"name\": \"chewer\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "10  {\"name\": \"jumping spider\", \"type\": \"arachnid\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "11           {\"name\": \"turtle\", \"type\": \"reptile\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "12            {\"name\": \"snake\", \"type\": \"reptile\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "13       {\"name\": \"octopus\", \"type\": \"cephalopod\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "14         {\"name\": \"armadillo\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     240  2024-11-17 05:44:47  \n",
       "1   animals-topic-batch-classic-way          0     241  2024-11-17 05:44:47  \n",
       "2   animals-topic-batch-classic-way          0     242  2024-11-17 05:44:47  \n",
       "3   animals-topic-batch-classic-way          0     243  2024-11-17 05:44:48  \n",
       "4   animals-topic-batch-classic-way          0     244  2024-11-17 05:44:48  \n",
       "5   animals-topic-batch-classic-way          0     245  2024-11-17 05:44:48  \n",
       "6   animals-topic-batch-classic-way          0     246  2024-11-17 05:44:48  \n",
       "7   animals-topic-batch-classic-way          0     247  2024-11-17 05:44:48  \n",
       "8   animals-topic-batch-classic-way          0     248  2024-11-17 05:44:48  \n",
       "9   animals-topic-batch-classic-way          0     249  2024-11-17 05:44:48  \n",
       "10  animals-topic-batch-classic-way          0     250  2024-11-17 05:44:48  \n",
       "11  animals-topic-batch-classic-way          0     251  2024-11-17 05:44:48  \n",
       "12  animals-topic-batch-classic-way          0     252  2024-11-17 05:44:48  \n",
       "13  animals-topic-batch-classic-way          0     253  2024-11-17 05:44:48  \n",
       "14  animals-topic-batch-classic-way          0     254  2024-11-17 05:44:48  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 16\n",
      "\n",
      "Batch index: 17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mole cricket\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"walking stick\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sweat bee\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"koala\", \"type\": \"marsupial\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>258</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"vinegar fly\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>259</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stonefly\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"plankton\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>262</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"gazelle\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crow\", \"type\": \"bird\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"psychodid\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafhopper\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"grizzly bear\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>267</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"stag beetle\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"gnat\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>269</td>\n",
       "      <td>2024-11-17 05:44:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                      Value  \\\n",
       "0    {\"name\": \"mole cricket\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "1   {\"name\": \"walking stick\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "2       {\"name\": \"sweat bee\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "3        {\"name\": \"koala\", \"type\": \"marsupial\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "4     {\"name\": \"vinegar fly\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "5          {\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "6        {\"name\": \"stonefly\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "7        {\"name\": \"plankton\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "8         {\"name\": \"gazelle\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "9              {\"name\": \"crow\", \"type\": \"bird\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "10      {\"name\": \"psychodid\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "11     {\"name\": \"leafhopper\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "12   {\"name\": \"grizzly bear\", \"type\": \"mammal\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "13    {\"name\": \"stag beetle\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "14           {\"name\": \"gnat\", \"type\": \"insect\", \"iteration\": 10, \"date_created\": \"2024-11-17 00:44:48 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     255  2024-11-17 05:44:48  \n",
       "1   animals-topic-batch-classic-way          0     256  2024-11-17 05:44:48  \n",
       "2   animals-topic-batch-classic-way          0     257  2024-11-17 05:44:48  \n",
       "3   animals-topic-batch-classic-way          0     258  2024-11-17 05:44:48  \n",
       "4   animals-topic-batch-classic-way          0     259  2024-11-17 05:44:48  \n",
       "5   animals-topic-batch-classic-way          0     260  2024-11-17 05:44:48  \n",
       "6   animals-topic-batch-classic-way          0     261  2024-11-17 05:44:48  \n",
       "7   animals-topic-batch-classic-way          0     262  2024-11-17 05:44:48  \n",
       "8   animals-topic-batch-classic-way          0     263  2024-11-17 05:44:48  \n",
       "9   animals-topic-batch-classic-way          0     264  2024-11-17 05:44:48  \n",
       "10  animals-topic-batch-classic-way          0     265  2024-11-17 05:44:48  \n",
       "11  animals-topic-batch-classic-way          0     266  2024-11-17 05:44:48  \n",
       "12  animals-topic-batch-classic-way          0     267  2024-11-17 05:44:48  \n",
       "13  animals-topic-batch-classic-way          0     268  2024-11-17 05:44:48  \n",
       "14  animals-topic-batch-classic-way          0     269  2024-11-17 05:44:48  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 17\n",
      "\n",
      "Producer will disconnect due to inactivity in 9 Seconds.\n",
      "Batch index: 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"crane\", \"type\": \"bird\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scout\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lemur\", \"type\": \"primate\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mason wasp\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>273</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"zebra\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"snout butterfly\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"rhino\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"torpedo bug\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hawk\", \"type\": \"bird\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>278</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"axolotl\", \"type\": \"amphibian\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"bear\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"leafcutter\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>281</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"sloth\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>282</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"weaver\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                        Value  \\\n",
       "0               {\"name\": \"crane\", \"type\": \"bird\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "1             {\"name\": \"scout\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "2            {\"name\": \"lemur\", \"type\": \"primate\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "3        {\"name\": \"mason wasp\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "4             {\"name\": \"zebra\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "5   {\"name\": \"snout butterfly\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "6             {\"name\": \"rhino\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "7       {\"name\": \"torpedo bug\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "8                {\"name\": \"hawk\", \"type\": \"bird\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "9        {\"name\": \"axolotl\", \"type\": \"amphibian\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "10             {\"name\": \"bear\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "11       {\"name\": \"leafcutter\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "12            {\"name\": \"sloth\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "13           {\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "14           {\"name\": \"weaver\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     270  2024-11-17 05:44:50  \n",
       "1   animals-topic-batch-classic-way          0     271  2024-11-17 05:44:50  \n",
       "2   animals-topic-batch-classic-way          0     272  2024-11-17 05:44:50  \n",
       "3   animals-topic-batch-classic-way          0     273  2024-11-17 05:44:50  \n",
       "4   animals-topic-batch-classic-way          0     274  2024-11-17 05:44:50  \n",
       "5   animals-topic-batch-classic-way          0     275  2024-11-17 05:44:50  \n",
       "6   animals-topic-batch-classic-way          0     276  2024-11-17 05:44:50  \n",
       "7   animals-topic-batch-classic-way          0     277  2024-11-17 05:44:50  \n",
       "8   animals-topic-batch-classic-way          0     278  2024-11-17 05:44:50  \n",
       "9   animals-topic-batch-classic-way          0     279  2024-11-17 05:44:50  \n",
       "10  animals-topic-batch-classic-way          0     280  2024-11-17 05:44:50  \n",
       "11  animals-topic-batch-classic-way          0     281  2024-11-17 05:44:50  \n",
       "12  animals-topic-batch-classic-way          0     282  2024-11-17 05:44:50  \n",
       "13  animals-topic-batch-classic-way          0     283  2024-11-17 05:44:50  \n",
       "14  animals-topic-batch-classic-way          0     284  2024-11-17 05:44:50  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 18\n",
      "\n",
      "Batch index: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tiger beetle\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>285</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"earthworms\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hyena\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"earwig\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"shrimp\", \"type\": \"crustacean\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>289</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>290</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"odorous ant\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>291</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"anemone\", \"type\": \"cnidarian\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"shark\", \"type\": \"fish\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"platypus\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"owl\", \"type\": \"bird\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"creeper\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "      <td>2024-11-17 05:44:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lizard\", \"type\": \"reptile\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tree cricket\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                     Value  \\\n",
       "0   {\"name\": \"tiger beetle\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "1     {\"name\": \"earthworms\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "2          {\"name\": \"hyena\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "3         {\"name\": \"earwig\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "4     {\"name\": \"shrimp\", \"type\": \"crustacean\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "5         {\"name\": \"beetle\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "6    {\"name\": \"odorous ant\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "7     {\"name\": \"anemone\", \"type\": \"cnidarian\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "8            {\"name\": \"shark\", \"type\": \"fish\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "9       {\"name\": \"platypus\", \"type\": \"mammal\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "10             {\"name\": \"owl\", \"type\": \"bird\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "11       {\"name\": \"creeper\", \"type\": \"insect\", \"iteration\": 11, \"date_created\": \"2024-11-17 00:44:50 EST\"}   \n",
       "12       {\"name\": \"lizard\", \"type\": \"reptile\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "13  {\"name\": \"tree cricket\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "14    {\"name\": \"silverfish\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     285  2024-11-17 05:44:50  \n",
       "1   animals-topic-batch-classic-way          0     286  2024-11-17 05:44:50  \n",
       "2   animals-topic-batch-classic-way          0     287  2024-11-17 05:44:50  \n",
       "3   animals-topic-batch-classic-way          0     288  2024-11-17 05:44:50  \n",
       "4   animals-topic-batch-classic-way          0     289  2024-11-17 05:44:50  \n",
       "5   animals-topic-batch-classic-way          0     290  2024-11-17 05:44:50  \n",
       "6   animals-topic-batch-classic-way          0     291  2024-11-17 05:44:50  \n",
       "7   animals-topic-batch-classic-way          0     292  2024-11-17 05:44:50  \n",
       "8   animals-topic-batch-classic-way          0     293  2024-11-17 05:44:50  \n",
       "9   animals-topic-batch-classic-way          0     294  2024-11-17 05:44:50  \n",
       "10  animals-topic-batch-classic-way          0     295  2024-11-17 05:44:50  \n",
       "11  animals-topic-batch-classic-way          0     296  2024-11-17 05:44:50  \n",
       "12  animals-topic-batch-classic-way          0     297  2024-11-17 05:44:51  \n",
       "13  animals-topic-batch-classic-way          0     298  2024-11-17 05:44:51  \n",
       "14  animals-topic-batch-classic-way          0     299  2024-11-17 05:44:51  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 19\n",
      "\n",
      "Batch index: 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"whitefly\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"chameleon\", \"type\": \"reptile\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"brown recluse\", \"type\": \"arachnid\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>302</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"anaconda\", \"type\": \"reptile\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"hydra\", \"type\": \"cnidarian\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>304</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"psychodid\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"dolphin\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>306</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"tailor\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>307</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"strangler\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>308</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"zebra\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"polar bear\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>310</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"scarab\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>311</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"riffle bug\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"robber fly\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"lemur\", \"type\": \"primate\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Key  \\\n",
       "0   Animal   \n",
       "1   Animal   \n",
       "2   Animal   \n",
       "3   Animal   \n",
       "4   Animal   \n",
       "5   Animal   \n",
       "6   Animal   \n",
       "7   Animal   \n",
       "8   Animal   \n",
       "9   Animal   \n",
       "10  Animal   \n",
       "11  Animal   \n",
       "12  Animal   \n",
       "13  Animal   \n",
       "14  Animal   \n",
       "\n",
       "                                                                                                        Value  \\\n",
       "0          {\"name\": \"whitefly\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "1        {\"name\": \"chameleon\", \"type\": \"reptile\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "2   {\"name\": \"brown recluse\", \"type\": \"arachnid\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "3         {\"name\": \"anaconda\", \"type\": \"reptile\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "4          {\"name\": \"hydra\", \"type\": \"cnidarian\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "5         {\"name\": \"psychodid\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "6           {\"name\": \"dolphin\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "7            {\"name\": \"tailor\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "8         {\"name\": \"strangler\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "9             {\"name\": \"zebra\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "10       {\"name\": \"polar bear\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "11           {\"name\": \"scarab\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "12       {\"name\": \"riffle bug\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "13       {\"name\": \"robber fly\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "14           {\"name\": \"lemur\", \"type\": \"primate\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "\n",
       "                              Topic  Partition  Offset            Timestamp  \n",
       "0   animals-topic-batch-classic-way          0     300  2024-11-17 05:44:51  \n",
       "1   animals-topic-batch-classic-way          0     301  2024-11-17 05:44:51  \n",
       "2   animals-topic-batch-classic-way          0     302  2024-11-17 05:44:51  \n",
       "3   animals-topic-batch-classic-way          0     303  2024-11-17 05:44:51  \n",
       "4   animals-topic-batch-classic-way          0     304  2024-11-17 05:44:51  \n",
       "5   animals-topic-batch-classic-way          0     305  2024-11-17 05:44:51  \n",
       "6   animals-topic-batch-classic-way          0     306  2024-11-17 05:44:51  \n",
       "7   animals-topic-batch-classic-way          0     307  2024-11-17 05:44:51  \n",
       "8   animals-topic-batch-classic-way          0     308  2024-11-17 05:44:51  \n",
       "9   animals-topic-batch-classic-way          0     309  2024-11-17 05:44:51  \n",
       "10  animals-topic-batch-classic-way          0     310  2024-11-17 05:44:51  \n",
       "11  animals-topic-batch-classic-way          0     311  2024-11-17 05:44:51  \n",
       "12  animals-topic-batch-classic-way          0     312  2024-11-17 05:44:51  \n",
       "13  animals-topic-batch-classic-way          0     313  2024-11-17 05:44:51  \n",
       "14  animals-topic-batch-classic-way          0     314  2024-11-17 05:44:51  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 20\n",
      "\n",
      "Producer will disconnect due to inactivity in 9 Seconds.\n",
      "Producer will disconnect due to inactivity in 8 Seconds.\n",
      "Producer will disconnect due to inactivity in 7 Seconds.\n",
      "Producer will disconnect due to inactivity in 6 Seconds.\n",
      "Producer will disconnect due to inactivity in 5 Seconds.\n",
      "Producer will disconnect due to inactivity in 4 Seconds.\n",
      "Producer will disconnect due to inactivity in 3 Seconds.\n",
      "Producer will disconnect due to inactivity in 2 Seconds.\n",
      "Producer will disconnect due to inactivity in 1 Seconds.\n",
      "Producer will disconnect due to inactivity in 0 Seconds.\n",
      "No new messages received in the last 10 seconds. Returning the current batch.\n",
      "Batch index: 21\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Partition</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"basker\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"mealybug\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"dragonfly\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"odorous ant\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"miner\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"pillbug\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>320</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"rhinoceros\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"chafers\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>322</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"name\": \"maggot\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}</td>\n",
       "      <td>animals-topic-batch-classic-way</td>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "      <td>2024-11-17 05:44:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Key  \\\n",
       "0  Animal   \n",
       "1  Animal   \n",
       "2  Animal   \n",
       "3  Animal   \n",
       "4  Animal   \n",
       "5  Animal   \n",
       "6  Animal   \n",
       "7  Animal   \n",
       "8  Animal   \n",
       "\n",
       "                                                                                                   Value  \\\n",
       "0       {\"name\": \"basker\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "1     {\"name\": \"mealybug\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "2    {\"name\": \"dragonfly\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "3  {\"name\": \"odorous ant\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "4        {\"name\": \"miner\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "5      {\"name\": \"pillbug\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "6   {\"name\": \"rhinoceros\", \"type\": \"mammal\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "7      {\"name\": \"chafers\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "8       {\"name\": \"maggot\", \"type\": \"insect\", \"iteration\": 12, \"date_created\": \"2024-11-17 00:44:51 EST\"}   \n",
       "\n",
       "                             Topic  Partition  Offset            Timestamp  \n",
       "0  animals-topic-batch-classic-way          0     315  2024-11-17 05:44:51  \n",
       "1  animals-topic-batch-classic-way          0     316  2024-11-17 05:44:51  \n",
       "2  animals-topic-batch-classic-way          0     317  2024-11-17 05:44:51  \n",
       "3  animals-topic-batch-classic-way          0     318  2024-11-17 05:44:51  \n",
       "4  animals-topic-batch-classic-way          0     319  2024-11-17 05:44:51  \n",
       "5  animals-topic-batch-classic-way          0     320  2024-11-17 05:44:51  \n",
       "6  animals-topic-batch-classic-way          0     321  2024-11-17 05:44:51  \n",
       "7  animals-topic-batch-classic-way          0     322  2024-11-17 05:44:51  \n",
       "8  animals-topic-batch-classic-way          0     323  2024-11-17 05:44:51  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Preprocessing batch 21\n",
      "\n",
      "Producer will disconnect due to inactivity in -1 Seconds.\n",
      "No new messages received in the last 10 seconds. Returning the current batch.\n",
      "[2024-11-17 05:45:02,596] INFO [GroupCoordinator 2]: Preparing to rebalance group my_consumer_group in state PreparingRebalance with old generation 1 (__consumer_offsets-35) (reason: Removing member rdkafka-7f346216-8c53-4bc9-bcd9-afb147a19fa9 on LeaveGroup; client reason: not provided) (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:45:02,597] INFO [GroupCoordinator 2]: Group my_consumer_group with generation 2 is now empty (__consumer_offsets-35) (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:45:02,599] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=rdkafka-7f346216-8c53-4bc9-bcd9-afb147a19fa9, groupInstanceId=None, clientId=rdkafka, clientHost=/172.17.0.2, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, roundrobin)) has left group my_consumer_group through explicit `LeaveGroup`; client reason: not provided (kafka.coordinator.group.GroupCoordinator)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from math import ceil\n",
    "\n",
    "import pandas as pd\n",
    "from confluent_kafka import Consumer, KafkaError\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "\n",
    "def consume_messages(kafka_bootstrap_servers, topic, batch_size=20, timeout=10):\n",
    "    \"\"\"\n",
    "    Consume messages from a Kafka topic in batches and return them as a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        kafka_bootstrap_servers (str): Kafka bootstrap servers in the format \"host:port\".\n",
    "        topic (str): Kafka topic from which to consume messages.\n",
    "        batch_size (int): Size of each batch of messages to return as a DataFrame. Defaults to 20.\n",
    "        timeout (int): Maximum time to wait for new messages (in seconds) before returning the current batch. Defaults to 10 seconds.\n",
    "\n",
    "    Yields:\n",
    "        pandas.DataFrame: DataFrame containing the consumed batch of messages.\n",
    "\n",
    "    Raises:\n",
    "        KeyboardInterrupt: Raised when the consumer is stopped by the user (e.g., through keyboard interrupt).\n",
    "    \"\"\"\n",
    "    # Consumer configuration\n",
    "    conf = {\n",
    "        \"bootstrap.servers\": kafka_bootstrap_servers,  # Kafka bootstrap servers\n",
    "        \"group.id\": \"my_consumer_group\",  # Consumer group ID\n",
    "        \"auto.offset.reset\": \"earliest\",  # Set the starting offset to the earliest available\n",
    "    }\n",
    "\n",
    "    # Create consumer\n",
    "    consumer = Consumer(conf)\n",
    "\n",
    "    # Subscribe to the topic\n",
    "    consumer.subscribe([topic])\n",
    "\n",
    "    # List to store messages for each batch\n",
    "    messages = []\n",
    "\n",
    "    # Time tracking for timeout\n",
    "    last_message_time = time.time()\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # Wait for messages\n",
    "            msg = consumer.poll(1.0)\n",
    "\n",
    "            # Check if the timeout has been reached\n",
    "            time_limit = time.time() - last_message_time\n",
    "\n",
    "            # If no message received within the poll timeout\n",
    "            if msg is None:\n",
    "                print(\n",
    "                    f\"Producer will disconnect due to inactivity in {ceil(timeout - time_limit)} Seconds.\"\n",
    "                )\n",
    "                # If timeout exceeded, return the current batch\n",
    "                if time_limit > timeout:\n",
    "                    print(\n",
    "                        f\"No new messages received in the last {timeout} seconds. Returning the current batch.\"\n",
    "                    )\n",
    "                    if messages:\n",
    "                        # Convert the list of messages into a pandas DataFrame\n",
    "                        df = pd.DataFrame(messages)\n",
    "                        # Yield the DataFrame\n",
    "                        yield df\n",
    "                        # Clear the messages list for the next batch\n",
    "                        messages = []\n",
    "                    # If no messages received on timeout, break the loop\n",
    "                    else:\n",
    "                        break\n",
    "                continue\n",
    "\n",
    "            # Update last message time\n",
    "            last_message_time = time.time()\n",
    "\n",
    "            # Handle Kafka errors\n",
    "            if msg.error():\n",
    "                # If end of partition, continue with the next one\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    continue\n",
    "                else:\n",
    "                    # Otherwise, print the error and break the loop\n",
    "                    print(f\"Error receiving message: {msg.error()}\")\n",
    "                    break\n",
    "\n",
    "            # Decode the received value as JSON\n",
    "            try:\n",
    "                message = {\n",
    "                    \"Key\": msg.key().decode(\"utf-8\"),\n",
    "                    \"Value\": msg.value().decode(\"utf-8\"),\n",
    "                    \"Topic\": msg.topic(),\n",
    "                    \"Partition\": msg.partition(),\n",
    "                    \"Offset\": msg.offset(),\n",
    "                    \"Timestamp\": datetime.utcfromtimestamp(\n",
    "                        msg.timestamp()[1] / 1000\n",
    "                    ).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                }\n",
    "                messages.append(message)\n",
    "            except Exception as e:\n",
    "                # Print error if decoding fails\n",
    "                print(f\"Error processing message: {e}\")\n",
    "\n",
    "            # Check if the batch size has been reached\n",
    "            if len(messages) == batch_size:\n",
    "                # Convert the list of messages into a pandas DataFrame\n",
    "                df = pd.DataFrame(messages)\n",
    "                # Yield the DataFrame\n",
    "                yield df\n",
    "                # Clear the messages list for the next batch\n",
    "                messages = []\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        # If KeyboardInterrupt occurs, print message and stop the consumer\n",
    "        print(\"Stopping the consumer...\")\n",
    "\n",
    "    finally:\n",
    "        # Close the consumer\n",
    "        consumer.close()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "topic = \"animals-topic-batch-classic-way\"\n",
    "\n",
    "for index, batch_df in enumerate(\n",
    "    consume_messages(kafka_bootstrap_servers, topic, batch_size=15)\n",
    "):\n",
    "    print(f\"Batch index:\", index)\n",
    "    display(batch_df)  # Display the batch DataFrame\n",
    "    # Perform operations on the batch DataFrame\n",
    "    print(f\"End Preprocessing batch {index}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b043b562-ce26-4f1b-a291-4ef32c295555",
   "metadata": {},
   "source": [
    "# <center> SPARK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072390a7-8284-4012-a43a-54d48ea249c3",
   "metadata": {},
   "source": [
    "# ANIMALS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76f7b6c4-b8d0-44c2-b1cf-5ba74cb78a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    # Create a sample list with animal data\n",
    "    dataset = [\n",
    "        (\"lion\", \"mammal\"), (\"elephant\", \"mammal\"), (\"tiger\", \"feline\"), (\"whale\", \"mammal\"), (\"penguin\", \"bird\"), (\"gorilla\", \"primate\"), (\"leopard\", \"feline\"),\n",
    "        (\"crocodile\", \"reptile\"), (\"rhinoceros\", \"mammal\"), (\"zebra\", \"mammal\"), (\"hippopotamus\", \"mammal\"), (\"eagle\", \"bird\"), (\"orangutan\", \"primate\"),\n",
    "        (\"grizzly bear\", \"mammal\"), (\"owl\", \"bird\"), (\"polar bear\", \"mammal\"), (\"python\", \"reptile\"), (\"hawk\", \"bird\"), (\"wolf\", \"mammal\"), (\"tortoise\", \"reptile\"),\n",
    "        (\"swan\", \"bird\"), (\"cheetah\", \"feline\"), (\"seagull\", \"bird\"), (\"giraffe\", \"mammal\"), (\"deer\", \"mammal\"), (\"giraffe\", \"mammal\"), (\"lizard\", \"reptile\"),\n",
    "        (\"flamingo\", \"bird\"), (\"chimp\", \"primate\"), (\"buffalo\", \"mammal\"), (\"vulture\", \"bird\"), (\"bear\", \"mammal\"), (\"anaconda\", \"reptile\"), (\"pigeon\", \"bird\"),\n",
    "        (\"coyote\", \"mammal\"), (\"chameleon\", \"reptile\"), (\"ostrich\", \"bird\"), (\"jaguar\", \"feline\"), (\"owl\", \"bird\"), (\"beetle\", \"insect\"), (\"snail\", \"invertebrate\"),\n",
    "        (\"octopus\", \"cephalopod\"), (\"lobster\", \"crustacean\"), (\"koala\", \"marsupial\"), (\"crane\", \"bird\"), (\"iguana\", \"reptile\"), (\"lemur\", \"primate\"), (\"sloth\", \"mammal\"),\n",
    "        (\"gazelle\", \"mammal\"), (\"wombat\", \"marsupial\"), (\"hummingbird\", \"bird\"), (\"porcupine\", \"mammal\"), (\"macaw\", \"bird\"), (\"hyena\", \"mammal\"), (\"dolphin\", \"mammal\"),\n",
    "        (\"seahorse\", \"fish\"), (\"orca\", \"mammal\"), (\"kangaroo\", \"marsupial\"), (\"shark\", \"fish\"), (\"beaver\", \"mammal\"), (\"platypus\", \"mammal\"), (\"armadillo\", \"mammal\"),\n",
    "        (\"rabbit\", \"mammal\"), (\"camel\", \"mammal\"), (\"squirrel\", \"mammal\"), (\"peacock\", \"bird\"), (\"crow\", \"bird\"), (\"frog\", \"amphibian\"), (\"toad\", \"amphibian\"),\n",
    "        (\"newt\", \"amphibian\"), (\"axolotl\", \"amphibian\"), (\"butterfly\", \"insect\"), (\"dragonfly\", \"insect\"), (\"grasshopper\", \"insect\"), (\"mantis\", \"insect\"),\n",
    "        (\"beetle\", \"insect\"), (\"ant\", \"insect\"), (\"termite\", \"insect\"), (\"spider\", \"arachnid\"), (\"scorpion\", \"arachnid\"), (\"tick\", \"arachnid\"), (\"bee\", \"insect\"),\n",
    "        (\"wasp\", \"insect\"), (\"hornet\", \"insect\"), (\"fly\", \"insect\"), (\"mosquito\", \"insect\"), (\"cockroach\", \"insect\"), (\"ladybug\", \"insect\"), (\"firefly\", \"insect\"),\n",
    "        (\"millipede\", \"arthropod\"), (\"centipede\", \"arthropod\"), (\"crab\", \"crustacean\"), (\"shrimp\", \"crustacean\"), (\"barnacle\", \"crustacean\"), (\"clam\", \"mollusk\"),\n",
    "        (\"oyster\", \"mollusk\"), (\"mussel\", \"mollusk\"), (\"snail\", \"mollusk\"), (\"slug\", \"mollusk\"), (\"squid\", \"cephalopod\"), (\"cuttlefish\", \"cephalopod\"), (\"nautilus\", \"cephalopod\"),\n",
    "        (\"jellyfish\", \"cnidarian\"), (\"coral\", \"cnidarian\"), (\"hydra\", \"cnidarian\"), (\"anemone\", \"cnidarian\"), (\"sponge\", \"porifera\"), (\"sea cucumber\", \"echinoderm\"),\n",
    "        (\"starfish\", \"echinoderm\"), (\"sand dollar\", \"echinoderm\"), (\"sea urchin\", \"echinoderm\"), (\"brittle star\", \"echinoderm\"), (\"sea star\", \"echinoderm\"), (\"sea lily\", \"echinoderm\"),\n",
    "        (\"feather star\", \"echinoderm\"), (\"black widow\", \"arachnid\"), (\"brown recluse\", \"arachnid\"), (\"tarantula\", \"arachnid\"), (\"daddy longlegs\", \"arachnid\"),\n",
    "        (\"wolf spider\", \"arachnid\"), (\"jumping spider\", \"arachnid\"), (\"huntsman spider\", \"arachnid\"), (\"tarantula hawk\", \"insect\"), (\"assassin bug\", \"insect\"),\n",
    "        (\"lacewing\", \"insect\"), (\"stink bug\", \"insect\"), (\"cicada\", \"insect\"), (\"walking stick\", \"insect\"), (\"scorpionfly\", \"insect\"), (\"flower mantis\", \"insect\"),\n",
    "        (\"praying mantis\", \"insect\"), (\"earwig\", \"insect\"), (\"flea\", \"insect\"), (\"leaf insect\", \"insect\"), (\"planthopper\", \"insect\"), (\"scale insect\", \"insect\"),\n",
    "        (\"aphid\", \"insect\"), (\"mealybug\", \"insect\"), (\"thrips\", \"insect\"), (\"whitefly\", \"insect\"), (\"beetle\", \"insect\"), (\"antlion\", \"insect\"), (\"snakefly\", \"insect\"),\n",
    "        (\"dobsonfly\", \"insect\"), (\"webspinner\", \"insect\"), (\"mayfly\", \"insect\"), (\"stonefly\", \"insect\"), (\"silverfish\", \"insect\"), (\"firebrat\", \"insect\"),\n",
    "        (\"bristletail\", \"insect\"), (\"thysanuran\", \"insect\"), (\"dragonfly\", \"insect\"), (\"damselfly\", \"insect\"), (\"bluet\", \"insect\"), (\"darner\", \"insect\"),\n",
    "        (\"adder\", \"insect\"), (\"basker\", \"insect\"), (\"biter\", \"insect\"), (\"blister beetle\", \"insect\"), (\"bomber\", \"insect\"), (\"bristle beetle\", \"insect\"),\n",
    "        (\"burrower\", \"insect\"), (\"carrier\", \"insect\"), (\"caterpillar\", \"insect\"), (\"chafers\", \"insect\"), (\"chewer\", \"insect\"), (\"click beetle\", \"insect\"),\n",
    "        (\"cobblers\", \"insect\"), (\"cobweb spider\", \"arachnid\"), (\"cockroaches\", \"insect\"), (\"coil worm\", \"insect\"), (\"creeper\", \"insect\"), (\"cuckoo wasp\", \"insect\"),\n",
    "        (\"cutworm\", \"insect\"), (\"digger\", \"insect\"), (\"dor beetle\", \"insect\"), (\"earthworms\", \"insect\"), (\"eggfly\", \"insect\"), (\"elaters\", \"insect\"),\n",
    "        (\"emperor\", \"insect\"), (\"gadfly\", \"insect\"), (\"gnat\", \"insect\"), (\"grasshopper\", \"insect\"), (\"grazer\", \"insect\"), (\"ground beetle\", \"insect\"),\n",
    "        (\"harvester\", \"insect\"), (\"hornet\", \"insect\"), (\"hornworm\", \"insect\"), (\"humblebee\", \"insect\"), (\"humpbacked fly\", \"insect\"), (\"hoverfly\", \"insect\"),\n",
    "        (\"hunter\", \"insect\"), (\"jumper\", \"insect\"), (\"katydid\", \"insect\"), (\"lacewing\", \"insect\"), (\"leafcutter\", \"insect\"), (\"leafhopper\", \"insect\"),\n",
    "        (\"leafroller\", \"insect\"), (\"louse\", \"insect\"), (\"maggot\", \"insect\"), (\"mantisfly\", \"insect\"), (\"marsh fly\", \"insect\"), (\"marsh beetle\", \"insect\"),\n",
    "        (\"mason wasp\", \"insect\"), (\"mealybug\", \"insect\"), (\"miner\", \"insect\"), (\"mite\", \"insect\"), (\"mole cricket\", \"insect\"), (\"moth\", \"insect\"),\n",
    "        (\"nemesis\", \"insect\"), (\"net-winged insect\", \"insect\"), (\"nightcrawler\", \"insect\"), (\"nit\", \"insect\"), (\"nymph\", \"insect\"), (\"odorous ant\", \"insect\"),\n",
    "        (\"oracle\", \"insect\"), (\"orb weaver\", \"arachnid\"), (\"orcus\", \"insect\"), (\"ostracod\", \"insect\"), (\"outlaw\", \"insect\"), (\"peacock butterfly\", \"insect\"),\n",
    "        (\"pharaoh ant\", \"insect\"), (\"pillbug\", \"insect\"), (\"plankton\", \"insect\"), (\"pollinator\", \"insect\"), (\"potter wasp\", \"insect\"), (\"praying mantis\", \"insect\"),\n",
    "        (\"predator\", \"insect\"), (\"proboscis\", \"insect\"), (\"prophet\", \"insect\"), (\"pruner\", \"insect\"), (\"pseudoscorpion\", \"arachnid\"), (\"psycho\", \"insect\"),\n",
    "        (\"psycho fly\", \"insect\"), (\"psychodid\", \"insect\"), (\"pupa\", \"insect\"), (\"purple martin\", \"insect\"), (\"putter\", \"insect\"), (\"ranger\", \"insect\"),\n",
    "        (\"recluse\", \"insect\"), (\"reducer\", \"insect\"), (\"repeater\", \"insect\"), (\"riffle bug\", \"insect\"), (\"robber fly\", \"insect\"), (\"rootworm\", \"insect\"),\n",
    "        (\"rover\", \"insect\"), (\"saber wasp\", \"insect\"), (\"sawfly\", \"insect\"), (\"scarab\", \"insect\"), (\"scorpionfly\", \"insect\"), (\"scourge\", \"insect\"),\n",
    "        (\"scout\", \"insect\"), (\"scuttle fly\", \"insect\"), (\"silk spinner\", \"insect\"), (\"silverfish\", \"insect\"), (\"skipper butterfly\", \"insect\"), (\"snout butterfly\", \"insect\"),\n",
    "        (\"snout beetle\", \"insect\"), (\"snout moth\", \"insect\"), (\"sow bug\", \"insect\"), (\"spider mite\", \"insect\"), (\"spider wasp\", \"insect\"), (\"sphinx moth\", \"insect\"),\n",
    "        (\"spider\", \"arachnid\"), (\"spinner\", \"insect\"), (\"spittlebug\", \"insect\"), (\"spook\", \"insect\"), (\"springtail\", \"insect\"), (\"stag beetle\", \"insect\"),\n",
    "        (\"stealer\", \"insect\"), (\"stinger\", \"insect\"), (\"stink bug\", \"insect\"), (\"stinging ant\", \"insect\"), (\"stonefly\", \"insect\"), (\"strangler\", \"insect\"),\n",
    "        (\"sucking louse\", \"insect\"), (\"sweat bee\", \"insect\"), (\"tailor\", \"insect\"), (\"tanglefoot\", \"insect\"), (\"tarantula\", \"arachnid\"), (\"tarantula hawk\", \"insect\"),\n",
    "        (\"tick\", \"arachnid\"), (\"tiger beetle\", \"insect\"), (\"tiger moth\", \"insect\"), (\"tiphiid wasp\", \"insect\"), (\"titan beetle\", \"insect\"), (\"toad bug\", \"insect\"),\n",
    "        (\"torchbearer\", \"insect\"), (\"torpedo bug\", \"insect\"), (\"tortoise beetle\", \"insect\"), (\"trapper\", \"insect\"), (\"tree cricket\", \"insect\"), (\"trilobite beetle\", \"insect\"),\n",
    "        (\"trogonoptera\", \"insect\"), (\"twig borer\", \"insect\"), (\"vampire\", \"insect\"), (\"victorious\", \"insect\"), (\"vinegar fly\", \"insect\"), (\"vine (weevil\", \"insect\"),\n",
    "        (\"wanderer\", \"insect\"), (\"wasps\", \"insect\"), (\"weaver\", \"insect\"), (\"webworm moth\", \"insect\"), (\"weta\", \"insect\"), (\"whirligig beetle\", \"insect\"),\n",
    "        (\"whisperer\", \"insect\"), (\"whitefly\", \"insect\"), (\"widow spider\", \"arachnid\"), (\"willow fly\", \"insect\"), (\"winged ant\", \"insect\"), (\"wood wasp\", \"insect\"),\n",
    "        (\"woodworm\", \"insect\"), (\"woolly bear\", \"insect\"), (\"worm\", \"insect\"), (\"wrestler\", \"insect\"), (\"yucca moth\", \"insect\"), (\"zebra butterfly\", \"insect\"),\n",
    "        (\"zebra\", \"mammal\"), (\"koala\", \"marsupial\"), (\"cheetah\", \"feline\"), (\"dolphin\", \"mammal\"), (\"parrot\", \"bird\"), (\"rhino\", \"mammal\"), (\"panda\", \"mammal\"),\n",
    "        (\"kangaroo\", \"marsupial\"), (\"panther\", \"feline\"), (\"chimpanzee\", \"primate\"), (\"hippo\", \"mammal\"), (\"eagle\", \"bird\"), (\"orangutan\", \"primate\"),\n",
    "        (\"bear\", \"mammal\"), (\"owl\", \"bird\"), (\"polar bear\", \"mammal\"), (\"snake\", \"reptile\"), (\"hawk\", \"bird\"), (\"fox\", \"mammal\"), (\"turtle\", \"reptile\"),\n",
    "        (\"swan\", \"bird\"), (\"jaguar\", \"feline\"), (\"seagull\", \"bird\"), (\"gazelle\", \"mammal\"),\n",
    "    ]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cfb762-517f-4751-9d95-470531a78e84",
   "metadata": {},
   "source": [
    "# DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9cf8395-7cce-4af4-8f47-4aa0e30f4cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 05:45:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/17 05:45:28 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "# Directory where JARs are located\n",
    "jars_directory = \"/usr/local/spark/jars/\"\n",
    "\n",
    "# List of JAR filenames\n",
    "jar_files = [\n",
    "    \"commons-pool2-2.12.0.jar\",\n",
    "    \"kafka-clients-3.9.0.jar\",\n",
    "    \"spark-sql-kafka-0-10_2.12-3.5.3.jar\",\n",
    "    \"spark-token-provider-kafka-0-10_2.12-3.5.3.jar\",\n",
    "]\n",
    "\n",
    "dependencies = \",\".join([os.path.join(jars_directory, jar) for jar in jar_files])\n",
    "\n",
    "# Configure Kafka connection\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "topic = \"animals-topic-batch\"\n",
    "\n",
    "# Create Spark session and add JARs\n",
    "spark_session = (\n",
    "    SparkSession.builder.appName(\"WriteKafkaAnimals\")\n",
    "    .config(\"spark.jars\", dependencies)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e05947-be49-4ba6-a986-3f20fe11babe",
   "metadata": {},
   "source": [
    "# BATCH WRITING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56f14306-a6e2-48c6-8fe8-7926efd1ff2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                        (0 + 16) / 16]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-17 05:45:33,278] INFO Creating topic animals-topic-batch with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(2)) (kafka.zk.AdminZkClient)\n",
      "[2024-11-17 05:45:33,307] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(animals-topic-batch-0) (kafka.server.ReplicaFetcherManager)\n",
      "[2024-11-17 05:45:33,311] INFO [LogLoader partition=animals-topic-batch-0, dir=/usr/local/kafka/data/logs/broker_2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)\n",
      "[2024-11-17 05:45:33,311] INFO Created log for partition animals-topic-batch-0 in /usr/local/kafka/data/logs/broker_2/animals-topic-batch-0 with properties {} (kafka.log.LogManager)\n",
      "[2024-11-17 05:45:33,312] INFO [Partition animals-topic-batch-0 broker=2] No checkpointed highwatermark is found for partition animals-topic-batch-0 (kafka.cluster.Partition)\n",
      "[2024-11-17 05:45:33,313] INFO [Partition animals-topic-batch-0 broker=2] Log loaded for partition animals-topic-batch-0 with initial high watermark 0 (kafka.cluster.Partition)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 05:45:33 WARN NetworkClient: [Producer clientId=producer-1] The metadata response from the cluster reported a recoverable issue with correlation id 1 : {animals-topic-batch=LEADER_NOT_AVAILABLE}\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 , Data written to Kafka topic (animals-topic-batch).\n",
      "Iteration 2 , Data written to Kafka topic (animals-topic-batch).\n",
      "Iteration 3 , Data written to Kafka topic (animals-topic-batch).\n",
      "Iteration 4 , Data written to Kafka topic (animals-topic-batch).\n",
      "Iteration 5 , Data written to Kafka topic (animals-topic-batch).\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "\n",
    "import pytz\n",
    "\n",
    "\n",
    "# Function to save batch data to a Kafka topic\n",
    "def save_batch_data(\n",
    "    spark_session,\n",
    "    kafka_bootstrap_servers,\n",
    "    dataset,\n",
    "    topic,\n",
    "    iterations=1,\n",
    "    empty=0,\n",
    "    random_sample=20,\n",
    "):\n",
    "    \"\"\"\n",
    "    Save batch data to a Kafka topic.\n",
    "\n",
    "    Args:\n",
    "        spark_session (SparkSession): Spark session object.\n",
    "        kafka_bootstrap_servers (str): Kafka bootstrap servers in the format \"host:port\".\n",
    "        dataset (list): List of tuples containing data to be written to Kafka.\n",
    "        topic (str): Kafka topic to which the data will be written.\n",
    "        iterations (int, optional): Number of iterations to run. Defaults to 1.\n",
    "        empty (int, optional): Placeholder for future use. Defaults to 0.\n",
    "        random_sample (int, optional): Number of random samples to select from the dataset for each iteration. Defaults to 20.\n",
    "    \"\"\"\n",
    "    # Define the columns for the DataFrame\n",
    "    columns = [\"topic_name\", \"name\", \"animal_type\", \"iteration\", \"date_created\"]\n",
    "\n",
    "    # Iterate through the specified number of iterations\n",
    "    for iteration in range(iterations):\n",
    "        # Select random elements from the dataset\n",
    "        selected_data = random.sample(dataset, random_sample)\n",
    "\n",
    "        # Write data to Kafka\n",
    "        local_timezone = pytz.timezone(\"America/New_York\")  # Set the local timezone\n",
    "        date_created = datetime.now(local_timezone).strftime(\n",
    "            \"%Y-%m-%d %H:%M:%S %Z\"\n",
    "        )  # Get the current timestamp in the desired format\n",
    "\n",
    "        values = list()\n",
    "\n",
    "        # Create a list of tuples with animal data and other metadata\n",
    "        for name, animal_type in selected_data:\n",
    "            animal_data = (\"Animal\", name, animal_type, iteration + 1, date_created)\n",
    "            values.append(animal_data)\n",
    "\n",
    "        # Create a Spark DataFrame from the values and columns\n",
    "        df_animals = spark_session.createDataFrame(values, columns)\n",
    "\n",
    "        # Write the DataFrame to the Kafka topic\n",
    "        df_animals.selectExpr(\n",
    "            \"topic_name as key\",\n",
    "            \"to_json(struct(name, animal_type, iteration, date_created)) as value\",\n",
    "        ).write.format(\"kafka\").option(\n",
    "            \"kafka.bootstrap.servers\", kafka_bootstrap_servers\n",
    "        ).option(\n",
    "            \"topic\", topic\n",
    "        ).save()\n",
    "\n",
    "        # Print a message indicating that the data has been written to the Kafka topic\n",
    "        print(f\"Iteration {iteration + 1} , Data written to Kafka topic ({topic}).\")\n",
    "\n",
    "\n",
    "# Configure Kafka connection\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "topic = \"animals-topic-batch\"\n",
    "dataset = get_dataset()\n",
    "save_batch_data(\n",
    "    spark_session=spark_session,\n",
    "    kafka_bootstrap_servers=kafka_bootstrap_servers,\n",
    "    dataset=dataset,\n",
    "    topic=topic,\n",
    "    iterations=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18600232-19bf-42b8-a191-a096ba535b08",
   "metadata": {},
   "source": [
    "# BATCH READING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc3e9cb-e24c-4366-a0da-27cb057aba45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]24/11/17 05:45:37 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------------------------------------------------------------------------------------+-------------------+---------+------+-----------------------+-------------+\n",
      "|key   |value                                                                                                    |topic              |partition|offset|timestamp              |timestampType|\n",
      "+------+---------------------------------------------------------------------------------------------------------+-------------------+---------+------+-----------------------+-------------+\n",
      "|Animal|{\"name\":\"owl\",\"animal_type\":\"bird\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}               |animals-topic-batch|0        |0     |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"maggot\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}          |animals-topic-batch|0        |1     |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"nit\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}             |animals-topic-batch|0        |2     |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"hawk\",\"animal_type\":\"bird\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}              |animals-topic-batch|0        |3     |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"scarab\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}          |animals-topic-batch|0        |4     |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"whirligig beetle\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}|animals-topic-batch|0        |5     |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"mantis\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}          |animals-topic-batch|0        |6     |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"earwig\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}          |animals-topic-batch|0        |7     |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"blister beetle\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}  |animals-topic-batch|0        |8     |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"silverfish\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}      |animals-topic-batch|0        |9     |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"hydra\",\"animal_type\":\"cnidarian\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}        |animals-topic-batch|0        |10    |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"toad\",\"animal_type\":\"amphibian\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}         |animals-topic-batch|0        |11    |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"grazer\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}          |animals-topic-batch|0        |12    |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"hippo\",\"animal_type\":\"mammal\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}           |animals-topic-batch|0        |13    |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"lion\",\"animal_type\":\"mammal\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}            |animals-topic-batch|0        |14    |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"tiger moth\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}      |animals-topic-batch|0        |15    |2024-11-17 05:45:33.412|0            |\n",
      "|Animal|{\"name\":\"rhinoceros\",\"animal_type\":\"mammal\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}      |animals-topic-batch|0        |16    |2024-11-17 05:45:33.428|0            |\n",
      "|Animal|{\"name\":\"rhino\",\"animal_type\":\"mammal\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}           |animals-topic-batch|0        |17    |2024-11-17 05:45:33.429|0            |\n",
      "|Animal|{\"name\":\"sow bug\",\"animal_type\":\"insect\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}         |animals-topic-batch|0        |18    |2024-11-17 05:45:33.429|0            |\n",
      "|Animal|{\"name\":\"bear\",\"animal_type\":\"mammal\",\"iteration\":1,\"date_created\":\"2024-11-17 00:45:29 EST\"}            |animals-topic-batch|0        |19    |2024-11-17 05:45:33.425|0            |\n",
      "+------+---------------------------------------------------------------------------------------------------------+-------------------+---------+------+-----------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "24/11/17 05:45:38 WARN KafkaDataConsumer: KafkaDataConsumer is not running in UninterruptibleThread. It may hang when KafkaDataConsumer's methods are interrupted because of KAFKA-1894\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "\n",
    "# Define the hexadecimal decoding function\n",
    "@udf(returnType=StringType())\n",
    "def decode_hex(value):\n",
    "    try:\n",
    "        if isinstance(value, str):\n",
    "            return bytes.fromhex(value).decode(\"utf-8\")\n",
    "        elif isinstance(value, bytearray):\n",
    "            return bytes(value).decode(\"utf-8\")\n",
    "        else:\n",
    "            return str(value)\n",
    "    except (ValueError, UnicodeDecodeError):\n",
    "        return str(value)\n",
    "\n",
    "\n",
    "def read_batch_data(spark_session, kafka_bootstrap_servers, topic):\n",
    "\n",
    "    # Try to read data from Kafka\n",
    "    try:\n",
    "        # Read data from Kafka\n",
    "        df_kafka = (\n",
    "            spark_session.read.format(\"kafka\")\n",
    "            .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers)\n",
    "            .option(\"subscribe\", topic)\n",
    "            .load()\n",
    "        )\n",
    "\n",
    "        # Decode hexadecimal values\n",
    "        df_decoded = df_kafka.withColumn(\"key\", decode_hex(\"key\")).withColumn(\n",
    "            \"value\", decode_hex(\"value\")\n",
    "        )\n",
    "\n",
    "        # Show the DataFrame with decoded data\n",
    "        df_decoded.show(truncate=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        if \"UnknownTopicOrPartitionException\" in str(e):\n",
    "            print(f\"The topic '{topic}' does not exist in the Kafka cluster.\")\n",
    "        else:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    finally:\n",
    "        # Stop the Spark session\n",
    "        None\n",
    "\n",
    "\n",
    "topic = \"animals-topic-batch\"\n",
    "read_batch_data(spark_session, kafka_bootstrap_servers, topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a48a04-8cb8-460b-b9dd-d1b1e601dff6",
   "metadata": {},
   "source": [
    "# STREAMING WRITING\n",
    "## MASSIVE DATA INSERTION TO KAFKA FOR STREAMING READ\n",
    "### COPY, PASTE, AND RUN THE FOLLOWING CODE IN ANOTHER NOTEBOOK TO OBSERVE STREAMING REDIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c759bab-bb0c-4279-8602-b24a5a6281c6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```python\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from time import sleep\n",
    "\n",
    "# Directory where JARs are located\n",
    "jars_directory = \"/usr/local/spark/jars/\"\n",
    "\n",
    "# List of JAR filenames\n",
    "jar_files = [\n",
    "    \"commons-pool2-2.12.0.jar\",\n",
    "    \"kafka-clients-3.9.0.jar\",\n",
    "    \"spark-sql-kafka-0-10_2.12-3.5.3.jar\",\n",
    "    \"spark-token-provider-kafka-0-10_2.12-3.5.3.jar\"\n",
    "]\n",
    "\n",
    "dependencies = \",\".join([os.path.join(jars_directory, jar) for jar in jar_files])\n",
    "\n",
    "# Configure Kafka connection\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "topic = \"animals-topic-batch\"\n",
    "\n",
    "\n",
    "# Create Spark session and add JARs\n",
    "spark_session = SparkSession.builder \\\n",
    "    .appName(\"WriteKafkaAnimals\") \\\n",
    "    .config(\"spark.jars\", dependencies) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "def save_batch_data(spark_session, kafka_bootstrap_servers, topic, iterations=1):\n",
    "\n",
    "    # Create a sample DataFrame with animal data\n",
    "    data = [(\"zebra\", \"mammal\"), (\"koala\", \"marsupial\"), (\"cheetah\", \"feline\"),(\"dolphin\", \"mammal\"),\n",
    "            (\"parrot\", \"bird\"), (\"rhino\", \"mammal\"), (\"panda\", \"mammal\"), (\"kangaroo\", \"marsupial\"), \n",
    "            (\"panther\", \"feline\"), (\"chimpanzee\", \"primate\"), (\"hippo\", \"mammal\"), (\"eagle\", \"bird\"), \n",
    "            (\"orangutan\", \"primate\"), (\"bear\", \"mammal\"), (\"owl\", \"bird\"), (\"polar bear\", \"mammal\"), \n",
    "            (\"snake\", \"reptile\"), (\"hawk\", \"bird\"), (\"fox\", \"mammal\"), (\"turtle\", \"reptile\"), \n",
    "            (\"swan\", \"bird\"), (\"jaguar\", \"feline\"), (\"seagull\", \"bird\"), (\"gazelle\", \"mammal\")]\n",
    "    \n",
    "    columns = [\"name\", \"type\"]\n",
    "    \n",
    "    df_animals = spark_session.createDataFrame(data, columns)\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        sleep(0.2)\n",
    "        # Write the DataFrame to Kafka topic\n",
    "        df_animals.selectExpr(\"name as key\", \"type as value\") \\\n",
    "            .write \\\n",
    "            .format(\"kafka\") \\\n",
    "            .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "            .option(\"topic\", topic) \\\n",
    "            .save()\n",
    "        print (f'Iteration {iteration}, completed!!!')\n",
    "    \n",
    "    # Print a message indicating that the data has been written to the Kafka topic\n",
    "    print(f\"{iterations} Iterations, Data written to Kafka topic ({topic}).\")\n",
    "\n",
    "     # Finally, stop the Spark session\n",
    "    spark_session.stop()\n",
    "\n",
    "save_batch_data(spark_session, kafka_bootstrap_servers, topic, iterations=13)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3268fa8-9fa5-49d3-87fd-d7db3c28bf07",
   "metadata": {},
   "source": [
    "# STREAMING READING\n",
    "## IT WILL BE LISTENING TO THE \"animals-topic-batch\" TOPIC\n",
    "## WHEN NEW DATA ARRIVES, IT READS AND STORES THEM IN THE \"animals-topic-streaming\" TOPIC\n",
    "## MAKE THE TRANSFORMATIONS\n",
    "### UPPER CASE, PROCCESS ROW BY ROW, USE UDF FUNCTION AND SEND PARAMETERS, CREATE PANDAS DATAFRAME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a09ea76d-2f8b-4917-afe6-214f1da52d1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 05:46:02 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "24/11/17 05:46:02 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "24/11/17 05:46:02 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "24/11/17 05:46:02 WARN StreamingQueryManager: Stopping existing streaming query [id=201229ec-a37a-4ee3-b813-f461ddab352b, runId=4abd1707-863a-4b9a-bf11-36e2a449a5a9], as a new run is being started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kafkaStream <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "transformedStream <class 'pyspark.sql.dataframe.DataFrame'>\n",
      "query <class 'pyspark.sql.streaming.query.StreamingQuery'>\n",
      "Batch ID : 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"OWL\",\"ANIMAL_TYPE\":\"BIRD\",\"ITERATION\":1,\"DATE_CREATED\":\"2024-11-17 00:45:29 EST\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"MAGGOT\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":1,\"DATE_CREATED\":\"2024-11-17 00:45:29 EST\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"NIT\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":1,\"DATE_CREATED\":\"2024-11-17 00:45:29 EST\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"HAWK\",\"ANIMAL_TYPE\":\"BIRD\",\"ITERATION\":1,\"DATE_CREATED\":\"2024-11-17 00:45:29 EST\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Animal</td>\n",
       "      <td>{\"NAME\":\"SCARAB\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":1,\"DATE_CREATED\":\"2024-11-17 00:45:29 EST\"}</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>turtle</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>swan</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>gazelle</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>hippo</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>eagle</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         key  \\\n",
       "0     Animal   \n",
       "1     Animal   \n",
       "2     Animal   \n",
       "3     Animal   \n",
       "4     Animal   \n",
       "..       ...   \n",
       "143   turtle   \n",
       "144     swan   \n",
       "145  gazelle   \n",
       "146    hippo   \n",
       "147    eagle   \n",
       "\n",
       "                                                                                               value  \\\n",
       "0         {\"NAME\":\"OWL\",\"ANIMAL_TYPE\":\"BIRD\",\"ITERATION\":1,\"DATE_CREATED\":\"2024-11-17 00:45:29 EST\"}   \n",
       "1    {\"NAME\":\"MAGGOT\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":1,\"DATE_CREATED\":\"2024-11-17 00:45:29 EST\"}   \n",
       "2       {\"NAME\":\"NIT\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":1,\"DATE_CREATED\":\"2024-11-17 00:45:29 EST\"}   \n",
       "3        {\"NAME\":\"HAWK\",\"ANIMAL_TYPE\":\"BIRD\",\"ITERATION\":1,\"DATE_CREATED\":\"2024-11-17 00:45:29 EST\"}   \n",
       "4    {\"NAME\":\"SCARAB\",\"ANIMAL_TYPE\":\"INSECT\",\"ITERATION\":1,\"DATE_CREATED\":\"2024-11-17 00:45:29 EST\"}   \n",
       "..                                                                                               ...   \n",
       "143                                                                                          REPTILE   \n",
       "144                                                                                             BIRD   \n",
       "145                                                                                           MAMMAL   \n",
       "146                                                                                           MAMMAL   \n",
       "147                                                                                             BIRD   \n",
       "\n",
       "             input_topic             output_topic  \\\n",
       "0    animals-topic-batch  animals-topic-streaming   \n",
       "1    animals-topic-batch  animals-topic-streaming   \n",
       "2    animals-topic-batch  animals-topic-streaming   \n",
       "3    animals-topic-batch  animals-topic-streaming   \n",
       "4    animals-topic-batch  animals-topic-streaming   \n",
       "..                   ...                      ...   \n",
       "143  animals-topic-batch  animals-topic-streaming   \n",
       "144  animals-topic-batch  animals-topic-streaming   \n",
       "145  animals-topic-batch  animals-topic-streaming   \n",
       "146  animals-topic-batch  animals-topic-streaming   \n",
       "147  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                  checkpoint_location              files_directory  \n",
       "0    /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1    /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2    /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3    /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4    /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "..                                ...                          ...  \n",
       "143  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "144  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "145  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "146  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "147  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "\n",
       "[148 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hippo</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eagle</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>parrot</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rhino</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>koala</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cheetah</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>snake</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hawk</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chimpanzee</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zebra</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kangaroo</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>panther</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>panda</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>owl</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>turtle</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>swan</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>polar bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jaguar</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>orangutan</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key      value          input_topic             output_topic  \\\n",
       "0        hippo     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "1        eagle       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "2       parrot       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "3        rhino     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "4      dolphin     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "5        koala  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "6      cheetah     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "7        snake    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "8         hawk       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "9   chimpanzee    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "10       zebra     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "11    kangaroo  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "12     panther     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "13       panda     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "14        bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "15         owl       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "16      turtle    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "17        swan       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "18  polar bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "19      jaguar     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "20   orangutan    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                 checkpoint_location              files_directory  \n",
       "0   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "5   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "6   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "7   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "8   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "9   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "10  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "11  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "12  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "13  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "14  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "15  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "16  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "17  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "18  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "19  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "20  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fox</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seagull</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gazelle</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>panda</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>owl</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>koala</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cheetah</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>orangutan</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jaguar</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zebra</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fox</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kangaroo</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>panther</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>polar bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>turtle</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>swan</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>parrot</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rhino</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>snake</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hawk</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hippo</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>eagle</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key      value          input_topic             output_topic  \\\n",
       "0          fox     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "1      seagull       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "2      gazelle     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "3        panda     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "4         bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "5          owl       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "6        koala  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "7      cheetah     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "8    orangutan    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "9       jaguar     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "10       zebra     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "11         fox     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "12    kangaroo  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "13     panther     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "14  polar bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "15      turtle    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "16        swan       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "17      parrot       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "18       rhino     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "19       snake    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "20        hawk       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "21     dolphin     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "22       hippo     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "23       eagle       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                 checkpoint_location              files_directory  \n",
       "0   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "5   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "6   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "7   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "8   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "9   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "10  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "11  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "12  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "13  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "14  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "15  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "16  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "17  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "18  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "19  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "20  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "21  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "22  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "23  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seagull</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gazelle</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chimpanzee</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>polar bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>snake</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hawk</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jaguar</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>panda</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>orangutan</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kangaroo</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>panther</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chimpanzee</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>zebra</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>koala</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>parrot</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cheetah</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rhino</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>owl</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hippo</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>eagle</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fox</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>turtle</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>swan</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key      value          input_topic             output_topic  \\\n",
       "0      seagull       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "1      gazelle     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "2   chimpanzee    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "3   polar bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "4        snake    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "5         hawk       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "6      dolphin     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "7       jaguar     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "8        panda     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "9    orangutan    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "10    kangaroo  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "11     panther     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "12  chimpanzee    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "13       zebra     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "14       koala  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "15      parrot       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "16     cheetah     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "17       rhino     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "18        bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "19         owl       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "20       hippo     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "21       eagle       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "22         fox     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "23      turtle    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "24        swan       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                 checkpoint_location              files_directory  \n",
       "0   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "5   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "6   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "7   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "8   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "9   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "10  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "11  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "12  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "13  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "14  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "15  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "16  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "17  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "18  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "19  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "20  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "21  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "22  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "23  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "24  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seagull</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gazelle</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chimpanzee</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>parrot</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rhino</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>orangutan</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>koala</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cheetah</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>owl</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zebra</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>panda</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>snake</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hawk</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hippo</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>eagle</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jaguar</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fox</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kangaroo</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>panther</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>polar bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>seagull</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gazelle</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key      value          input_topic             output_topic  \\\n",
       "0      seagull       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "1      gazelle     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "2   chimpanzee    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "3       parrot       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "4        rhino     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "5    orangutan    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "6        koala  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "7      cheetah     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "8         bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "9          owl       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "10       zebra     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "11       panda     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "12       snake    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "13        hawk       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "14       hippo     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "15       eagle       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "16      jaguar     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "17         fox     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "18     dolphin     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "19    kangaroo  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "20     panther     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "21  polar bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "22     seagull       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "23     gazelle     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                 checkpoint_location              files_directory  \n",
       "0   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "5   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "6   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "7   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "8   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "9   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "10  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "11  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "12  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "13  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "14  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "15  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "16  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "17  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "18  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "19  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "20  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "21  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "22  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "23  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turtle</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>swan</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seagull</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gazelle</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fox</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>panda</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>orangutan</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>parrot</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>polar bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zebra</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>turtle</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>swan</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>kangaroo</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>panther</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rhino</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>koala</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cheetah</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hippo</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>eagle</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>owl</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chimpanzee</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jaguar</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>snake</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hawk</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key      value          input_topic             output_topic  \\\n",
       "0       turtle    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "1         swan       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "2      seagull       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "3      gazelle     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "4          fox     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "5        panda     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "6    orangutan    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "7       parrot       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "8      dolphin     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "9   polar bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "10       zebra     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "11      turtle    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "12        swan       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "13    kangaroo  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "14     panther     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "15       rhino     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "16       koala  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "17     cheetah     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "18       hippo     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "19       eagle       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "20        bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "21         owl       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "22  chimpanzee    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "23      jaguar     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "24       snake    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "25        hawk       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                 checkpoint_location              files_directory  \n",
       "0   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "5   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "6   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "7   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "8   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "9   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "10  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "11  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "12  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "13  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "14  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "15  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "16  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "17  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "18  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "19  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "20  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "21  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "22  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "23  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "24  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "25  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seagull</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gazelle</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orangutan</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>koala</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cheetah</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hippo</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>snake</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>eagle</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hawk</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chimpanzee</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>panda</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>polar bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fox</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kangaroo</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>panther</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>owl</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>turtle</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jaguar</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>swan</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>zebra</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key      value          input_topic             output_topic  \\\n",
       "0      seagull       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "1      gazelle     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "2    orangutan    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "3        koala  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "4      cheetah     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "5      dolphin     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "6        hippo     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "7        snake    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "8        eagle       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "9         hawk       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "10  chimpanzee    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "11       panda     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "12  polar bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "13         fox     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "14    kangaroo  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "15     panther     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "16        bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "17         owl       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "18      turtle    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "19      jaguar     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "20        swan       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "21       zebra     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                 checkpoint_location              files_directory  \n",
       "0   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "5   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "6   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "7   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "8   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "9   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "10  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "11  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "12  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "13  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "14  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "15  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "16  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "17  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "18  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "19  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "20  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "21  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parrot</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rhino</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>polar bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jaguar</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>snake</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>orangutan</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hawk</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kangaroo</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>panther</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>parrot</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rhino</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>koala</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cheetah</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>turtle</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>swan</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>zebra</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hippo</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>eagle</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>seagull</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>panda</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gazelle</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fox</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chimpanzee</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key      value          input_topic             output_topic  \\\n",
       "0       parrot       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "1        rhino     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "2   polar bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "3       jaguar     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "4        snake    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "5      dolphin     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "6    orangutan    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "7         hawk       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "8     kangaroo  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "9      panther     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "10      parrot       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "11       rhino     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "12       koala  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "13     cheetah     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "14      turtle    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "15        swan       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "16       zebra     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "17       hippo     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "18       eagle       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "19     seagull       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "20       panda     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "21     gazelle     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "22         fox     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "23  chimpanzee    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                 checkpoint_location              files_directory  \n",
       "0   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "5   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "6   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "7   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "8   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "9   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "10  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "11  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "12  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "13  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "14  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "15  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "16  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "17  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "18  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "19  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "20  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "21  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "22  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "23  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>owl</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jaguar</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fox</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>panda</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chimpanzee</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>turtle</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>polar bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>swan</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>koala</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cheetah</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>orangutan</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hippo</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>eagle</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kangaroo</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>panther</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>parrot</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rhino</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>snake</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hawk</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>seagull</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gazelle</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>owl</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>zebra</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key      value          input_topic             output_topic  \\\n",
       "0         bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "1          owl       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "2       jaguar     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "3          fox     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "4        panda     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "5   chimpanzee    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "6       turtle    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "7   polar bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "8         swan       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "9        koala  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "10     cheetah     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "11   orangutan    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "12       hippo     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "13       eagle       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "14    kangaroo  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "15     panther     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "16     dolphin     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "17      parrot       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "18       rhino     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "19       snake    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "20        hawk       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "21     seagull       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "22     gazelle     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "23        bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "24         owl       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "25       zebra     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                 checkpoint_location              files_directory  \n",
       "0   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "5   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "6   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "7   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "8   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "9   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "10  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "11  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "12  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "13  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "14  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "15  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "16  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "17  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "18  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "19  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "20  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "21  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "22  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "23  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "24  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "25  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>owl</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>snake</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hawk</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>koala</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cheetah</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>polar bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fox</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>turtle</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>swan</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>panda</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>parrot</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rhino</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chimpanzee</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hippo</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eagle</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>jaguar</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>zebra</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kangaroo</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>panther</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>seagull</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gazelle</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key      value          input_topic             output_topic  \\\n",
       "0         bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "1          owl       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "2        snake    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "3         hawk       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "4      dolphin     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "5        koala  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "6      cheetah     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "7   polar bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "8          fox     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "9       turtle    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "10        swan       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "11       panda     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "12      parrot       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "13       rhino     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "14  chimpanzee    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "15       hippo     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "16       eagle       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "17      jaguar     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "18       zebra     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "19    kangaroo  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "20     panther     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "21     seagull       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "22     gazelle     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                 checkpoint_location              files_directory  \n",
       "0   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "5   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "6   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "7   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "8   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "9   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "10  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "11  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "12  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "13  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "14  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "15  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "16  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "17  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "18  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "19  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "20  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "21  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "22  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orangutan</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>parrot</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rhino</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>panda</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chimpanzee</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seagull</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gazelle</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>snake</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hawk</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>orangutan</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jaguar</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kangaroo</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>panther</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>polar bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hippo</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>eagle</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>fox</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>koala</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cheetah</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>zebra</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>turtle</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>swan</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>owl</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key      value          input_topic             output_topic  \\\n",
       "0    orangutan    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "1       parrot       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "2        rhino     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "3        panda     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "4   chimpanzee    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "5      seagull       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "6      gazelle     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "7        snake    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "8         hawk       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "9    orangutan    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "10      jaguar     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "11    kangaroo  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "12     panther     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "13  polar bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "14     dolphin     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "15       hippo     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "16       eagle       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "17         fox     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "18       koala  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "19     cheetah     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "20       zebra     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "21      turtle    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "22        swan       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "23        bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "24         owl       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                 checkpoint_location              files_directory  \n",
       "0   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "5   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "6   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "7   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "8   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "9   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "10  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "11  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "12  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "13  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "14  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "15  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "16  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "17  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "18  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "19  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "20  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "21  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "22  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "23  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "24  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snake</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hawk</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zebra</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hippo</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eagle</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>panda</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>turtle</td>\n",
       "      <td>REPTILE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>swan</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jaguar</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>seagull</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gazelle</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>orangutan</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chimpanzee</td>\n",
       "      <td>PRIMATE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>parrot</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rhino</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kangaroo</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>polar bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>panther</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bear</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>owl</td>\n",
       "      <td>BIRD</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>koala</td>\n",
       "      <td>MARSUPIAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cheetah</td>\n",
       "      <td>FELINE</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fox</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           key      value          input_topic             output_topic  \\\n",
       "0        snake    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "1         hawk       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "2        zebra     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "3        hippo     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "4        eagle       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "5        panda     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "6       turtle    REPTILE  animals-topic-batch  animals-topic-streaming   \n",
       "7         swan       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "8       jaguar     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "9      seagull       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "10     gazelle     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "11   orangutan    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "12  chimpanzee    PRIMATE  animals-topic-batch  animals-topic-streaming   \n",
       "13      parrot       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "14       rhino     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "15    kangaroo  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "16  polar bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "17     panther     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "18        bear     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "19         owl       BIRD  animals-topic-batch  animals-topic-streaming   \n",
       "20       koala  MARSUPIAL  animals-topic-batch  animals-topic-streaming   \n",
       "21     cheetah     FELINE  animals-topic-batch  animals-topic-streaming   \n",
       "22         fox     MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                 checkpoint_location              files_directory  \n",
       "0   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "1   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "2   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "3   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "4   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "5   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "6   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "7   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "8   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "9   /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "10  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "11  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "12  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "13  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "14  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "15  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "16  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "17  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "18  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "19  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "20  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "21  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  \n",
       "22  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch ID : 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>input_topic</th>\n",
       "      <th>output_topic</th>\n",
       "      <th>checkpoint_location</th>\n",
       "      <th>files_directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dolphin</td>\n",
       "      <td>MAMMAL</td>\n",
       "      <td>animals-topic-batch</td>\n",
       "      <td>animals-topic-streaming</td>\n",
       "      <td>/usr/local/kafka/data/checkpoint</td>\n",
       "      <td>/usr/local/kafka/data/files</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       key   value          input_topic             output_topic  \\\n",
       "0  dolphin  MAMMAL  animals-topic-batch  animals-topic-streaming   \n",
       "\n",
       "                checkpoint_location              files_directory  \n",
       "0  /usr/local/kafka/data/checkpoint  /usr/local/kafka/data/files  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing microbatch 0 at 2024_11_17_05_46_17\n",
      "+--------+-------------------+---------------------+----------------+-------------+----------------+------------------+----------------+\n",
      "|batch_id|timestamp          |passenger_nationality|passenger_gender|passenger_age|avg_ticket_price|total_ticket_price|total_passengers|\n",
      "+--------+-------------------+---------------------+----------------+-------------+----------------+------------------+----------------+\n",
      "|0       |2024_11_17_05_46_17|NULL                 | \\\"crustacean\\\")|NULL         |NULL            |NULL              |3               |\n",
      "|0       |2024_11_17_05_46_17|NULL                 | \\\"reptile\\\")   |NULL         |NULL            |NULL              |3               |\n",
      "|0       |2024_11_17_05_46_17|NULL                 | \\\"arachnid\\\")  |NULL         |NULL            |NULL              |5               |\n",
      "|0       |2024_11_17_05_46_17|NULL                 | \\\"mammal\\\")    |NULL         |NULL            |NULL              |6               |\n",
      "|0       |2024_11_17_05_46_17|NULL                 |NULL            |NULL         |NULL            |NULL              |7               |\n",
      "+--------+-------------------+---------------------+----------------+-------------+----------------+------------------+----------------+\n",
      "\n",
      "+----+-----------+-------+--------------+--------------+---------------+------------+------------+--------------+----------------+-----------+--------+--------------+-------------+-------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+----------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|  id|secure_code|airline|departure_city|departure_date|arrival_airport|arrival_city|arrival_time|passenger_name|passenger_gender|seat_number|currency|departure_gate|flight_status|co_pilot_name|aircraft_type|fuel_consumption|flight_id|flight_number|departure_airport|departure_country|departure_time|arrival_country|arrival_date|flight_duration|passenger_age|passenger_nationality|ticket_price|baggage_weight|arrival_gate|pilot_name|cabin_crew_count|aircraft_registration|flight_distance|batch_id|          timestamp|\n",
      "+----+-----------+-------+--------------+--------------+---------------+------------+------------+--------------+----------------+-----------+--------+--------------+-------------+-------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+----------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "|NULL|       NULL|   NULL|          NULL|          NULL|           NULL|        NULL|        NULL|          NULL|            NULL|       NULL|    NULL|          NULL|         NULL|         NULL|         NULL|            NULL|     NULL|         NULL|             NULL|             NULL|          NULL|           NULL|        NULL|           NULL|         NULL|                 NULL|        NULL|          NULL|        NULL|      NULL|            NULL|                 NULL|           NULL|       0|2024_11_17_05_46_17|\n",
      "+----+-----------+-------+--------------+--------------+---------------+------------+------------+--------------+----------------+-----------+--------+--------------+-------------+-------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+----------+----------------+---------------------+---------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Processing microbatch 1 at 2024_11_17_05_46_30\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|batch_id|timestamp          |passenger_nationality|passenger_gender|passenger_age|avg_ticket_price  |total_ticket_price|total_passengers|\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|1       |2024_11_17_05_46_30|Brazil               |Male            |56           |353.31333333333333|1059.94           |3               |\n",
      "|1       |2024_11_17_05_46_30|Brazil               |Male            |53           |690.0966666666667 |2070.29           |3               |\n",
      "|1       |2024_11_17_05_46_30|China                |Female          |68           |91.99333333333334 |275.98            |3               |\n",
      "|1       |2024_11_17_05_46_30|China                |Female          |47           |666.9266666666666 |2000.78           |3               |\n",
      "|1       |2024_11_17_05_46_30|China                |Male            |30           |450.3299999999999 |1350.9899999999998|3               |\n",
      "|1       |2024_11_17_05_46_30|China                |Male            |45           |273.32666666666665|819.98            |3               |\n",
      "|1       |2024_11_17_05_46_30|China                |Male            |56           |479.7666666666667 |1439.3000000000002|3               |\n",
      "|1       |2024_11_17_05_46_30|China                |Male            |21           |474.1233333333333 |1422.37           |3               |\n",
      "|1       |2024_11_17_05_46_30|China                |Male            |57           |653.4266666666667 |1960.2800000000002|3               |\n",
      "|1       |2024_11_17_05_46_30|China                |Male            |35           |270.90000000000003|812.7             |3               |\n",
      "|1       |2024_11_17_05_46_30|Indonesia            |Female          |82           |525.33            |1575.99           |3               |\n",
      "|1       |2024_11_17_05_46_30|Indonesia            |Female          |20           |500.2833333333333 |1500.85           |3               |\n",
      "|1       |2024_11_17_05_46_30|Indonesia            |Male            |41           |538.02            |1614.06           |3               |\n",
      "|1       |2024_11_17_05_46_30|Philippines          |Female          |93           |460.9166666666667 |1382.75           |3               |\n",
      "|1       |2024_11_17_05_46_30|China                |Female          |87           |554.2025          |2216.81           |4               |\n",
      "|1       |2024_11_17_05_46_30|China                |Female          |72           |511.3875          |2045.55           |4               |\n",
      "|1       |2024_11_17_05_46_30|China                |Female          |69           |347.235           |1388.94           |4               |\n",
      "|1       |2024_11_17_05_46_30|China                |Male            |34           |414.83250000000004|1659.3300000000002|4               |\n",
      "|1       |2024_11_17_05_46_30|Indonesia            |Male            |52           |560.5999999999999 |2242.3999999999996|4               |\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "\n",
      "+---+--------------------+--------+-------------------+--------------+---------------+-----------------+----------------+--------------------+----------------+-----------+--------+--------------+-------------+--------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "| id|         secure_code| airline|     departure_city|departure_date|arrival_airport|     arrival_city|    arrival_time|      passenger_name|passenger_gender|seat_number|currency|departure_gate|flight_status|       co_pilot_name|aircraft_type|fuel_consumption|flight_id|flight_number|departure_airport|departure_country|departure_time|arrival_country|arrival_date|flight_duration|passenger_age|passenger_nationality|ticket_price|baggage_weight|arrival_gate|          pilot_name|cabin_crew_count|aircraft_registration|flight_distance|batch_id|          timestamp|\n",
      "+---+--------------------+--------+-------------------+--------------+---------------+-----------------+----------------+--------------------+----------------+-----------+--------+--------------+-------------+--------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|  1|01H4EEMGMG9VADVF0...| EasyFly|             Berlin|    25/12/2022|            PEI|          Pereira|27/12/2022 14:13|    Nathalie Cardona|          Female|         A1|     EUR|            B2|      On Time|       Hart Blunkett| Embraer E190|         7916.39|        1|         1978|              CFQ|          Germany|6/7/2023 04:42|       Colombia|  27/12/2022|          14.18|            0|             Colombia|      797.24|         43.85|          E5|           Sunny Few|               9|               N12345|        1400.24|       1|2024_11_17_05_46_30|\n",
      "|  2|01H4EEMGMYP8GX4GR...|   Delta|Les Sables-d'Olonne|      4/1/2022|            YHU|         Westport|  6/7/2023 06:53|    Willie Childrens|          Female|         B2|     EUR|            A1|      Delayed|     Leanor Gribbins|  Airbus A320|         9666.36|        2|         2337|              ONG|           France|6/7/2023 17:31|    New Zealand|  23/12/2022|          13.54|           29|               Sweden|      383.63|         35.78|          D4|      Donielle Strut|               4|               N12345|         465.84|       1|2024_11_17_05_46_30|\n",
      "|  3|01H4EEMGN3BZJ9RR7...|  United|                Oyo|      3/4/2022|            KWJ|            Jabon|  6/7/2023 03:44|        Fifine Luten|          Female|         B2|     NGN|            C3|      On Time|    Christie Wakeley|   Boeing 737|         8047.44|        3|         7588|              TEX|          Nigeria|6/7/2023 11:08|      Indonesia|   30/9/2022|           6.28|           34|            Argentina|      439.09|         47.81|          D4|   Shelly Paddefield|               3|               N67890|        3151.78|       1|2024_11_17_05_46_30|\n",
      "|  4|01H4EEMGN9DFF5XJC...|   Delta|    Kuragaki-kosugi|     31/5/2022|            ANP|         Xianyuan|  6/7/2023 18:56|   Doll Sommerscales|          Female|         C3|     JPY|            A1|      Delayed|          Mia Vannah|  Airbus A320|         5156.19|        4|         7545|              ORB|            Japan|6/7/2023 11:11|          China|  14/10/2022|            5.6|           34|                China|      706.19|         25.79|          D4|   Babara Kretschmer|               6|               N12345|         264.64|       1|2024_11_17_05_46_30|\n",
      "|  5|01H4EEMGNFX6T41V6...|   Delta|        Ko Pha Ngan|     10/7/2022|            QUB|Sovetskaya Gavan’|  6/7/2023 16:55|       Norman Crosen|            Male|         A1|     THB|            A1|      On Time|         Barn Timmes|   Boeing 737|         7584.07|        5|         4553|              WEW|         Thailand|6/7/2023 10:40|         Russia|  13/10/2022|          14.71|           40|              Uruguay|      906.66|          11.6|          E5|       Bert Mathison|               5|               N67890|        2158.97|       1|2024_11_17_05_46_30|\n",
      "|  6|01H4EEMGNM5EFYXD9...|  United|       Cândido Mota|     3/12/2022|            VDM|            Légua|  6/7/2023 08:02|     Ingram Reicherz|            Male|         C3|     BRL|            C3|    Cancelled|Leicester McEntagart|   Boeing 737|         2035.88|        6|         2803|              BBV|           Brazil|6/7/2023 18:37|       Portugal|   29/3/2022|          15.39|           42|          South Korea|      131.44|         29.75|          D4|     Sergent Scarffe|               5|               N67890|        4838.19|       1|2024_11_17_05_46_30|\n",
      "|  7|01H4EEMGNT502Q3TQ...|American|          Zhangatas|     22/2/2022|            OGL|        Caibarién|  6/7/2023 11:55|          Jock Braam|            Male|         B2|     KZT|            C3|      On Time|       Rollin Leedal|   Boeing 737|         8287.38|        7|          757|              JUT|       Kazakhstan|6/7/2023 10:07|           Cuba|    2/9/2022|          17.45|           36|               Brazil|      476.27|         31.51|          D4|     Rayner Pennyman|               3|               N67890|         1777.3|       1|2024_11_17_05_46_30|\n",
      "|  8|01H4EEMGNZQZMS1G5...|  United|             Nevers|    20/10/2022|            MBG|            Tivat|  6/7/2023 15:03|         Shea Fedder|            Male|         A1|     EUR|            C3|      On Time|       Flynn Symmons|   Boeing 737|         4142.26|        8|         8642|              ELQ|           France|6/7/2023 23:13|     Montenegro|    4/2/2022|           4.77|           53|               Brazil|      640.94|         26.07|          E5|Johnathan Liversedge|               6|               NABCDE|         109.33|       1|2024_11_17_05_46_30|\n",
      "|  9|01H4EEMGP5RRF1T84...|   Delta|             Gaoyao|    27/12/2022|            SXM|     Chaoyangdong|  6/7/2023 17:35|    Cherise Anscombe|          Female|         C3|     CNY|            C3|      On Time|        Raquel Jeves|  Airbus A320|         9916.74|        9|         2765|              IZA|            China|6/7/2023 18:28|          China|    7/1/2022|           2.94|           57|                China|      133.09|         22.26|          F6|  Willette Episcopio|               4|               N12345|        3589.68|       1|2024_11_17_05_46_30|\n",
      "| 10|01H4EEMGPAR2YFG70...|   Delta|             Chatan|      6/1/2022|            YOL|           Istres|  6/7/2023 13:29|     Amara McGebenay|          Female|         A1|     JPY|            B2|      Delayed|       Philly Hickin| Embraer E190|          7003.2|       10|         6815|              LEE|            Japan|6/7/2023 12:14|         France|    5/8/2022|          21.62|           52|               Greece|      116.34|         27.61|          D4|         Lilah Kempe|               5|               N67890|         228.93|       1|2024_11_17_05_46_30|\n",
      "| 11|01H4EEMGPGM90HM7B...|   Delta|           Forninho|     15/1/2022|            PRM|           Kornyn|  6/7/2023 08:00|     Hoebart Fruchon|            Male|         C3|     EUR|            B2|      Delayed|     Cesare Janovsky| Embraer E190|         6868.05|       11|         6610|              KPB|         Portugal|6/7/2023 03:30|        Ukraine|    7/1/2022|           9.21|           70|                 Peru|      459.82|         45.14|          E5|         Hodge Polak|               5|               N12345|        3974.33|       1|2024_11_17_05_46_30|\n",
      "| 12|01H4EEMGPP9H8CR43...|American|             Lomboy|     16/3/2022|            DMU|       Ballinteer|  6/7/2023 00:25|        Rockie Huett|            Male|         C3|     PHP|            B2|    Cancelled|     Zerk Le Hucquet|   Boeing 737|         5346.91|       12|         8756|              OGL|      Philippines|6/7/2023 20:41|        Ireland|   1/11/2022|           3.86|           94|            Argentina|      462.73|         49.57|          D4|      Lauren Bussons|               5|               N67890|        2646.13|       1|2024_11_17_05_46_30|\n",
      "| 13|01H4EEMGPVCXFW2VZ...|  United|             Essang|    23/10/2022|            WLA|      Três Passos|  6/7/2023 16:28|        Lorrin Armit|          Female|         A1|     IDR|            B2|    Cancelled|     Inessa Bradnock| Embraer E190|          7185.9|       13|         3976|              NVY|        Indonesia|6/7/2023 18:56|         Brazil|  28/11/2022|          23.51|           66|               Sweden|       930.5|         39.47|          F6|    Lisetta Proudler|               1|               N12345|        2442.77|       1|2024_11_17_05_46_30|\n",
      "| 14|01H4EEMGQ0ETBKDEA...|American|           Zipárion|    15/12/2022|            LDN|      Courtaboeuf|  6/7/2023 07:03|       Burke Ruspine|            Male|         A1|     EUR|            C3|      Delayed|        Noach Gudgen|  Airbus A320|         2121.62|       14|          506|              ZTA|           Greece|6/7/2023 00:55|         France|   25/3/2022|          22.49|           66|              Ukraine|      963.38|          6.13|          F6|     Thorny Eggleson|               3|               NABCDE|        3944.21|       1|2024_11_17_05_46_30|\n",
      "| 15|01H4EEMGQ6HJV44PC...|American|              Gialo|     17/8/2022|            FKN|           Beigou|  6/7/2023 02:52|      Frank Beastall|            Male|         C3|     LYD|            B2|    Cancelled|          Salim Shay|  Airbus A320|         6812.66|       15|         1420|              RUK|            Libya|6/7/2023 13:08|          China|   25/1/2022|           12.5|           79|              Bolivia|      721.82|         11.42|          D4|       Field McEntee|               7|               NABCDE|         745.48|       1|2024_11_17_05_46_30|\n",
      "| 16|01H4EEMGQBFQP91SE...|American|              Rusip|    18/12/2022|            QCY|         Oštarije|  6/7/2023 03:22|    Richie Rosindill|            Male|         A1|     IDR|            B2|    Cancelled|    Dolph Lanchberry|  Airbus A320|         5704.86|       16|         6843|              MTY|        Indonesia|6/7/2023 07:41|        Croatia|  20/12/2022|          19.42|           86|               Poland|      723.34|         43.14|          D4|       Josh Docharty|               9|               NABCDE|        1008.69|       1|2024_11_17_05_46_30|\n",
      "| 17|01H4EEMGQG22ER3ZS...|   Delta|             Panyam|     20/5/2022|            OXR|         El Limon|  6/7/2023 03:55|Shellysheldon Bubeer|            Male|         C3|     NGN|            B2|      Delayed|      Julius Kelsall|  Airbus A320|         7480.92|       17|          933|              PCO|          Nigeria|6/7/2023 18:12|         Mexico|   17/4/2022|          21.86|           45|               Norway|      983.86|         34.47|          E5|     Edward Pavolini|               5|               N67890|        3659.46|       1|2024_11_17_05_46_30|\n",
      "| 18|01H4EEMGQPE6HCDYD...|   Delta|         Xiaomenjia|      3/9/2022|            VDS|         Trinidad|  6/7/2023 21:31|    Amelia Ralestone|          Female|         B2|     CNY|            B2|    Cancelled|        Veda Stollen| Embraer E190|         2859.73|       18|         9051|              DHG|            China|6/7/2023 09:46|           Peru|    1/1/2022|           6.62|           60|             Portugal|      216.07|          2.59|          F6|       Arlana Pudner|               3|               N67890|        4842.87|       1|2024_11_17_05_46_30|\n",
      "| 19|01H4EEMGQVNVPC68C...|   Delta|          Xujiadian|    28/11/2022|            CGV|           Vannes|  6/7/2023 19:38|       Kylie Dowdall|          Female|         B2|     CNY|            C3|      Delayed|     Klarika Dulanty|   Boeing 737|         1982.61|       19|         2934|              HAO|            China|6/7/2023 08:26|         France|  12/10/2022|          13.13|           82|               Greece|      835.35|         43.71|          F6|      Nadean Verrell|               4|               N12345|        4133.64|       1|2024_11_17_05_46_30|\n",
      "| 20|01H4EEMGR16AZ5ZR3...|American|             Mainit|     11/6/2022|            IOU|             Gujō|  6/7/2023 23:12|       Elston Greson|            Male|         C3|     PHP|            B2|      Delayed|      Ethelred Wyche| Embraer E190|          2882.4|       20|         8761|              TCZ|      Philippines|6/7/2023 07:20|          Japan|    2/9/2022|          14.22|           29|               France|      861.69|          20.1|          F6|        Andre Gatiss|               7|               NABCDE|        2833.98|       1|2024_11_17_05_46_30|\n",
      "+---+--------------------+--------+-------------------+--------------+---------------+-----------------+----------------+--------------------+----------------+-----------+--------+--------------+-------------+--------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Processing microbatch 2 at 2024_11_17_05_46_35\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|batch_id|timestamp          |passenger_nationality|passenger_gender|passenger_age|avg_ticket_price  |total_ticket_price|total_passengers|\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|2       |2024_11_17_05_46_35|China                |Female          |61           |314.9766666666667 |944.9300000000001 |3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Female          |53           |286.78000000000003|860.34            |3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Female          |54           |678.1066666666667 |2034.3200000000002|3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Female          |78           |654.3733333333333 |1963.1200000000001|3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Female          |51           |395.4766666666667 |1186.43           |3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Female          |93           |426.99333333333334|1280.98           |3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Female          |57           |315.3066666666667 |945.9200000000001 |3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Female          |73           |390.07666666666665|1170.23           |3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Male            |93           |559.5             |1678.5            |3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Male            |21           |418.32            |1254.96           |3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Male            |74           |594.3433333333334 |1783.0300000000002|3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Male            |66           |733.0766666666667 |2199.23           |3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Male            |49           |732.3266666666667 |2196.98           |3               |\n",
      "|2       |2024_11_17_05_46_35|China                |Male            |96           |473.55            |1420.65           |3               |\n",
      "|2       |2024_11_17_05_46_35|Indonesia            |Female          |32           |463.46000000000004|1390.38           |3               |\n",
      "|2       |2024_11_17_05_46_35|Indonesia            |Female          |76           |659.92            |1979.76           |3               |\n",
      "|2       |2024_11_17_05_46_35|Indonesia            |Male            |96           |612.04            |1836.12           |3               |\n",
      "|2       |2024_11_17_05_46_35|Philippines          |Female          |75           |571.68            |1715.04           |3               |\n",
      "|2       |2024_11_17_05_46_35|Russia               |Male            |63           |441.71999999999997|1325.1599999999999|3               |\n",
      "|2       |2024_11_17_05_46_35|United States        |Male            |27           |479.26            |1437.78           |3               |\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+--------------------+--------+--------------+--------------+---------------+----------------+--------------+--------------------+----------------+-----------+--------+--------------+-------------+-------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|  id|         secure_code| airline|departure_city|departure_date|arrival_airport|    arrival_city|  arrival_time|      passenger_name|passenger_gender|seat_number|currency|departure_gate|flight_status|      co_pilot_name|aircraft_type|fuel_consumption|flight_id|flight_number|departure_airport|departure_country|departure_time|     arrival_country|arrival_date|flight_duration|passenger_age|passenger_nationality|ticket_price|baggage_weight|arrival_gate|        pilot_name|cabin_crew_count|aircraft_registration|flight_distance|batch_id|          timestamp|\n",
      "+----+--------------------+--------+--------------+--------------+---------------+----------------+--------------+--------------------+----------------+-----------+--------+--------------+-------------+-------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|1001|01H4EEMMVYAY9VQRE...|American|  Nakhon Nayok|     2/11/2022|            CUI|          Bromma|6/7/2023 08:54|     Murielle Raulin|     Genderfluid|         A1|     THB|            B2|    Cancelled|    Kelbee Franzman|   Boeing 737|         8950.14|     1001|          776|              GTS|         Thailand|6/7/2023 02:21|              Sweden|   29/4/2022|           6.51|           19|               Poland|      568.46|         38.15|          F6|Henriette Chopping|               2|               N67890|        3090.45|       2|2024_11_17_05_46_35|\n",
      "|1002|01H4EEMMW1YT1DA0S...|   Delta|     Ulaan-Uul|     7/12/2022|            RGS|        Xiaozhai|6/7/2023 04:47|         Meris Katte|          Female|         B2|     MNT|            A1|      On Time|Anna-diana Shillito| Embraer E190|         6007.32|     1002|         3193|              GUU|         Mongolia|6/7/2023 18:37|               China|  10/10/2022|          12.95|           24|              Armenia|      886.62|         45.62|          E5| Mignonne Peperell|               2|               N12345|        4177.52|       2|2024_11_17_05_46_35|\n",
      "|1003|01H4EEMMW7ZA8JA1T...|   Delta|  Kuala Lumpur|     30/9/2022|            ENV|           Mólos|6/7/2023 00:38|        Amber Sheber|          Female|         C3|     MYR|            C3|      On Time|  Courtenay Salters| Embraer E190|         3601.69|     1003|         5991|              HZV|         Malaysia|6/7/2023 11:58|              Greece|    9/4/2022|           7.76|           73|                China|       78.31|         42.15|          F6|       Tanya Coult|               7|               N12345|        1179.22|       2|2024_11_17_05_46_35|\n",
      "|1004|01H4EEMMWCBCMSN1W...|  United| Baltasar Brum|     17/7/2022|            NHD|  Ciudad Sandino|6/7/2023 08:35|Konstantine McFet...|            Male|         A1|     UYU|            A1|      Delayed|     Jaimie D'Cruze| Embraer E190|         9653.98|     1004|          911|              MXB|          Uruguay|6/7/2023 00:44|           Nicaragua|   20/8/2022|          13.01|           64|              Vietnam|      975.68|         38.98|          D4|   Anthony McKinty|               6|               NABCDE|        1151.95|       2|2024_11_17_05_46_35|\n",
      "|1005|01H4EEMMWJTDDHW8Y...|  United|   Paucarcolla|     1/10/2022|            VDS|        Beltinci|6/7/2023 23:19|      Lulita Penhale|          Female|         A1|     PEN|            B2|    Cancelled|       Valry Bixley|   Boeing 737|         8869.95|     1005|         9426|              SOO|             Peru|6/7/2023 14:39|            Slovenia|   24/9/2022|           8.68|           81|             Mongolia|      509.32|         19.52|          D4|      Evy Clemenzi|               7|               N67890|        3513.93|       2|2024_11_17_05_46_35|\n",
      "|1006|01H4EEMMWQSX2RHG4...|   Delta|        Anding|     14/8/2022|            RZZ|       Zhuyeping|6/7/2023 00:00|      Branden Hugnin|            Male|         B2|     CNY|            C3|      On Time|     Skipton Sammon| Embraer E190|         8116.37|     1006|         4160|              PSH|            China|6/7/2023 03:35|               China|   27/8/2022|          20.45|           52|          Switzerland|      904.72|         36.29|          D4|    Taylor Ballach|               7|               NABCDE|        3039.29|       2|2024_11_17_05_46_35|\n",
      "|1007|01H4EEMMWXSGWXTJ8...|American| Sihanoukville|      6/8/2022|            TPQ|       Bandhagen|6/7/2023 03:42|     Zilvia Pickrell|          Female|         A1|     KHR|            B2|      Delayed|         Kandace Do|   Boeing 737|         3947.15|     1007|         3069|              HZH|         Cambodia|6/7/2023 10:41|              Sweden|   19/3/2022|          22.93|           70|                Sudan|      338.41|         14.08|          E5|    Tove MacGeaney|               3|               NABCDE|         353.36|       2|2024_11_17_05_46_35|\n",
      "|1008|01H4EEMMX2E1ENFMN...|American|       Itiruçu|     31/3/2022|            MAP|           Daliu|6/7/2023 15:22|     Allyson Devaney|          Female|         A1|     BRL|            C3|      Delayed|       Remy Bonnick|  Airbus A320|         1102.01|     1008|         5923|              FCH|           Brazil|6/7/2023 10:31|               China|   20/5/2022|          23.62|           27|                China|      815.73|         12.44|          D4|   Frederique Reef|              10|               N12345|        4875.94|       2|2024_11_17_05_46_35|\n",
      "|1009|01H4EEMMX65CZSPES...|   Delta|Montréal-Ouest|     23/1/2022|            THM|Gaspar Hernández|6/7/2023 00:32|    Zacharias Boagey|            Male|         A1|     CAD|            A1|      Delayed|      Dagny Pipping|   Boeing 737|         5779.58|     1009|         7445|              KIP|           Canada|6/7/2023 00:01|  Dominican Republic|   13/1/2022|          22.62|           48|                China|      912.96|           3.0|          D4|     Tracy McMyler|               1|               NABCDE|        3793.43|       2|2024_11_17_05_46_35|\n",
      "|1010|01H4EEMMX9JMTD9AG...|   Delta|          Nara|     3/10/2022|            MVT|            Ugba|6/7/2023 03:48|      Budd Schneidau|            Male|         B2|     XOF|            B2|      Delayed|Tybalt Clarricoates|   Boeing 737|         1311.62|     1010|         9423|              ARY|             Mali|6/7/2023 06:35|             Nigeria|   13/7/2022|           8.56|           24|               France|      882.91|         23.16|          D4|      Erwin Adamik|               3|               N12345|        3116.84|       2|2024_11_17_05_46_35|\n",
      "|1011|01H4EEMMXCJPG909B...|   Delta|        Pandak|      7/5/2022|            XIN|           Dijon|6/7/2023 05:54|      Erskine Rodman|            Male|         B2|     IDR|            A1|      Delayed|   Lenard Andreutti|   Boeing 737|         4267.26|     1011|         9710|              XPP|        Indonesia|6/7/2023 22:25|              France|   10/4/2022|           11.4|           94|                Chile|      137.15|         46.45|          E5|    Tailor Oughton|               8|               N12345|        3529.43|       2|2024_11_17_05_46_35|\n",
      "|1012|01H4EEMMXFP26SZSD...|   Delta|      Paris 10|    14/11/2022|            SHR|        Barbalha|6/7/2023 16:55|         Tish Grills|          Female|         C3|     EUR|            B2|      Delayed|             Ag Ash|  Airbus A320|         4081.97|     1012|         7262|              KBL|           France|6/7/2023 03:33|              Brazil|    8/3/2022|          16.43|           66|              Germany|       988.2|         35.59|          F6|    Leda McPartlin|               2|               N12345|        4403.12|       2|2024_11_17_05_46_35|\n",
      "|1013|01H4EEMMXJT24WGPM...|  United|    Nanxindian|     10/8/2022|            YFG|            Piru|6/7/2023 20:49|        Jared Seldon|            Male|         A1|     CNY|            B2|    Cancelled|          Neil Laye| Embraer E190|         5001.06|     1013|         6819|              AEB|            China|6/7/2023 00:17|           Indonesia|   22/8/2022|          20.76|           75|          Switzerland|      145.67|           0.4|          E5|   Sansone Sandars|               1|               N67890|        1799.16|       2|2024_11_17_05_46_35|\n",
      "|1014|01H4EEMMXN9PVFGSP...|  United| Bulahblangaro|     17/3/2022|            JHL|       Gračanica|6/7/2023 20:45|      Giacobo Trappe|            Male|         C3|     IDR|            A1|      Delayed|       Brandy Elwin| Embraer E190|         5399.15|     1014|         5525|              CSX|        Indonesia|6/7/2023 13:37|Bosnia and Herzeg...|   16/8/2022|          20.91|           27|        United States|      999.53|         22.73|          E5|   Keven Jurgenson|               1|               N67890|         344.09|       2|2024_11_17_05_46_35|\n",
      "|1015|01H4EEMMXQW35SA18...|American|        Sigavé|     27/1/2022|            YGC|       Pampanito|6/7/2023 09:34|      Harriot Fodden|          Female|         A1|     XPF|            A1|      On Time|       Tori Mapholm|   Boeing 737|         1550.71|     1015|         3584|              LGW|Wallis and Futuna|6/7/2023 15:28|           Venezuela|  15/10/2022|          22.91|           87|          Philippines|      264.39|         32.72|          D4|    Ranna Fursland|               9|               N12345|        2059.08|       2|2024_11_17_05_46_35|\n",
      "|1016|01H4EEMMXTKFV0WD6...|   Delta|         Ḏânan|     22/6/2022|            EMA|      Washington|6/7/2023 01:13|        Heida Cousen|          Female|         B2|     DJF|            A1|      On Time|    Mame Kirkbright|  Airbus A320|         6828.06|     1016|         5349|              VDI|         Djibouti|6/7/2023 23:51|       United States|    3/5/2022|           23.8|           26|              Nigeria|      348.88|         26.46|          E5|          Meg Folk|               4|               N67890|        1716.74|       2|2024_11_17_05_46_35|\n",
      "|1017|01H4EEMMXY6BZ2E9A...|  United|    Vila Maior|      9/8/2022|            YXZ|            Kaum|6/7/2023 11:53|         Barri Tower|            Male|         B2|     EUR|            A1|    Cancelled|   Thatch Whatmough|   Boeing 737|         7170.89|     1017|         9284|              ADY|         Portugal|6/7/2023 02:52|           Indonesia|  26/11/2022|          13.43|           60|              Belarus|       90.45|         34.03|          F6|    Felike Fereday|               6|               NABCDE|        4461.17|       2|2024_11_17_05_46_35|\n",
      "|1018|01H4EEMMY2N98Z4WE...|American|      Zhangzhu|    15/11/2022|            KOK|       Širvintos|6/7/2023 00:17|         Lana Hawton|          Female|         A1|     CNY|            B2|      On Time|    Drusilla Denney| Embraer E190|         2462.14|     1018|         4614|              AXA|            China|6/7/2023 15:41|           Lithuania|   29/7/2022|           1.16|           56|         South Africa|      945.66|         23.59|          E5|  Frederica Nassie|               6|               N12345|         1413.1|       2|2024_11_17_05_46_35|\n",
      "|1019|01H4EEMMY60MBFAVH...|   Delta|       Dubrava|     15/7/2022|            OMM|       Mnelalete|6/7/2023 06:30|       Merry MacGoun|          Female|         A1|     HRK|            A1|      Delayed|      Lindie Dungay|   Boeing 737|         3735.49|     1019|         4077|              TFS|          Croatia|6/7/2023 10:14|           Indonesia|   20/9/2022|          19.56|           96|                China|      207.65|         23.81|          F6|   Tomasine Sleany|               9|               N12345|         4650.5|       2|2024_11_17_05_46_35|\n",
      "|1020|01H4EEMMY9XP71MGH...|   Delta|        Māymay|     6/11/2022|            SHS|        Yancheng|6/7/2023 05:38|       Fields Yedall|      Non-binary|         C3|     AFN|            A1|      Delayed|      Aldwin Faivre|  Airbus A320|         8037.25|     1020|         8548|              FAA|      Afghanistan|6/7/2023 17:21|               China|   29/7/2022|            2.0|           87|            Indonesia|      730.91|         18.95|          F6|   Quincey Copcutt|               2|               N12345|        3435.56|       2|2024_11_17_05_46_35|\n",
      "+----+--------------------+--------+--------------+--------------+---------------+----------------+--------------+--------------------+----------------+-----------+--------+--------------+-------------+-------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Processing microbatch 3 at 2024_11_17_05_46_40\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|batch_id|timestamp          |passenger_nationality|passenger_gender|passenger_age|avg_ticket_price  |total_ticket_price|total_passengers|\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|3       |2024_11_17_05_46_40|China                |Female          |56           |464.8566666666666 |1394.57           |3               |\n",
      "|3       |2024_11_17_05_46_40|China                |Female          |38           |330.07            |990.21            |3               |\n",
      "|3       |2024_11_17_05_46_40|China                |Female          |32           |481.4433333333333 |1444.33           |3               |\n",
      "|3       |2024_11_17_05_46_40|China                |Female          |18           |560.2833333333334 |1680.8500000000001|3               |\n",
      "|3       |2024_11_17_05_46_40|China                |Female          |79           |263.59999999999997|790.8             |3               |\n",
      "|3       |2024_11_17_05_46_40|China                |Male            |38           |655.42            |1966.2599999999998|3               |\n",
      "|3       |2024_11_17_05_46_40|China                |Male            |92           |551.1             |1653.3000000000002|3               |\n",
      "|3       |2024_11_17_05_46_40|China                |Male            |37           |327.15            |981.4499999999999 |3               |\n",
      "|3       |2024_11_17_05_46_40|China                |Male            |69           |441.94            |1325.82           |3               |\n",
      "|3       |2024_11_17_05_46_40|China                |Male            |29           |579.73            |1739.19           |3               |\n",
      "|3       |2024_11_17_05_46_40|China                |Male            |50           |690.7966666666666 |2072.39           |3               |\n",
      "|3       |2024_11_17_05_46_40|Indonesia            |Female          |57           |293.09999999999997|879.3             |3               |\n",
      "|3       |2024_11_17_05_46_40|China                |Female          |80           |473.98749999999995|1895.9499999999998|4               |\n",
      "|3       |2024_11_17_05_46_40|China                |Male            |33           |448.2925          |1793.17           |4               |\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "\n",
      "+----+--------------------+--------+----------------+--------------+---------------+--------------------+--------------+------------------+----------------+-----------+--------+--------------+-------------+-------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|  id|         secure_code| airline|  departure_city|departure_date|arrival_airport|        arrival_city|  arrival_time|    passenger_name|passenger_gender|seat_number|currency|departure_gate|flight_status|      co_pilot_name|aircraft_type|fuel_consumption|flight_id|flight_number|departure_airport|departure_country|departure_time|     arrival_country|arrival_date|flight_duration|passenger_age|passenger_nationality|ticket_price|baggage_weight|arrival_gate|        pilot_name|cabin_crew_count|aircraft_registration|flight_distance|batch_id|          timestamp|\n",
      "+----+--------------------+--------+----------------+--------------+---------------+--------------------+--------------+------------------+----------------+-----------+--------+--------------+-------------+-------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|2001|01H4EEMR8K4ZX4H7G...|  United|       Ust’-Isha|    21/10/2022|            UVL|        Kristinehamn|6/7/2023 19:03|  Othello Spittall|     Genderfluid|         C3|     RUB|            C3|      Delayed|       Carson Ayres| Embraer E190|         4841.93|     2001|         6150|              TAM|           Russia|6/7/2023 17:28|              Sweden|   23/8/2022|          14.79|           68|              Senegal|      982.47|          7.43|          F6|     Gordy Finessy|               3|               N67890|        2905.35|       3|2024_11_17_05_46_40|\n",
      "|2002|01H4EEMR8PFBCHHYE...|  United|        Khoyniki|    17/10/2022|            MPG|            Miracema|6/7/2023 17:53|Fletch Pendlington|            Male|         C3|     BYR|            B2|    Cancelled|     Grantley Rozea|  Airbus A320|         3779.14|     2002|          481|                0|          Belarus|6/7/2023 20:10|              Brazil|   18/2/2022|          17.85|           29|                China|      474.16|          19.3|          F6|      Ernest Robbe|               1|               NABCDE|        2007.26|       3|2024_11_17_05_46_40|\n",
      "|2003|01H4EEMR8SKKFFPJA...|  United|          Osório|     29/7/2022|            LNA|   Vilar do Pinheiro|6/7/2023 06:38|    Susie Presidey|          Female|         C3|     BRL|            A1|      Delayed|Philly Franzettoini| Embraer E190|         9311.26|     2003|          115|              SWM|           Brazil|6/7/2023 19:54|            Portugal|  27/10/2022|          11.04|           84|               Brazil|      701.09|          7.03|          E5|    Karina Coveley|               7|               N12345|        3716.09|       3|2024_11_17_05_46_40|\n",
      "|2004|01H4EEMR8VBDBCEB4...|  United|            Trới|     10/4/2022|            CMC|              Nanger|6/7/2023 22:19|        Dunn Steel|            Male|         A1|     VND|            B2|      On Time|         Hunt Soles|  Airbus A320|         9448.42|     2004|         2190|              INL|          Vietnam|6/7/2023 08:09|           Indonesia|   27/8/2022|          14.06|           55|                 Peru|      328.59|         20.49|          F6| Worden Hutchcraft|               9|               NABCDE|        4402.55|       3|2024_11_17_05_46_40|\n",
      "|2005|01H4EEMR8Y8QZB4EB...|   Delta|    La Esmeralda|      2/1/2022|            NOM|          Calebasses|6/7/2023 13:25|    Mischa Rihosek|            Male|         B2|     VEF|            B2|      Delayed|           Car Sams| Embraer E190|         9137.93|     2005|          146|              YUA|        Venezuela|6/7/2023 15:30|           Mauritius|   14/1/2022|           15.0|           80|          Philippines|       357.2|         25.66|          F6|         Ugo Tutin|               7|               N12345|        2534.23|       3|2024_11_17_05_46_40|\n",
      "|2006|01H4EEMR91N5YZBW4...|American|         Obihiro|     21/4/2022|            WGN|              Vihāri|6/7/2023 04:40|     Markos Jancic|            Male|         A1|     JPY|            B2|      On Time|     Allard Dewdeny|   Boeing 737|         5775.05|     2006|          347|              CMI|            Japan|6/7/2023 04:33|            Pakistan|    4/4/2022|          17.26|           89|                Egypt|       790.4|         41.77|          E5|    Lucias Haswell|              10|               N67890|        4070.81|       3|2024_11_17_05_46_40|\n",
      "|2007|01H4EEMR94CV09C1G...|American|           Hotsk|     28/6/2022|            OHO|              Masjid|6/7/2023 04:04|  Loretta Duggleby|          Female|         A1|     BYR|            B2|    Cancelled|      Perri Faucett| Embraer E190|         9162.91|     2007|         8287|              NOP|          Belarus|6/7/2023 13:15|           Indonesia|    5/7/2022|          11.73|           34|        United States|      471.23|          3.73|          E5|     Norene Stoeck|               5|               N12345|        4610.89|       3|2024_11_17_05_46_40|\n",
      "|2008|01H4EEMR99RHGGY8S...|   Delta|            Ujar|     21/3/2022|            NRT|         Yanghuxiang|6/7/2023 14:33|        Dory Proud|          Female|         B2|     AZN|            A1|      Delayed|      Bobbee Voller|  Airbus A320|         3349.44|     2008|         7627|              EVA|       Azerbaijan|6/7/2023 23:46|               China|   26/5/2022|           8.96|           77|               Canada|      809.92|         42.05|          F6|   Teriann Mugford|               1|               NABCDE|        2663.78|       3|2024_11_17_05_46_40|\n",
      "|2009|01H4EEMR9CM89ZM8F...|American|         Linshui|     30/3/2022|            JUI|          Maluanluan|6/7/2023 17:19|     Selie Lanston|          Female|         A1|     CNY|            A1|    Cancelled|   Caresse McGaugie|   Boeing 737|         2628.44|     2009|         8084|              JMK|            China|6/7/2023 03:51|         Philippines|   27/4/2022|           10.8|           67|             Slovenia|      869.76|         39.28|          E5| Lavena Innerstone|               7|               N67890|        3016.51|       3|2024_11_17_05_46_40|\n",
      "|2010|01H4EEMR9F1SCQSJY...|American|           Modot|      5/5/2022|            BBH|                 Uyo|6/7/2023 16:42|   Charil Cullinan|     Genderfluid|         C3|     MNT|            C3|      On Time|       Myron Ayrton| Embraer E190|         4374.83|     2010|         9037|              PBF|         Mongolia|6/7/2023 09:13|             Nigeria|  30/12/2022|           2.54|          100|                China|      541.74|         22.81|          F6|       Con Warlawe|               7|               N67890|        1633.32|       3|2024_11_17_05_46_40|\n",
      "|2011|01H4EEMR9J3B21X0Q...|  United|  Jaraguá do Sul|     16/6/2022|            EBW|             Dobřany|6/7/2023 19:15|      Donna Strass|          Female|         A1|     BRL|            A1|    Cancelled|    Gretel Caulcott|  Airbus A320|         1689.77|     2011|         4229|              LDH|           Brazil|6/7/2023 13:27|      Czech Republic|   19/9/2022|           7.62|           38|                China|      481.35|         16.82|          E5|Kissiah Giacomelli|               5|               NABCDE|        3129.88|       3|2024_11_17_05_46_40|\n",
      "|2012|01H4EEMR9NRFARRFR...|  United|   Campo Quijano|    12/11/2022|            BIL|          As Sukhnah|6/7/2023 09:24|       Flinn Petti|            Male|         B2|     ARS|            B2|      Delayed|       Pavel Ivanov| Embraer E190|         8201.46|     2012|         4265|              VPY|        Argentina|6/7/2023 16:36|               Syria|   29/7/2022|          22.31|           92|               Sweden|       136.2|          8.04|          E5|       Bronny Tuke|               2|               NABCDE|         3375.1|       3|2024_11_17_05_46_40|\n",
      "|2013|01H4EEMR9RWAPHP7Y...|   Delta|Krajan Tegalombo|     28/8/2022|            THA|        Dorp Antriol|6/7/2023 06:49|     Corrine Marty|        Bigender|         A1|     IDR|            B2|      On Time|       Petr Vautrey|   Boeing 737|         7475.08|     2013|         4368|              RAF|        Indonesia|6/7/2023 10:50|Bonaire, Saint Eu...|   25/9/2022|          11.78|           57|                China|      639.19|         33.16|          E5| Juline Minchinden|               3|               N12345|        2380.44|       3|2024_11_17_05_46_40|\n",
      "|2014|01H4EEMR9V9N9MEKZ...|American|    Casa Quemada|     18/7/2022|            NJA|                Saki|6/7/2023 11:53|      Mella Durdle|          Female|         A1|     HNL|            A1|      Delayed|          Sal Samme| Embraer E190|         6494.78|     2014|         5955|              CZX|         Honduras|6/7/2023 08:23|             Nigeria|   13/3/2022|          19.22|          100|                China|      786.04|         31.25|          E5|    Rianon Milkins|               7|               NABCDE|        2841.42|       3|2024_11_17_05_46_40|\n",
      "|2015|01H4EEMR9XD3JVK7N...|  United| Juvisy-sur-Orge|     15/8/2022|            DBY|Shangcheng Chengg...|6/7/2023 11:31|       Glori Todeo|     Genderfluid|         C3|     EUR|            B2|      Delayed|    Walden Runnalls| Embraer E190|         4656.42|     2015|         8703|              LEA|           France|6/7/2023 20:51|               China|   16/8/2022|          20.12|           34|                China|      441.04|         44.61|          E5|      Evita Kegley|               8|               N12345|         422.97|       3|2024_11_17_05_46_40|\n",
      "|2016|01H4EEMRA04BRM4YY...|   Delta|            Mesa|     24/9/2022|            ATG|                Gōdo|6/7/2023 06:06|   Clim Durrington|            Male|         C3|     USD|            B2|    Cancelled|    Cullin Shergold|   Boeing 737|         2315.39|     2016|         9250|              JAF|    United States|6/7/2023 04:52|               Japan|   18/4/2022|          22.33|           38|                China|      874.39|           5.8|          F6|      Paul Broggio|              10|               N67890|        2530.48|       3|2024_11_17_05_46_40|\n",
      "|2017|01H4EEMRA3XKBXCQ7...|   Delta|  Vanderbijlpark|    12/11/2022|            VAK|          Lindavista|6/7/2023 13:03|     Brandy Traves|          Female|         B2|     ZAR|            B2|      On Time|    Barbi Robillard| Embraer E190|         2619.94|     2017|         8778|              FAC|     South Africa|6/7/2023 02:50|              Mexico|  13/12/2022|          15.84|           95|              Senegal|      941.73|         39.77|          D4|     Jeniece Villa|               4|               N67890|        2028.72|       3|2024_11_17_05_46_40|\n",
      "|2018|01H4EEMRA6F41VYEC...|American|Cachoeira do Sul|     27/5/2022|            SCV|         Chapultepec|6/7/2023 08:29|   Isabel Purchall|          Female|         B2|     BRL|            B2|      On Time|    Gail Giacomuzzo| Embraer E190|         3407.78|     2018|         9432|              PNS|           Brazil|6/7/2023 12:24|              Mexico|   22/2/2022|          15.92|           75|              Ukraine|      600.92|         49.94|          E5|      Cassi Gorton|               6|               NABCDE|        3141.88|       3|2024_11_17_05_46_40|\n",
      "|2019|01H4EEMRA9QNK333T...|American|      Kotatengah|      3/1/2022|            YXL|             Arcueil|6/7/2023 06:04|      Lita Burrell|          Female|         A1|     IDR|            A1|      Delayed|      Kimmie Regitz|   Boeing 737|         1660.32|     2019|         3598|              YLY|        Indonesia|6/7/2023 06:56|              France|    6/1/2022|          11.81|           78|               Russia|      242.65|         39.71|          F6|      Rhodia Hesey|               5|               N12345|        4846.85|       3|2024_11_17_05_46_40|\n",
      "|2020|01H4EEMRACD95JMMZ...|American|         Gandara|    19/10/2022|            KRC|           Abadiânia|6/7/2023 00:33|Doralynne Eversley|          Female|         B2|     EUR|            C3|      Delayed|     Agnese Bertlin|   Boeing 737|         7780.92|     2020|         2780|              MXY|         Portugal|6/7/2023 01:23|              Brazil|  14/11/2022|          19.01|          100|             Mongolia|      257.91|         49.54|          D4|   Stevena Cathery|               2|               N67890|        4819.25|       3|2024_11_17_05_46_40|\n",
      "+----+--------------------+--------+----------------+--------------+---------------+--------------------+--------------+------------------+----------------+-----------+--------+--------------+-------------+-------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Processing microbatch 4 at 2024_11_17_05_46_50\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|batch_id|timestamp          |passenger_nationality|passenger_gender|passenger_age|avg_ticket_price  |total_ticket_price|total_passengers|\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|4       |2024_11_17_05_46_50|China                |Female          |88           |689.8100000000001 |2069.4300000000003|3               |\n",
      "|4       |2024_11_17_05_46_50|China                |Female          |40           |405.80999999999995|1217.4299999999998|3               |\n",
      "|4       |2024_11_17_05_46_50|China                |Male            |74           |182.43666666666664|547.31            |3               |\n",
      "|4       |2024_11_17_05_46_50|China                |Male            |81           |455.77000000000004|1367.3100000000002|3               |\n",
      "|4       |2024_11_17_05_46_50|China                |Male            |75           |251.74            |755.22            |3               |\n",
      "|4       |2024_11_17_05_46_50|China                |Male            |67           |543.4133333333333 |1630.2399999999998|3               |\n",
      "|4       |2024_11_17_05_46_50|Indonesia            |Female          |72           |379.4433333333333 |1138.33           |3               |\n",
      "|4       |2024_11_17_05_46_50|Indonesia            |Male            |18           |484.02666666666664|1452.08           |3               |\n",
      "|4       |2024_11_17_05_46_50|Poland               |Male            |85           |826.87            |2480.61           |3               |\n",
      "|4       |2024_11_17_05_46_50|China                |Male            |79           |514.655           |2058.62           |4               |\n",
      "|4       |2024_11_17_05_46_50|China                |Male            |18           |452.0274999999999 |1808.1099999999997|4               |\n",
      "|4       |2024_11_17_05_46_50|China                |Male            |58           |704.3225          |2817.29           |4               |\n",
      "|4       |2024_11_17_05_46_50|China                |Male            |91           |636.2925          |2545.17           |4               |\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "\n",
      "+----+--------------------+--------+---------------+--------------+---------------+------------+--------------+-----------------+----------------+-----------+--------+--------------+-------------+------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|  id|         secure_code| airline| departure_city|departure_date|arrival_airport|arrival_city|  arrival_time|   passenger_name|passenger_gender|seat_number|currency|departure_gate|flight_status|     co_pilot_name|aircraft_type|fuel_consumption|flight_id|flight_number|departure_airport|departure_country|departure_time|     arrival_country|arrival_date|flight_duration|passenger_age|passenger_nationality|ticket_price|baggage_weight|arrival_gate|          pilot_name|cabin_crew_count|aircraft_registration|flight_distance|batch_id|          timestamp|\n",
      "+----+--------------------+--------+---------------+--------------+---------------+------------+--------------+-----------------+----------------+-----------+--------+--------------+-------------+------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|3001|01H4EEMVMVDV5SDHP...|  United|     Lewograran|      4/2/2022|            BGO|     Čajniče|6/7/2023 05:14|    Paquito Molan|            Male|         C3|     IDR|            B2|      Delayed|     Jud Goldspink|   Boeing 737|         1140.93|     3001|         6712|              DRW|        Indonesia|6/7/2023 05:22|Bosnia and Herzeg...|    9/9/2022|           1.82|           58|               Poland|      409.92|         36.57|          F6|          Bil Gittis|               7|               N67890|         347.53|       4|2024_11_17_05_46_50|\n",
      "|3002|01H4EEMVMYRMKR5RY...|  United|   Capitão Poço|     26/3/2022|            AUU|      Llauta|6/7/2023 15:33|    Otis Izkovici|            Male|         C3|     BRL|            C3|      Delayed|    Dougie Hendron|   Boeing 737|         9927.09|     3002|         6018|              KRV|           Brazil|6/7/2023 20:35|                Peru|   15/4/2022|           4.09|           31|               France|      663.18|          30.6|          E5|     Lock O'Hartigan|               5|               N12345|        1326.09|       4|2024_11_17_05_46_50|\n",
      "|3003|01H4EEMVN126AAKF6...|  United|          Enzan|    25/10/2022|            GIS|    Kil’mez’|6/7/2023 13:40|    Xena Georgins|          Female|         A1|     JPY|            C3|      Delayed|      Ketti Domini|   Boeing 737|         3519.36|     3003|          907|              RAV|            Japan|6/7/2023 21:54|              Russia|  20/10/2022|          17.54|           26|               Poland|      111.71|         18.78|          D4|Jillane De Cristo...|               9|               N67890|        3257.31|       4|2024_11_17_05_46_50|\n",
      "|3004|01H4EEMVN4BA0PYWX...|  United|    Phitsanulok|     17/8/2022|            TEN|       Thala|6/7/2023 01:14|     Corrie Maken|          Female|         A1|     THB|            C3|      Delayed| Loretta Wellesley|   Boeing 737|          6988.0|     3004|         6756|              JAP|         Thailand|6/7/2023 22:57|             Tunisia|   25/1/2022|           5.47|           60|                 Iran|      359.91|         28.69|          D4|    Elisabeth Hylden|              10|               N67890|        3887.37|       4|2024_11_17_05_46_50|\n",
      "|3005|01H4EEMVN79C0X9KZ...|  United|      Changxing|    28/10/2022|            BCM|      Zhaixi|6/7/2023 17:58| Jarred Shoesmith|            Male|         C3|     CNY|            C3|      Delayed|Maximilien Windham|   Boeing 737|         5603.39|     3005|         3574|              BDG|            China|6/7/2023 15:40|               China|   1/10/2022|          20.06|           35|             Mongolia|      518.89|         46.99|          F6|       Rodger Lampen|               4|               NABCDE|        1547.72|       4|2024_11_17_05_46_50|\n",
      "|3006|01H4EEMVNANRMJPN7...|   Delta|      Biny Selo|     2/11/2022|            AIV|        Rama|6/7/2023 08:03|     Anni Barbery|          Female|         B2|     AZN|            C3|    Cancelled|  Matelda Alldritt|   Boeing 737|         3152.84|     3006|         3974|              DNK|       Azerbaijan|6/7/2023 00:44|           Nicaragua|   29/6/2022|          23.84|           88|               Poland|      899.77|         30.96|          D4|      Margy Guerreru|               9|               N67890|         407.14|       4|2024_11_17_05_46_50|\n",
      "|3007|01H4EEMVND8FZCEX2...|American|          Saijō|     21/5/2022|            SHK|    Erdaocha|6/7/2023 20:26|   Lonny Stickels|            Male|         B2|     JPY|            C3|      On Time|  Mitchael Boteman|   Boeing 737|         4737.05|     3007|         2086|              IQA|            Japan|6/7/2023 00:52|               China|    7/3/2022|           8.94|           73|            Indonesia|      713.57|         45.07|          F6|      Balduin Dickie|               9|               NABCDE|        2037.57|       4|2024_11_17_05_46_50|\n",
      "|3008|01H4EEMVNFF0G20ZK...|  United|          Uthal|      1/8/2022|            MDY|      Skoura|6/7/2023 02:48|      Ragnar Wais|            Male|         C3|     PKR|            A1|    Cancelled|   Jamesy Rickerby|  Airbus A320|         6080.46|     3008|         6897|              GCJ|         Pakistan|6/7/2023 04:16|             Morocco|   7/12/2022|          12.65|           61|            Indonesia|      821.35|         11.86|          E5|  Westleigh Andrioli|               7|               N12345|        2854.91|       4|2024_11_17_05_46_50|\n",
      "|3009|01H4EEMVNJ9EHNKWN...|   Delta|        Baolong|     27/1/2022|            PUX|      Yelan’|6/7/2023 07:28|   Bryant Cropton|            Male|         A1|     CNY|            B2|      Delayed|    Erick Readhead|   Boeing 737|         7073.32|     3009|         3990|              CTH|            China|6/7/2023 18:23|              Russia|   17/2/2022|          23.87|           80|               Russia|      379.46|         49.81|          F6|       Billy Burdess|              10|               N12345|        4723.92|       4|2024_11_17_05_46_50|\n",
      "|3010|01H4EEMVNNWKJM9QV...|  United|    Prosperidad|    19/12/2022|            AQP|     Yên Bái|6/7/2023 13:36|       Kalvin Bow|            Male|         A1|     PHP|            C3|    Cancelled|   Pietrek Playden|  Airbus A320|         5665.73|     3010|         7103|              SVA|      Philippines|6/7/2023 08:35|             Vietnam|  28/12/2022|           1.99|           92|               Russia|      550.73|         31.96|          E5|       Grove Cossell|               2|               N12345|        2951.54|       4|2024_11_17_05_46_50|\n",
      "|3011|01H4EEMVNR8W9ZGAE...|   Delta|        Taikang|     21/9/2022|            RZA|     Haumeni|6/7/2023 02:15|       Lyn Kittle|          Female|         C3|     CNY|            C3|    Cancelled|        Bibi Carik| Embraer E190|         6803.72|     3011|         2923|              SLN|            China|6/7/2023 11:13|           Indonesia|   30/3/2022|          18.81|           32|                China|      695.46|         39.13|          E5|   Fay O'Kynsillaghe|               9|               N12345|        1159.33|       4|2024_11_17_05_46_50|\n",
      "|3012|01H4EEMVNV23FPBP7...|American|          Pelem|     31/7/2022|            VCV|     Jihlava|6/7/2023 13:02|   Basil Mozzetti|            Male|         A1|     IDR|            C3|    Cancelled|     Talbert Barck| Embraer E190|         6101.28|     3012|         1561|              PBH|        Indonesia|6/7/2023 10:46|      Czech Republic|   20/5/2022|          19.08|           48|            Indonesia|      115.28|         12.64|          E5|     Jeremy Petrenko|               2|               N67890|         443.26|       4|2024_11_17_05_46_50|\n",
      "|3013|01H4EEMVNYX6VS5D6...|  United|      Xitieshan|     29/7/2022|            AGE|  Nueva Loja|6/7/2023 08:36|      Kelsy Navan|          Female|         B2|     CNY|            A1|      On Time|       Rani Tabert|   Boeing 737|         6298.39|     3013|         4624|              BOY|            China|6/7/2023 02:44|             Ecuador|   16/8/2022|          16.23|           67|            Argentina|      288.93|         38.04|          E5|     Tammie Crommett|               5|               N12345|        4399.32|       4|2024_11_17_05_46_50|\n",
      "|3014|01H4EEMVP1RK5T6SX...|  United|       Tabalong|    20/12/2022|            IQQ|      Miętne|6/7/2023 10:53|    Jarrad Anglin|            Male|         A1|     PHP|            C3|    Cancelled|       Patric Nani|   Boeing 737|         1406.07|     3014|         7268|              LZI|      Philippines|6/7/2023 11:29|              Poland|   19/3/2022|          13.76|           93|            Indonesia|      844.43|         39.72|          F6|       Eugene Hurles|               1|               NABCDE|        1667.79|       4|2024_11_17_05_46_50|\n",
      "|3015|01H4EEMVP4N8WF1TM...|American|         Khōshī|    12/12/2022|            DEP|    Nahāvand|6/7/2023 11:58|Emlynne Clemensen|          Female|         A1|     AFN|            B2|      Delayed|   Bertine Gilbert| Embraer E190|         6451.83|     3015|          993|              NCO|      Afghanistan|6/7/2023 14:26|                Iran|   26/8/2022|          16.16|           35|              Germany|      163.23|         46.21|          D4|Jessalin Domenich...|               4|               NABCDE|        3874.91|       4|2024_11_17_05_46_50|\n",
      "|3016|01H4EEMVP7A3H0FGZ...|  United| Kout na Šumavě|     25/1/2022|            CXR|      Bilice|6/7/2023 13:31|  Jodie Philippon|            Male|         B2|     CZK|            C3|      On Time|Tobit Kettlestring| Embraer E190|         7765.82|     3016|         4814|                0|   Czech Republic|6/7/2023 15:27|             Croatia|    2/1/2022|          11.86|           49|            Indonesia|      595.83|         32.91|          F6|       Gill Steggles|               5|               N12345|         1537.0|       4|2024_11_17_05_46_50|\n",
      "|3017|01H4EEMVPAX52FR68...|  United|       Petřvald|     8/11/2022|            CGP|   Zhangyelu|6/7/2023 09:01|Stephan Pottberry|            Male|         B2|     CZK|            B2|      On Time|    Gardie Chawner|   Boeing 737|         5751.91|     3017|         7809|              MJL|   Czech Republic|6/7/2023 13:38|               China|    3/9/2022|          10.17|           32|               Panama|      948.05|         23.63|          F6|   Newton MacCulloch|               6|               N12345|        2810.95|       4|2024_11_17_05_46_50|\n",
      "|3018|01H4EEMVPEW03WB5W...|   Delta|          Oefau|     15/1/2022|            HEW|      Lianyi|6/7/2023 00:47|       Drona Riby|          Female|         B2|     IDR|            C3|    Cancelled|   Kissiah Karpets|  Airbus A320|          7239.6|     3018|          530|              AIL|        Indonesia|6/7/2023 13:16|               China|   22/2/2022|           22.1|           71|               Brazil|      601.57|          2.14|          D4|       Sharon Deamer|               1|               N67890|        4829.68|       4|2024_11_17_05_46_50|\n",
      "|3019|01H4EEMVPHRNE5KYQ...|  United|Vitry-sur-Seine|    29/12/2022|            CAP|     Lannion|6/7/2023 01:04|    Reid Daniells|            Male|         C3|     EUR|            A1|    Cancelled|   Leonid Carnduff|   Boeing 737|         8743.02|     3019|         3885|              URZ|           France|6/7/2023 10:36|              France|   29/3/2022|          15.44|           26|            Macedonia|      922.98|         21.39|          D4|          Jeno Morot|              10|               NABCDE|        3446.17|       4|2024_11_17_05_46_50|\n",
      "|3020|01H4EEMVPKDYN838W...|   Delta|       Rockford|    22/12/2022|            LUL|   Whakatane|6/7/2023 19:28|  Luise Sinisbury|          Female|         A1|     USD|            B2|    Cancelled|    Mareah Chesher| Embraer E190|         6488.22|     3020|         9455|              GNM|    United States|6/7/2023 09:05|         New Zealand|   20/5/2022|           6.52|           63|               Sweden|      889.22|         28.83|          E5|       Wendi Patroni|               3|               NABCDE|        3070.89|       4|2024_11_17_05_46_50|\n",
      "+----+--------------------+--------+---------------+--------------+---------------+------------+--------------+-----------------+----------------+-----------+--------+--------------+-------------+------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+--------------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Processing microbatch 5 at 2024_11_17_05_47_00\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|batch_id|timestamp          |passenger_nationality|passenger_gender|passenger_age|avg_ticket_price  |total_ticket_price|total_passengers|\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "|5       |2024_11_17_05_47_00|China                |Female          |26           |243.08333333333334|729.25            |3               |\n",
      "|5       |2024_11_17_05_47_00|China                |Female          |40           |310.0433333333333 |930.1299999999999 |3               |\n",
      "|5       |2024_11_17_05_47_00|China                |Female          |88           |637.7766666666666 |1913.33           |3               |\n",
      "|5       |2024_11_17_05_47_00|China                |Male            |30           |702.2133333333335 |2106.6400000000003|3               |\n",
      "|5       |2024_11_17_05_47_00|China                |Male            |86           |487.79            |1463.3700000000001|3               |\n",
      "|5       |2024_11_17_05_47_00|China                |Male            |26           |501.40333333333325|1504.2099999999998|3               |\n",
      "|5       |2024_11_17_05_47_00|China                |Male            |57           |754.3233333333333 |2262.97           |3               |\n",
      "|5       |2024_11_17_05_47_00|China                |Male            |99           |527.57            |1582.71           |3               |\n",
      "|5       |2024_11_17_05_47_00|Indonesia            |Female          |89           |456.5866666666666 |1369.7599999999998|3               |\n",
      "|5       |2024_11_17_05_47_00|Indonesia            |Female          |57           |377.4433333333333 |1132.33           |3               |\n",
      "|5       |2024_11_17_05_47_00|Indonesia            |Male            |24           |650.1233333333333 |1950.37           |3               |\n",
      "|5       |2024_11_17_05_47_00|Indonesia            |Male            |34           |408.89000000000004|1226.67           |3               |\n",
      "|5       |2024_11_17_05_47_00|Indonesia            |Male            |36           |257.6266666666667 |772.8800000000001 |3               |\n",
      "|5       |2024_11_17_05_47_00|Russia               |Male            |69           |435.7966666666666 |1307.3899999999999|3               |\n",
      "|5       |2024_11_17_05_47_00|Indonesia            |Female          |85           |706.0025          |2824.01           |4               |\n",
      "+--------+-------------------+---------------------+----------------+-------------+------------------+------------------+----------------+\n",
      "\n",
      "+----+--------------------+--------+--------------+--------------+---------------+--------------------+--------------+----------------+----------------+-----------+--------+--------------+-------------+------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|  id|         secure_code| airline|departure_city|departure_date|arrival_airport|        arrival_city|  arrival_time|  passenger_name|passenger_gender|seat_number|currency|departure_gate|flight_status|     co_pilot_name|aircraft_type|fuel_consumption|flight_id|flight_number|departure_airport|departure_country|departure_time|arrival_country|arrival_date|flight_duration|passenger_age|passenger_nationality|ticket_price|baggage_weight|arrival_gate|          pilot_name|cabin_crew_count|aircraft_registration|flight_distance|batch_id|          timestamp|\n",
      "+----+--------------------+--------+--------------+--------------+---------------+--------------------+--------------+----------------+----------------+-----------+--------+--------------+-------------+------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "|4001|01H4EEMZ2SXKZAF4E...|  United|     Xiabaishi|     1/12/2022|            VPZ|         Saltsjö-Boo|6/7/2023 07:38|    Erasmus Grim|     Genderqueer|         C3|     CNY|            A1|      On Time|       Brandy Epps| Embraer E190|         2394.39|     4001|         4693|              NTD|            China|6/7/2023 09:12|         Sweden|   16/5/2022|          11.36|           81|                China|      150.89|         29.04|          F6|     Karlik Clemetts|               8|               N12345|        3621.45|       5|2024_11_17_05_47_00|\n",
      "|4002|01H4EEMZ2WS3WW5CZ...|  United|       Mê Linh|     12/8/2022|            MWD|              Sogati|6/7/2023 13:29|      Cam Aucock|            Male|         B2|     VND|            C3|    Cancelled|Stanleigh Pickring|   Boeing 737|         7216.32|     4002|         8158|              UNK|          Vietnam|6/7/2023 21:27|      Indonesia|  29/11/2022|          12.04|           21|                 Peru|      455.35|         48.34|          F6|    Bentley Liddyard|               6|               N12345|        1711.91|       5|2024_11_17_05_47_00|\n",
      "|4003|01H4EEMZ2ZW67GYEM...|  United|  Buenos Aires|    25/12/2022|            WPK|       Weiwangzhuang|6/7/2023 16:50|   Finlay Wickes|            Male|         A1|     PEN|            B2|    Cancelled|      Fee Bilsford|   Boeing 737|         8360.83|     4003|         2466|              YPY|             Peru|6/7/2023 05:09|          China|  25/12/2022|          19.34|           66|               Brazil|      215.23|         11.09|          E5|  Garreth O'Doireidh|               2|               N12345|          296.9|       5|2024_11_17_05_47_00|\n",
      "|4004|01H4EEMZ31684170Q...|  United|  Tosontsengel|     27/3/2022|            FXO|           Luozhuang|6/7/2023 21:10|     Hyman Bever|            Male|         B2|     MNT|            C3|      On Time|Jefferson McSorley|  Airbus A320|         5421.46|     4004|         4808|              OBI|         Mongolia|6/7/2023 13:19|          China|   19/7/2022|          13.39|           55|       Czech Republic|      943.96|          0.44|          F6|       Prent Durston|               5|               N67890|        3848.62|       5|2024_11_17_05_47_00|\n",
      "|4005|01H4EEMZ34D4N4G1A...|American|       Lingion|    13/11/2022|            TUM|           Razumnoye|6/7/2023 18:32| Nicholas Shoute|         Agender|         C3|     PHP|            C3|      Delayed|   Munmro Shobrook|  Airbus A320|         4692.56|     4005|         7780|              WOW|      Philippines|6/7/2023 12:58|         Russia|   23/6/2022|           5.97|           50|            Guatemala|      800.65|         39.53|          E5|         Ilse Boleyn|               5|               N12345|        2686.87|       5|2024_11_17_05_47_00|\n",
      "|4006|01H4EEMZ3715ATHW6...|  United|         Xi’an|     20/7/2022|            AGE|               Dadus|6/7/2023 17:31|    Anna Janusik|          Female|         B2|     CNY|            A1|    Cancelled|     Starr Muttitt|  Airbus A320|          9098.8|     4006|         3020|              CYX|            China|6/7/2023 19:06|    Philippines|  24/12/2022|           5.97|           65|             Thailand|        88.2|         14.71|          E5|     Chloris Clemson|               8|               NABCDE|        2550.13|       5|2024_11_17_05_47_00|\n",
      "|4007|01H4EEMZ3A36BRPP7...|  United|    Louisville|     19/4/2022|            SBQ|             Pengshi|6/7/2023 16:22|    Galvan Conen|            Male|         A1|     USD|            A1|      Delayed|       Mick Yeeles|  Airbus A320|         7936.96|     4007|         9094|              APR|    United States|6/7/2023 08:16|          China|   28/8/2022|           1.25|           69|               Russia|      591.46|         30.86|          F6| Eziechiele Yanukhin|               6|               N12345|         508.38|       5|2024_11_17_05_47_00|\n",
      "|4008|01H4EEMZ3DH0JP5ZW...|American|     Tianhekou|    18/12/2022|            FAN|             Byczyna|6/7/2023 02:07|  Elga Brittoner|     Genderqueer|         B2|     CNY|            B2|      On Time|   Merrilee Hepher|   Boeing 737|         6015.65|     4008|         3479|              NIA|            China|6/7/2023 16:06|         Poland|   29/4/2022|          16.78|           89|                China|      606.42|         37.33|          F6|L;urette Klemensi...|               9|               NABCDE|        2732.92|       5|2024_11_17_05_47_00|\n",
      "|4009|01H4EEMZ3GA5ERHG2...|   Delta|       Palmira|    10/11/2022|            HOY|         Puente Alto|6/7/2023 05:35| Giulia Stanyard|          Female|         A1|     CUP|            C3|      On Time|     Kimberley Cox|  Airbus A320|          2313.6|     4009|         6575|              HAN|             Cuba|6/7/2023 06:49|          Chile|  21/10/2022|          18.92|           66|               Brazil|      510.82|         37.64|          D4|        Milka Phelip|              10|               N12345|        2244.74|       5|2024_11_17_05_47_00|\n",
      "|4010|01H4EEMZ3JM7SVK45...|  United|       Saratov|      4/2/2022|            URC|                Erqu|6/7/2023 06:43|   Yorgo Crevagh|            Male|         A1|     RUB|            B2|      Delayed|      Tonnie Sugge|  Airbus A320|         4166.37|     4010|         7556|              COB|           Russia|6/7/2023 03:35|          China|    9/4/2022|           7.39|           27|                China|      352.64|         18.91|          E5|         Chuck Karle|               6|               N12345|        2054.21|       5|2024_11_17_05_47_00|\n",
      "|4011|01H4EEMZ3NJXP2YQ6...|  United|        Wichit|     16/7/2022|            SWH|          Pindi Gheb|6/7/2023 18:38|   Zora Gransden|      Polygender|         C3|     THB|            C3|    Cancelled|      Olin Niblock|   Boeing 737|          7841.5|     4011|         7459|              ZUL|         Thailand|6/7/2023 20:04|       Pakistan|    7/4/2022|          23.35|           74|               Uganda|       752.9|          6.87|          D4|        Lilly Selman|               1|               N67890|         933.04|       5|2024_11_17_05_47_00|\n",
      "|4012|01H4EEMZ3R8717JMW...|   Delta|        Siaton|     27/1/2022|            LID|           Liangting|6/7/2023 08:24|    Hadria Palek|          Female|         A1|     PHP|            A1|      On Time|    Evania Milmith|   Boeing 737|         2251.44|     4012|         4222|              STC|      Philippines|6/7/2023 23:14|          China|    6/8/2022|          20.64|           71|               Russia|      146.37|          28.4|          F6|        Calli Duffer|               9|               N67890|        3071.08|       5|2024_11_17_05_47_00|\n",
      "|4013|01H4EEMZ3VN81QE2K...|  United|      Kengyuan|      1/3/2022|            BSW|               Lebak|6/7/2023 04:41| Tobias Madgwick|     Genderqueer|         B2|     CNY|            A1|    Cancelled|     Portie Armour|  Airbus A320|         9524.27|     4013|         9396|              TOC|            China|6/7/2023 02:58|      Indonesia|  12/10/2022|           6.23|           42|               Poland|      789.11|         40.11|          E5|   Gorden Biaggiotti|              10|               NABCDE|         4339.5|       5|2024_11_17_05_47_00|\n",
      "|4014|01H4EEMZ3Y8X5GCPW...|  United|     Yuqunweng|    29/11/2022|            IGG|           Gujiadian|6/7/2023 20:58|  Adolph Authers|            Male|         B2|     CNY|            C3|      On Time|  Theodoric Winear|  Airbus A320|         2898.94|     4014|         1974|              VCF|            China|6/7/2023 21:41|          China|   15/8/2022|          20.56|           41|               Russia|      220.54|         34.67|          E5|        Brew Jerrems|               4|               NABCDE|        1593.54|       5|2024_11_17_05_47_00|\n",
      "|4015|01H4EEMZ41ZW530RC...|  United|      Křižanov|     13/7/2022|            CUU|            Diaofeng|6/7/2023 02:01|  Merrel Maroney|            Male|         A1|     CZK|            B2|      Delayed| Forrester Keohane|   Boeing 737|         3862.35|     4015|         8595|              PBP|   Czech Republic|6/7/2023 09:56|          China|   13/3/2022|          18.34|           21|               Serbia|      372.29|         44.18|          E5|        Arny Whatham|               5|               NABCDE|        4975.33|       5|2024_11_17_05_47_00|\n",
      "|4016|01H4EEMZ43S0AWGF3...|American|         Panay|     29/5/2022|            MAX|              Huazhu|6/7/2023 01:04|Sebastian Allitt|            Male|         C3|     PHP|            B2|      Delayed|   Camey Barkhouse|  Airbus A320|         8720.71|     4016|         6493|              BOA|      Philippines|6/7/2023 21:23|          China|   15/6/2022|          16.61|           19|              Austria|      580.01|          4.57|          F6|      Riobard Skitch|               9|               NABCDE|        4069.38|       5|2024_11_17_05_47_00|\n",
      "|4017|01H4EEMZ46GS5AYC8...|  United|       Canillo|    22/10/2022|            QGP|          Kryvyy Rih|6/7/2023 00:10|    Katti Surgen|          Female|         C3|     EUR|            A1|      Delayed|     Bobbye Scryne| Embraer E190|         3497.85|     4017|         2533|              TIP|          Andorra|6/7/2023 18:04|        Ukraine|  18/11/2022|          22.79|          100|               Russia|      291.34|          0.08|          E5|   Jocelin Jendrusch|               3|               N67890|        3745.24|       5|2024_11_17_05_47_00|\n",
      "|4018|01H4EEMZ499STC5SE...|   Delta| Rio Brilhante|     21/9/2022|            YYM|                Hōfu|6/7/2023 22:10|  Farley Iltchev|            Male|         C3|     BRL|            C3|      Delayed|  Earlie Chasemore|   Boeing 737|         6980.72|     4018|         8297|              RBT|           Brazil|6/7/2023 17:40|          Japan|   19/7/2022|          22.03|           68|            Indonesia|      549.51|          4.76|          E5|       Thatch Earley|              10|               N67890|        4776.57|       5|2024_11_17_05_47_00|\n",
      "|4019|01H4EEMZ4CMYK6PEK...|  United|       Chapecó|    30/11/2022|            TJC|         Montbéliard|6/7/2023 21:10|   Rosene Chiles|          Female|         A1|     BRL|            B2|      Delayed|   April O' Timony|  Airbus A320|         7990.26|     4019|         1216|              RDG|           Brazil|6/7/2023 22:54|         France|   2/11/2022|           7.07|           30|              Senegal|      695.27|           7.1|          D4|   Gertrudis Marklew|               8|               N12345|        2954.73|       5|2024_11_17_05_47_00|\n",
      "|4020|01H4EEMZ4FK7SXVVN...|American|      Lamalera|     17/3/2022|            IFA|Kedungbanteng Krajan|6/7/2023 16:41|  Fowler Leggitt|     Genderqueer|         B2|     IDR|            C3|    Cancelled|    Terrel Gowrich|  Airbus A320|         4548.78|     4020|         9387|              JVL|        Indonesia|6/7/2023 07:56|      Indonesia|   11/6/2022|          22.12|           30|              Ukraine|      722.77|         39.26|          F6|   Garreth Kornousek|               7|               NABCDE|        4409.26|       5|2024_11_17_05_47_00|\n",
      "+----+--------------------+--------+--------------+--------------+---------------+--------------------+--------------+----------------+----------------+-----------+--------+--------------+-------------+------------------+-------------+----------------+---------+-------------+-----------------+-----------------+--------------+---------------+------------+---------------+-------------+---------------------+------------+--------------+------------+--------------------+----------------+---------------------+---------------+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark_session = SparkSession.builder.appName(\"KafkaStreamingApp\").getOrCreate()\n",
    "\n",
    "def read_streaming_data(\n",
    "    spark_session,\n",
    "    kafka_bootstrap_servers,\n",
    "    input_topic,\n",
    "    output_topic,\n",
    "    checkpoint_location,\n",
    "    files_directory,\n",
    "):\n",
    "\n",
    "    # Read from Kafka in streaming mode\n",
    "    kafkaStream = (\n",
    "        spark_session.readStream.format(\"kafka\")\n",
    "        .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers)\n",
    "        .option(\"subscribe\", input_topic)\n",
    "        .option(\"startingOffsets\", \"earliest\")\n",
    "        .load()\n",
    "    )\n",
    "\n",
    "    # Perform some transformation on the data (here we are simply renaming the columns and uppercase the values)\n",
    "    kafkaTransformedStream = kafkaStream.selectExpr(\n",
    "        \"CAST(key AS STRING) as key\", \"UPPER(CAST(value AS STRING)) as value\"\n",
    "    )\n",
    "\n",
    "    # Configure a streaming write query to write data to Parquet format\n",
    "    kafkaStreamSaveToParquet = (\n",
    "        kafkaTransformedStream.writeStream.outputMode(\"append\")\n",
    "        .format(\"parquet\")\n",
    "        .option(\"path\", files_directory)\n",
    "        .option(\"checkpointLocation\", checkpoint_location)\n",
    "        .trigger(processingTime=\"1 minute\")\n",
    "        .start()\n",
    "    )\n",
    "\n",
    "    # Define a function to process each batch and print it without truncating\n",
    "    def process_batch(\n",
    "        batch_df,\n",
    "        batch_id,\n",
    "        kafka_bootstrap_servers,\n",
    "        input_topic,\n",
    "        output_topic,\n",
    "        checkpoint_location,\n",
    "        files_directory,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Processes each batch of the streaming DataFrame and displays it as a Pandas DataFrame.\n",
    "\n",
    "        Args:\n",
    "        - batch_df (DataFrame): The DataFrame containing the batch data.\n",
    "        - batch_id (int): The ID of the batch being processed.\n",
    "        - kafka_bootstrap_servers (str): The Kafka bootstrap servers.\n",
    "        - input_topic (str): The input Kafka topic.\n",
    "        - output_topic (str): The output Kafka topic.\n",
    "        - checkpoint_location (str): The location for checkpointing.\n",
    "        - files_directory (str): The directory path for saving files.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        # Print the batch ID for identification\n",
    "        print(f\"Batch ID : {batch_id}\")\n",
    "\n",
    "        # Collect key-value pairs from the batch DataFrame\n",
    "        key_values = batch_df.select(col(\"key\"), col(\"value\")).collect()\n",
    "\n",
    "        # Initialize an empty list to store data for the Pandas DataFrame\n",
    "        data = []\n",
    "\n",
    "        # Iterate through key-value pairs\n",
    "        for row in key_values:\n",
    "            # Extract the key and value directly as they are not JSON\n",
    "            row_data = {\n",
    "                \"key\": row[\"key\"],\n",
    "                \"value\": row[\"value\"],\n",
    "                \"input_topic\": input_topic,\n",
    "                \"output_topic\": output_topic,\n",
    "                \"checkpoint_location\": checkpoint_location,\n",
    "                \"files_directory\": files_directory\n",
    "            }\n",
    "\n",
    "            # Append the dictionary to the data list\n",
    "            data.append(row_data)\n",
    "\n",
    "        # Create a Pandas DataFrame from the collected data\n",
    "        df_pandas = pd.DataFrame(data)\n",
    "\n",
    "        # Display the Pandas DataFrame\n",
    "        display(df_pandas)\n",
    "\n",
    "    from functools import partial\n",
    "\n",
    "    # Create a partial function with the additional parameters\n",
    "    partial_process_batch = partial(\n",
    "        process_batch,\n",
    "        kafka_bootstrap_servers=kafka_bootstrap_servers,\n",
    "        input_topic=input_topic,\n",
    "        output_topic=output_topic,\n",
    "        checkpoint_location=checkpoint_location,\n",
    "        files_directory=files_directory,\n",
    "    )\n",
    "\n",
    "    # Configure a streaming write query to send data to Kafka, and use a function into foreach for show content without truncate\n",
    "    kafkaStreamWriter = (\n",
    "        kafkaTransformedStream.writeStream.option(\"failOnDataLoss\", \"false\")\n",
    "        .outputMode(\"append\")\n",
    "        .format(\"kafka\")\n",
    "        .option(\"truncate\", \"false\")\n",
    "        .option(\"checkpointLocation\", checkpoint_location)\n",
    "        .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers)\n",
    "        .option(\"topic\", output_topic)\n",
    "        .foreachBatch(partial_process_batch)\n",
    "        .start()\n",
    "    )\n",
    "\n",
    "    print(\"kafkaStream\", type(kafkaStream))\n",
    "    print(\"transformedStream\", type(kafkaTransformedStream))\n",
    "    print(\"query\", type(kafkaStreamWriter))\n",
    "\n",
    "\n",
    "# Configure Kafka connection\n",
    "kafka_bootstrap_servers = \"localhost:9092\"\n",
    "input_topic = \"animals-topic-batch\"\n",
    "output_topic = \"animals-topic-streaming\"\n",
    "# Checkpoint directory within the Kafka directory\n",
    "checkpoint_location = \"/usr/local/kafka/data/checkpoint\"\n",
    "files_directory = \"/usr/local/kafka/data/files\"\n",
    "\n",
    "read_streaming_data(\n",
    "    spark_session,\n",
    "    kafka_bootstrap_servers,\n",
    "    input_topic,\n",
    "    output_topic,\n",
    "    checkpoint_location,\n",
    "    files_directory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec0bf92-d064-4727-a24e-1f6b06f02ca2",
   "metadata": {},
   "source": [
    "# STREAMING FILES USING FROM DIRECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62a87ecc-d707-4e67-a9a5-eaabca9461f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 05:46:17 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n",
      "24/11/17 05:46:17 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/11/17 05:46:18 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Spark-Kafka-Confluence-Batch-Streaming-MlLib.ipynb\n",
      "24/11/17 05:46:18 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Untitled.ipynb\n",
      "                                                                                24/11/17 05:46:20 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Untitled.ipynb\n",
      "24/11/17 05:46:20 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Spark-Kafka-Confluence-Batch-Streaming-MlLib.ipynb\n",
      "24/11/17 05:46:22 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 1, schema size: 34\n",
      "CSV file: file:///notebooks/Spark-Kafka-Confluence-Batch-Streaming-MlLib.ipynb\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, expr, lit\n",
    "from pyspark.sql.types import (\n",
    "    DoubleType,\n",
    "    FloatType,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    StructField,\n",
    "    StructType,\n",
    ")\n",
    "\n",
    "\n",
    "def process_batch(directory_to_save_files, df, epoch_id):\n",
    "\n",
    "    # Generate a timestamp\n",
    "    timestamp_str = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "    # Add epoch_id and timestamp_str as new columns\n",
    "    df = df.withColumn(\"batch_id\", lit(epoch_id)).withColumn(\n",
    "        \"timestamp\", lit(timestamp_str)\n",
    "    )\n",
    "\n",
    "    # Print information about the new batch\n",
    "    print(f\"Processing microbatch {epoch_id} at {timestamp_str}\")\n",
    "\n",
    "    # Group by specified columns and calculate the average ticket price\n",
    "    grouped_df = df.groupBy(\n",
    "        \"batch_id\",\n",
    "        \"timestamp\",\n",
    "        \"passenger_nationality\",\n",
    "        \"passenger_gender\",\n",
    "        \"passenger_age\",\n",
    "    ).agg(\n",
    "        F.avg(\"ticket_price\").alias(\"avg_ticket_price\"),\n",
    "        F.sum(\"ticket_price\").alias(\"total_ticket_price\"),\n",
    "        F.count(\"passenger_name\").alias(\"total_passengers\"),\n",
    "    )\n",
    "\n",
    "    # Filter out groups where the total number of passengers is greater than 1\n",
    "    # filtered_df = grouped_df.filter(grouped_df.total_passengers > 1)\n",
    "    # Multiple filter conditions\n",
    "    filtered_df = grouped_df.filter(\n",
    "        (col(\"total_passengers\") > 2) & (col(\"total_passengers\") <= 7)\n",
    "    )\n",
    "\n",
    "    # Sort the DataFrame by passenger_nationality and passenger_age\n",
    "    sorted_df = filtered_df.orderBy(\n",
    "        \"total_passengers\", \"passenger_nationality\", \"passenger_gender\"\n",
    "    )\n",
    "\n",
    "    # Show the sorted DataFrame\n",
    "    sorted_df.show(truncate=False)\n",
    "\n",
    "    # Coalesce to a single partition and write the DataFrame as Parquet with timestamp\n",
    "    maximum_parquet_files_per_batch = 3\n",
    "    sorted_df.coalesce(maximum_parquet_files_per_batch).write.parquet(\n",
    "        f\"{directory_to_save_files}/microbatch_{epoch_id}_{timestamp_str}\"\n",
    "    )\n",
    "\n",
    "    # Show the original DataFrame\n",
    "    df.show()\n",
    "\n",
    "\n",
    "def read_file_like_streaming(\n",
    "    spark_session, customSchema, format, checkpoint_location, directory_to_save_files\n",
    "):\n",
    "\n",
    "    # Read the DataFrame as a continuous stream\n",
    "    streaming_df = (\n",
    "        spark_session.readStream.schema(customSchema)\n",
    "        .format(format)\n",
    "        .option(\"header\", \"true\")\n",
    "        .load(folder_files_path)\n",
    "    )\n",
    "\n",
    "    # Display the DataFrame in the console and count the records per microbatch\n",
    "    # .trigger(processingTime='5 seconds') specifies that Spark Structured Streaming should process micro-batches of data from the specified directory every 5 seconds.\n",
    "    query = (\n",
    "        streaming_df.writeStream.outputMode(\"append\")\n",
    "        .trigger(processingTime=\"5 seconds\")\n",
    "        .option(\"checkpointLocation\", checkpoint_location)\n",
    "        .option(\"basePath\", directory_to_save_files)\n",
    "        .foreachBatch(\n",
    "            lambda df, epoch_id: process_batch(directory_to_save_files, df, epoch_id)\n",
    "        )\n",
    "        .start()\n",
    "    )\n",
    "\n",
    "    # Wait for the streaming to complete\n",
    "    # query.awaitTermination()\n",
    "\n",
    "\n",
    "# Define the schema\n",
    "customSchema = StructType(\n",
    "    [\n",
    "        StructField(\"id\", IntegerType(), True),\n",
    "        StructField(\"secure_code\", StringType(), True),\n",
    "        StructField(\"airline\", StringType(), True),\n",
    "        StructField(\"departure_city\", StringType(), True),\n",
    "        StructField(\"departure_date\", StringType(), True),\n",
    "        StructField(\"arrival_airport\", StringType(), True),\n",
    "        StructField(\"arrival_city\", StringType(), True),\n",
    "        StructField(\"arrival_time\", StringType(), True),\n",
    "        StructField(\"passenger_name\", StringType(), True),\n",
    "        StructField(\"passenger_gender\", StringType(), True),\n",
    "        StructField(\"seat_number\", StringType(), True),\n",
    "        StructField(\"currency\", StringType(), True),\n",
    "        StructField(\"departure_gate\", StringType(), True),\n",
    "        StructField(\"flight_status\", StringType(), True),\n",
    "        StructField(\"co_pilot_name\", StringType(), True),\n",
    "        StructField(\"aircraft_type\", StringType(), True),\n",
    "        StructField(\"fuel_consumption\", DoubleType(), True),\n",
    "        StructField(\"flight_id\", IntegerType(), True),\n",
    "        StructField(\"flight_number\", IntegerType(), True),\n",
    "        StructField(\"departure_airport\", StringType(), True),\n",
    "        StructField(\"departure_country\", StringType(), True),\n",
    "        StructField(\"departure_time\", StringType(), True),\n",
    "        StructField(\"arrival_country\", StringType(), True),\n",
    "        StructField(\"arrival_date\", StringType(), True),\n",
    "        StructField(\"flight_duration\", DoubleType(), True),\n",
    "        StructField(\"passenger_age\", IntegerType(), True),\n",
    "        StructField(\"passenger_nationality\", StringType(), True),\n",
    "        StructField(\"ticket_price\", DoubleType(), True),\n",
    "        StructField(\"baggage_weight\", DoubleType(), True),\n",
    "        StructField(\"arrival_gate\", StringType(), True),\n",
    "        StructField(\"pilot_name\", StringType(), True),\n",
    "        StructField(\"cabin_crew_count\", IntegerType(), True),\n",
    "        StructField(\"aircraft_registration\", StringType(), True),\n",
    "        StructField(\"flight_distance\", DoubleType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "format = \"csv\"\n",
    "folder_files_path = \"/notebooks\"\n",
    "directory_to_save_files = \"/usr/local/kafka/data/files/batch\"\n",
    "shutil.rmtree(directory_to_save_files, ignore_errors=True)\n",
    "\n",
    "# Delete the checkpoint directory\n",
    "checkpoint_location = \"/usr/local/kafka/data/batch\"\n",
    "shutil.rmtree(checkpoint_location, ignore_errors=True)\n",
    "\n",
    "read_file_like_streaming(\n",
    "    spark_session=spark_session,\n",
    "    customSchema=customSchema,\n",
    "    format=format,\n",
    "    checkpoint_location=checkpoint_location,\n",
    "    directory_to_save_files=directory_to_save_files,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730cf897-dcf0-40ca-a082-d446b80f44e4",
   "metadata": {},
   "source": [
    "# COPY, PASTE, AND RUN THE FOLLOWING CODE IN ANOTHER NOTEBOOK TO OBSERVE STREAMING REDING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe4f8d6-35aa-460f-a14d-b0c792be1933",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "for index in range(1,6):\n",
    "\n",
    "    part_1 = index\n",
    "    part_2 = index + 5\n",
    "\n",
    "    file_name = 'flight_logs'\n",
    "    final_file = f'{file_name}_{index}.csv'\n",
    "    \n",
    "    file_1 = f'{file_name}_part_1_{index}.csv'\n",
    "    base_url1 = f'https://raw.githubusercontent.com/JorgeCardona/recursos/main/datasets/{file_1}'\n",
    "    df1 = pd.read_csv(base_url1)\n",
    "    \n",
    "    file_2 = f'{file_name}_part_2_{index}.csv'\n",
    "    base_url2 = f'https://raw.githubusercontent.com/JorgeCardona/recursos/main/datasets/{file_2}'\n",
    "    df2 = pd.read_csv(base_url2)\n",
    "\n",
    "    df3 = pd.merge(df1, df2, left_on='id', right_on='flight_id', how='inner')\n",
    "    df3.to_csv(f'{final_file}',index=False)\n",
    "\n",
    "    print(f'{final_file} saved Successfully!!')\n",
    "    sleep(5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f64fe-6aac-48d9-95ff-34f9d8a007f6",
   "metadata": {},
   "source": [
    "# LOAD PARQUET FILES DIRECTORY ON DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfa23a9d-027e-4fe5-9559-6b3098df2b16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>passenger_nationality</th>\n",
       "      <th>passenger_gender</th>\n",
       "      <th>passenger_age</th>\n",
       "      <th>avg_ticket_price</th>\n",
       "      <th>total_ticket_price</th>\n",
       "      <th>total_passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2024_11_17_05_46_17</td>\n",
       "      <td>None</td>\n",
       "      <td>\\\"crustacean\\\")</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2024_11_17_05_46_17</td>\n",
       "      <td>None</td>\n",
       "      <td>\\\"reptile\\\")</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2024_11_17_05_46_17</td>\n",
       "      <td>None</td>\n",
       "      <td>\\\"arachnid\\\")</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2024_11_17_05_46_17</td>\n",
       "      <td>None</td>\n",
       "      <td>\\\"mammal\\\")</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2024_11_17_05_46_17</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_id            timestamp passenger_nationality  passenger_gender  \\\n",
       "0         0  2024_11_17_05_46_17                  None   \\\"crustacean\\\")   \n",
       "1         0  2024_11_17_05_46_17                  None      \\\"reptile\\\")   \n",
       "2         0  2024_11_17_05_46_17                  None     \\\"arachnid\\\")   \n",
       "3         0  2024_11_17_05_46_17                  None       \\\"mammal\\\")   \n",
       "4         0  2024_11_17_05_46_17                  None              None   \n",
       "\n",
       "   passenger_age  avg_ticket_price  total_ticket_price  total_passengers  \n",
       "0            NaN               NaN                 NaN                 3  \n",
       "1            NaN               NaN                 NaN                 3  \n",
       "2            NaN               NaN                 NaN                 5  \n",
       "3            NaN               NaN                 NaN                 6  \n",
       "4            NaN               NaN                 NaN                 7  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "\n",
    "def find_microbatch_file(directory):\n",
    "    \"\"\"\n",
    "    Busca un archivo en el directorio especificado que contiene el término \"microbatch\" en su nombre.\n",
    "\n",
    "    Args:\n",
    "    - directory (str): La ruta del directorio donde se buscarán los archivos.\n",
    "\n",
    "    Returns:\n",
    "    - str: El nombre del archivo que contiene el término \"microbatch\" en su nombre, o una cadena vacía si no se encuentra.\n",
    "    \"\"\"\n",
    "    # Listar todos los archivos en el directorio\n",
    "    all_files = os.listdir(directory)\n",
    "\n",
    "    # Inicializar la variable para almacenar el nombre del archivo microbatch\n",
    "    microbatch_file_name = \"\"\n",
    "\n",
    "    # Buscar el archivo que contiene el término \"microbatch\" en su nombre\n",
    "    for file_name in all_files:\n",
    "        if \"microbatch\" in file_name:\n",
    "            microbatch_file_name = file_name\n",
    "\n",
    "    return microbatch_file_name\n",
    "\n",
    "\n",
    "def read_parquet_directory_into_dataframe(directory_path):\n",
    "    \"\"\"\n",
    "    Reads all Parquet files from a directory into a single pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - directory_path (str): Path to the directory containing Parquet files.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Combined DataFrame containing data from all Parquet files.\n",
    "    \"\"\"\n",
    "    # Use glob to get a list of all Parquet file paths in the specified directory\n",
    "    parquet_files = glob.glob(f\"{directory_path}/*.parquet\")\n",
    "\n",
    "    # Initialize an empty list to store individual DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Loop through each Parquet file and read it into a DataFrame\n",
    "    for parquet_file in parquet_files:\n",
    "        # Read Parquet file into a DataFrame\n",
    "        df = pq.read_table(parquet_file).to_pandas()\n",
    "\n",
    "        # Append the DataFrame to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    all_data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "# Specify the directory where Parquet files are located\n",
    "directory_to_save_files = \"/usr/local/kafka/data/files/batch\"\n",
    "microbatch_parquet_directory_name = find_microbatch_file(\n",
    "    directory=directory_to_save_files\n",
    ")\n",
    "directory_path = f\"{directory_to_save_files}/{microbatch_parquet_directory_name}/\"\n",
    "\n",
    "read_parquet_directory_into_dataframe(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912aab18-669b-4d64-b6fb-31b3b6c71114",
   "metadata": {},
   "source": [
    "# SPARK MLLIB + SCIKIT LEARN\n",
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07f88fea-b54c-4d62-9a6a-80bea1dd0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import (\n",
    "    BinaryClassificationEvaluator,\n",
    "    MulticlassClassificationEvaluator,\n",
    "    RegressionEvaluator,\n",
    ")\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import col, format_number, lit, udf, when\n",
    "from pyspark.sql.types import FloatType, StringType, StructField, StructType\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6799c2-aa8c-4637-9922-3572221f7462",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0f2e294-6a8a-4699-881d-a66c347b91de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark Session\n",
    "def create_spark_session():\n",
    "    \"\"\"\n",
    "    Create a Spark session.\n",
    "\n",
    "    Returns:\n",
    "    - spark_session (SparkSession): A SparkSession object.\n",
    "    \"\"\"\n",
    "    spark_session = (\n",
    "        SparkSession.builder.master(\"local\")\n",
    "        .appName(\"scikit-learn-with-spark\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    return spark_session\n",
    "\n",
    "\n",
    "def create_dataframe_from_dataset(\n",
    "    dataset,\n",
    "    dataset_data_key=\"data\",\n",
    "    dataset_columns=[\"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\"],\n",
    "    dataset_data_target=\"target\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a pandas DataFrame from a dataset dictionary.\n",
    "\n",
    "    Args:\n",
    "    - dataset (dict): The dataset dictionary containing data and target keys.\n",
    "    - dataset_data_key (str): The key in the dataset dictionary corresponding to the data.\n",
    "    - dataset_columns (list): List of column names for the DataFrame.\n",
    "    - dataset_data_target (str): The key in the dataset dictionary corresponding to the target.\n",
    "\n",
    "    Returns:\n",
    "    - df (DataFrame): A pandas DataFrame containing the data and target from the dataset dictionary.\n",
    "    \"\"\"\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(dataset[dataset_data_key], columns=dataset_columns)\n",
    "    df[dataset_data_target] = dataset[dataset_data_target]\n",
    "\n",
    "    display(df)\n",
    "\n",
    "\n",
    "def create_multiple_samples_datasets(\n",
    "    original_dataset, n_datasets, n_records, delay_time=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Create multiple datasets from an original dataset.\n",
    "\n",
    "    Args:\n",
    "    - original_dataset (Bunch): The original dataset from which to create new datasets.\n",
    "    - n_datasets (int): Number of datasets to create.\n",
    "    - n_records (int): Number of records in each new dataset.\n",
    "    - delay_time (int): Time to wait (in seconds) between creating each dataset.\n",
    "\n",
    "    Returns:\n",
    "    - datasets (list): A list of pandas DataFrames, each representing a new dataset.\n",
    "    \"\"\"\n",
    "    datasets = []\n",
    "\n",
    "    for dataset_index in range(n_datasets):\n",
    "        # Create a new dataset with n random records\n",
    "        indices = np.random.choice(\n",
    "            range(len(original_dataset.data)), size=n_records, replace=False\n",
    "        )\n",
    "        data = original_dataset.data[indices]\n",
    "        target = original_dataset.target[indices]\n",
    "        new_dataset = pd.DataFrame(data, columns=original_dataset.feature_names)\n",
    "        new_dataset[\"target\"] = target\n",
    "        datasets.append(new_dataset)\n",
    "\n",
    "        # Write new dataset to a CSV file\n",
    "        new_dataset.to_csv(f\"new_dataset_{dataset_index}.csv\", index=False)\n",
    "\n",
    "        # Wait for a specified delay time\n",
    "        sleep(delay_time)\n",
    "\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Load the Iris dataset and display it as a pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - data_features (array): Array containing the features of the Iris dataset.\n",
    "    - target_classes (array): Array containing the target classes of the Iris dataset.\n",
    "    \"\"\"\n",
    "    # Load the Iris dataset\n",
    "    dataset = load_iris()\n",
    "    data_features, target_classes = dataset.data, dataset.target\n",
    "    key_column = \"data\"\n",
    "    features_columns = [\"feature_1\", \"feature_2\", \"feature_3\", \"feature_4\"]\n",
    "    taget_column = \"target\"\n",
    "\n",
    "    create_dataframe_from_dataset(\n",
    "        dataset,\n",
    "        dataset_data_key=key_column,\n",
    "        dataset_columns=features_columns,\n",
    "        dataset_data_target=taget_column,\n",
    "    )\n",
    "\n",
    "    return data_features, target_classes\n",
    "\n",
    "\n",
    "def load_dataset_from_csv(csv_file):\n",
    "    \"\"\"\n",
    "    Load the Iris dataset from a CSV file and display it as a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file containing the Iris dataset.\n",
    "\n",
    "    Returns:\n",
    "        - data_features (array): Array containing the features of the Iris dataset.\n",
    "        - target_classes (array): Array containing the target classes of the Iris dataset.\n",
    "    \"\"\"\n",
    "    # Load the Iris dataset from the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Separate the feature columns and the target column\n",
    "    features_columns = [\n",
    "        \"sepal length (cm)\",\n",
    "        \"sepal width (cm)\",\n",
    "        \"petal length (cm)\",\n",
    "        \"petal width (cm)\",\n",
    "    ]\n",
    "    target_column = \"class\"\n",
    "\n",
    "    data_features = df[features_columns].values\n",
    "    target_classes = df[target_column].values\n",
    "\n",
    "    return data_features, target_classes\n",
    "\n",
    "\n",
    "def split_dataset_train_testing(data_features, target_classes):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and testing sets.\n",
    "\n",
    "    Args:\n",
    "    - data_features (array): Array containing the features of the dataset.\n",
    "    - target_classes (array): Array containing the target classes of the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - data_features_train_splitted (array): Features of the training set.\n",
    "    - data_features_test_splitted (array): Features of the testing set.\n",
    "    - target_classes_train_splitted (array): Target classes of the training set.\n",
    "    - target_classes_test_splitted (array): Target classes of the testing set.\n",
    "    \"\"\"\n",
    "    # Split the data into training and testing sets\n",
    "    (\n",
    "        data_features_train_splitted,\n",
    "        data_features_test_splitted,\n",
    "        target_classes_train_splitted,\n",
    "        target_classes_test_splitted,\n",
    "    ) = train_test_split(data_features, target_classes, test_size=0.2, random_state=42)\n",
    "\n",
    "    return (\n",
    "        data_features_train_splitted,\n",
    "        data_features_test_splitted,\n",
    "        target_classes_train_splitted,\n",
    "        target_classes_test_splitted,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_filtered_dataset(data_features_dataset, target_classes_dataset):\n",
    "    \"\"\"\n",
    "    Convert dataset features and target classes to appropriate formats.\n",
    "\n",
    "    Args:\n",
    "    - data_features_dataset (array): Array containing the features of the dataset.\n",
    "    - target_classes_dataset (array): Array containing the target classes of the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - data_features_filtered (list): List of feature vectors converted to Vectors.dense format.\n",
    "    - target_classes_filtered (list): List of target classes converted to floats.\n",
    "    \"\"\"\n",
    "    # Convert numpy values to Python floats\n",
    "    data_features_filtered = [\n",
    "        Vectors.dense(features) for features in data_features_dataset\n",
    "    ]\n",
    "    target_classes_filtered = [\n",
    "        float(label) for label in target_classes_dataset\n",
    "    ]  # Convert to float\n",
    "\n",
    "    return data_features_filtered, target_classes_filtered\n",
    "\n",
    "\n",
    "def create_spark_dataframe(\n",
    "    sparkml_session, data_features_dataset, target_classes_dataset\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a Spark DataFrame from the dataset features and target classes.\n",
    "\n",
    "    Args:\n",
    "    - data_features_dataset (array): Array containing the features of the dataset.\n",
    "    - target_classes_dataset (array): Array containing the target classes of the dataset.\n",
    "\n",
    "    Returns:\n",
    "    - final_data_set (DataFrame): A Spark DataFrame containing the features and target classes.\n",
    "    \"\"\"\n",
    "    # Create Spark DataFrames from training data\n",
    "    data_set = list(zip(data_features_dataset, target_classes_dataset))\n",
    "    schema = StructType(\n",
    "        [\n",
    "            StructField(\"features\", VectorUDT(), True),\n",
    "            StructField(\"label\", FloatType(), True),\n",
    "        ]\n",
    "    )\n",
    "    final_data_set = sparkml_session.createDataFrame(data_set, schema=schema)\n",
    "\n",
    "    return final_data_set\n",
    "\n",
    "\n",
    "def create_ml_trained_model(train_df):\n",
    "    \"\"\"\n",
    "    Create and train a logistic regression model.\n",
    "\n",
    "    Args:\n",
    "    - train_df (DataFrame): DataFrame containing the training data.\n",
    "\n",
    "    Returns:\n",
    "    - model: Trained logistic regression model.\n",
    "    \"\"\"\n",
    "    # Create and train a logistic regression model\n",
    "    lr = LogisticRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        maxIter=10,\n",
    "        regParam=0.3,\n",
    "        elasticNetParam=0.8,\n",
    "    )\n",
    "    model = lr.fit(train_df)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_prediction(model, test_df):\n",
    "    \"\"\"\n",
    "    Make predictions using a trained model and display the results.\n",
    "\n",
    "    Args:\n",
    "    - model: Trained machine learning model.\n",
    "    - test_df (DataFrame): DataFrame containing the test data.\n",
    "\n",
    "    Returns:\n",
    "    - prediction_result (DataFrame): DataFrame containing the prediction results.\n",
    "    \"\"\"\n",
    "    # Make predictions on the test data\n",
    "    prediction_result = model.transform(test_df)\n",
    "    # Format prediction column to display two decimal places\n",
    "    prediction_result = prediction_result.withColumn(\n",
    "        \"formatted_prediction\", format_number(\"prediction\", 2)\n",
    "    )\n",
    "\n",
    "    # Map numeric labels back to target names\n",
    "    target_names = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "    label_to_name_udf = udf(lambda label: target_names[int(label)], StringType())\n",
    "\n",
    "    # Create new columns with predicted and actual class names\n",
    "    prediction_result = prediction_result.withColumn(\n",
    "        \"predicted_class_name\", label_to_name_udf(\"prediction\")\n",
    "    )\n",
    "    prediction_result = prediction_result.withColumn(\n",
    "        \"actual_class_name\", label_to_name_udf(\"label\")\n",
    "    )\n",
    "\n",
    "    # Add new column to indicate correct or incorrect classification\n",
    "    prediction_result = prediction_result.withColumn(\n",
    "        \"correctly_classified\",\n",
    "        when(\n",
    "            prediction_result[\"predicted_class_name\"]\n",
    "            == prediction_result[\"actual_class_name\"],\n",
    "            \"✓\",\n",
    "        ).otherwise(\"❌\"),\n",
    "    )\n",
    "\n",
    "    # Display the results\n",
    "    prediction_result.show()\n",
    "\n",
    "    return prediction_result\n",
    "\n",
    "\n",
    "def mse_rmse_mae_r2_avaluator(prediction_result):\n",
    "    \"\"\"\n",
    "    Evaluate regression metrics including MSE, RMSE, MAE, and R2 score.\n",
    "\n",
    "    Args:\n",
    "    - prediction_result (DataFrame): DataFrame containing the prediction results.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    regression_evaluator_mse = RegressionEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"mse\"\n",
    "    )\n",
    "    print(\n",
    "        \"Mean Squared Error (Regression):\",\n",
    "        round(regression_evaluator_mse.evaluate(prediction_result), 4) * 100,\n",
    "        \"%\",\n",
    "    )\n",
    "\n",
    "    regression_evaluator_rmse = RegressionEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"rmse\"\n",
    "    )\n",
    "    print(\n",
    "        \"Root Mean Squared Error (Regression):\",\n",
    "        round(regression_evaluator_rmse.evaluate(prediction_result), 4) * 100,\n",
    "        \"%\",\n",
    "    )\n",
    "\n",
    "    regression_evaluator_mae = RegressionEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"mae\"\n",
    "    )\n",
    "    print(\n",
    "        \"Mean Absolute Error (Regression):\",\n",
    "        round(regression_evaluator_mae.evaluate(prediction_result), 4) * 100,\n",
    "        \"%\",\n",
    "    )\n",
    "\n",
    "    # R2 Score (Regression)\n",
    "    r2_evaluator = RegressionEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"r2\"\n",
    "    )\n",
    "    print(\n",
    "        \"R2 Score (Regression):\",\n",
    "        round(r2_evaluator.evaluate(prediction_result), 4) * 100,\n",
    "        \"%\",\n",
    "    )\n",
    "\n",
    "\n",
    "def accuracy_f1Score_precision_recall_evaluator(prediction_result):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using accuracy, F1 score, precision, and recall metrics.\n",
    "\n",
    "    Args:\n",
    "    - prediction_result (DataFrame): DataFrame containing the prediction results.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Accuracy\n",
    "    evaluator_accuracy = MulticlassClassificationEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\"\n",
    "    )\n",
    "    accuracy = evaluator_accuracy.evaluate(prediction_result)\n",
    "    print(f\"Accuracy: {round(accuracy,4)*100} %\")\n",
    "\n",
    "    # F1 Score\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"f1\"\n",
    "    )\n",
    "    f1_score = evaluator_f1.evaluate(prediction_result)\n",
    "    print(f\"F1 Score: {round(f1_score,4)*100} %\")\n",
    "\n",
    "    # Precision\n",
    "    evaluator_precision = MulticlassClassificationEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"weightedPrecision\"\n",
    "    )\n",
    "    precision = evaluator_precision.evaluate(prediction_result)\n",
    "    print(f\"Precision: {round(precision,4)*100} %\")\n",
    "\n",
    "    # Recall\n",
    "    evaluator_recall = MulticlassClassificationEvaluator(\n",
    "        predictionCol=\"prediction\", labelCol=\"label\", metricName=\"weightedRecall\"\n",
    "    )\n",
    "    recall = evaluator_recall.evaluate(prediction_result)\n",
    "    print(f\"Recall: {round(recall,4)*100} %\")\n",
    "\n",
    "\n",
    "def area_under_curve_confusion_matrix_evaluator(prediction_result):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using area under ROC curve and confusion matrix.\n",
    "\n",
    "    Args:\n",
    "    - prediction_result (DataFrame): DataFrame containing the prediction results.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Binary Classification Evaluator for ROC\n",
    "    binary_evaluator = BinaryClassificationEvaluator(\n",
    "        rawPredictionCol=\"prediction\", labelCol=\"label\"\n",
    "    )\n",
    "    roc_auc = binary_evaluator.evaluate(\n",
    "        prediction_result, {binary_evaluator.metricName: \"areaUnderROC\"}\n",
    "    )\n",
    "    print(f\"Area Under ROC: {round(roc_auc,4)*100} %\")\n",
    "\n",
    "    # Extract predictions and labels as RDD\n",
    "    prediction_and_label = prediction_result.select(\"prediction\", \"label\").rdd.map(\n",
    "        lambda row: (float(row[\"prediction\"]), float(row[\"label\"]))\n",
    "    )\n",
    "\n",
    "    # Create a MulticlassMetrics object\n",
    "    metrics = MulticlassMetrics(prediction_and_label)\n",
    "\n",
    "    # Output the confusion matrix\n",
    "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix)\n",
    "\n",
    "\n",
    "def create_pandas_dataframe(spark_dataframe):\n",
    "    \"\"\"\n",
    "    Convert a Spark DataFrame to a Pandas DataFrame and display the results.\n",
    "\n",
    "    Args:\n",
    "    - spark_dataframe (DataFrame): Spark DataFrame to be converted.\n",
    "\n",
    "    Returns:\n",
    "    - df_pandas (DataFrame): Pandas DataFrame containing the data from the Spark DataFrame.\n",
    "    \"\"\"\n",
    "    # Display the results like a pandas DataFrame\n",
    "    df_pandas = spark_dataframe.toPandas()\n",
    "    display(df_pandas)\n",
    "    return df_pandas\n",
    "\n",
    "def display_classification_results(df_results):\n",
    "    \"\"\"\n",
    "    Display classification results based on the DataFrame provided.\n",
    "\n",
    "    Args:\n",
    "    - df_results (DataFrame): DataFrame containing classification results.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Obtain unique classes from the 'correctly_classified' column\n",
    "    unique_classes = df_results['correctly_classified'].unique()\n",
    "\n",
    "    # Print total number of unique classes\n",
    "    print(\"Total unique classes:\", len(unique_classes))\n",
    "    print(\"Unique classes:\", unique_classes)\n",
    "    print(\"Total Records on Dataset:\", df_results.shape[0])\n",
    "\n",
    "    # Iterate over each unique class and calculate the percentage of records classified as that class\n",
    "    for class_value in unique_classes:\n",
    "        # Filter DataFrame to get records classified as the current class\n",
    "        class_records = df_results.query(f'correctly_classified == \"{class_value}\"')\n",
    "        \n",
    "        # Calculate percentage of records classified as the current class\n",
    "        total_percentage = (class_records.shape[0] / df_results.shape[0]) * 100\n",
    "        \n",
    "        # Print the number of records classified as the current class and the percentage\n",
    "        print(f'Records classified \"{class_value}\": {class_records.shape[0]}/{df_results.shape[0]} = {round(total_percentage, 2)}%')\n",
    "\n",
    "\n",
    "def export_spark_model(model, model_path, overwrite=False):\n",
    "    \"\"\"\n",
    "    Export a trained Spark model to the specified path.\n",
    "\n",
    "    Args:\n",
    "    - model (pyspark.ml.Model): The trained Spark model to export.\n",
    "    - model_path (str): The path where the model will be saved.\n",
    "    - overwrite (bool, optional): Whether to overwrite the model if it already exists. Default is False.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Save the model to the specified path\n",
    "    if overwrite:\n",
    "        model.write().overwrite().save(model_path)\n",
    "    else:\n",
    "        model.write().save(model_path)\n",
    "\n",
    "    print(f\"Model saved successfully at: {model_path}\")\n",
    "\n",
    "\n",
    "def load_spark_model(model_path: str) -> Union[LogisticRegressionModel, None]:\n",
    "    \"\"\"\n",
    "    Load a trained Spark model from the specified path.\n",
    "\n",
    "    Args:\n",
    "    - model_path (str): The path from where the model will be loaded.\n",
    "\n",
    "    Returns:\n",
    "    - Union[LogisticRegressionModel, None]: The loaded Spark model or None if loading fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the model from the specified path\n",
    "        loaded_model = LogisticRegressionModel.load(model_path)\n",
    "        print(f\"Model loaded successfully from: {model_path}\")\n",
    "        return loaded_model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4151b-579b-448e-9d97-dace939f4a29",
   "metadata": {},
   "source": [
    "# RUNNING ML PROCCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a494ea33-3b85-4c9e-b9eb-aec1fdc88d0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 05:47:16 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_1  feature_2  feature_3  feature_4  target\n",
       "0          5.1        3.5        1.4        0.2       0\n",
       "1          4.9        3.0        1.4        0.2       0\n",
       "2          4.7        3.2        1.3        0.2       0\n",
       "3          4.6        3.1        1.5        0.2       0\n",
       "4          5.0        3.6        1.4        0.2       0\n",
       "..         ...        ...        ...        ...     ...\n",
       "145        6.7        3.0        5.2        2.3       2\n",
       "146        6.3        2.5        5.0        1.9       2\n",
       "147        6.5        3.0        5.2        2.0       2\n",
       "148        6.2        3.4        5.4        2.3       2\n",
       "149        5.9        3.0        5.1        1.8       2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 05:47:20 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at: /notebooks/spark_ml_model/dataset_iris\n",
      "Model loaded successfully from: /notebooks/spark_ml_model/dataset_iris\n",
      "+--------------------+-----+--------------------+--------------------+----------+--------------------+--------------------+-----------------+--------------------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|formatted_prediction|predicted_class_name|actual_class_name|correctly_classified|\n",
      "+--------------------+-----+--------------------+--------------------+----------+--------------------+--------------------+-----------------+--------------------+\n",
      "|[6.34,3.03,4.29,1.1]|  1.0|[-0.5405590083053...|[0.28644828464755...|       1.0|                1.00|          versicolor|       versicolor|                   ✓|\n",
      "|[6.08,2.62,3.93,1...|  1.0|[-0.5466408257513...|[0.27689074407750...|       2.0|                2.00|           virginica|       versicolor|                   ❌|\n",
      "|[5.24,2.6,4.74,1.11]|  1.0|[-0.6615694617345...|[0.26211433883602...|       1.0|                1.00|          versicolor|       versicolor|                   ✓|\n",
      "|[4.75,3.12,1.32,0...|  0.0|[0.47294985742743...|[0.54758662353233...|       0.0|                0.00|              setosa|           setosa|                   ✓|\n",
      "|[6.76,3.21,5.29,1...|  2.0|[-1.0773019594656...|[0.17272724854531...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "|[5.66,2.61,3.88,1.3]|  1.0|[-0.4979637814550...|[0.28977899348067...|       1.0|                1.00|          versicolor|       versicolor|                   ✓|\n",
      "|[7.34,2.9,4.08,0.97]|  1.0|[-0.4435353588106...|[0.31025496235700...|       1.0|                1.00|          versicolor|       versicolor|                   ✓|\n",
      "|[7.72,3.23,6.03,2...|  2.0|[-1.3583358480790...|[0.13154999753580...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "| [5.0,2.92,1.42,0.2]|  0.0|[0.50178183887836...|[0.55956091035566...|       0.0|                0.00|              setosa|           setosa|                   ✓|\n",
      "|[7.35,3.16,5.4,1.99]|  2.0|[-1.1190335437155...|[0.16603723307095...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "|[5.42,3.47,5.41,2...|  2.0|[-1.1701838678711...|[0.15614141190010...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "|[5.15,3.75,1.46,0...|  0.0|[0.47189971616237...|[0.55048494054842...|       0.0|                0.00|              setosa|           setosa|                   ✓|\n",
      "|[4.48,3.45,1.65,0...|  0.0|[0.39305266828324...|[0.52831027614363...|       0.0|                0.00|              setosa|           setosa|                   ✓|\n",
      "|[6.59,3.31,4.13,1...|  1.0|[-0.5407455069699...|[0.28293832367297...|       1.0|                1.00|          versicolor|       versicolor|                   ✓|\n",
      "|[5.22,3.27,6.14,2...|  2.0|[-1.4097740531015...|[0.12462871550908...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "|[5.28,3.43,1.26,0...|  0.0|[0.55983506484927...|[0.57520218844506...|       0.0|                0.00|              setosa|           setosa|                   ✓|\n",
      "|[5.77,2.47,5.02,1.6]|  1.0|[-0.8933931025491...|[0.20870144707264...|       2.0|                2.00|           virginica|       versicolor|                   ❌|\n",
      "|[4.92,3.38,1.19,0.2]|  0.0|[0.56197790561056...|[0.57433893507614...|       0.0|                0.00|              setosa|           setosa|                   ✓|\n",
      "|[6.31,3.28,6.03,2...|  2.0|[-1.3648069285941...|[0.13047120321374...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "|[6.79,3.15,6.45,1...|  2.0|[-1.3711928926468...|[0.13517439851462...|       2.0|                2.00|           virginica|        virginica|                   ✓|\n",
      "+--------------------+-----+--------------------+--------------------+----------+--------------------+--------------------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Mean Squared Error (Regression): 15.0 %\n",
      "Root Mean Squared Error (Regression): 38.73 %\n",
      "Mean Absolute Error (Regression): 15.0 %\n",
      "R2 Score (Regression): 77.64999999999999 %\n",
      "Accuracy: 85.0 %\n",
      "F1 Score: 84.17 %\n",
      "Precision: 89.8 %\n",
      "Recall: 85.0 %\n",
      "Area Under ROC: 99.72999999999999 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[225.   0.   0.]\n",
      " [  2. 104.  88.]\n",
      " [  0.   0. 181.]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "      <th>formatted_prediction</th>\n",
       "      <th>predicted_class_name</th>\n",
       "      <th>actual_class_name</th>\n",
       "      <th>correctly_classified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[6.34, 3.03, 4.29, 1.1]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.5405590083053458, -0.2903442505059092, -0.3526444944609868]</td>\n",
       "      <td>[0.2864482846475502, 0.36788587593220956, 0.3456658394202402]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[6.08, 2.62, 3.93, 1.41]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.5466408257513526, -0.2903442505059092, -0.2694660890118225]</td>\n",
       "      <td>[0.27689074407750386, 0.35778046710014444, 0.36532878882235165]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[5.24, 2.6, 4.74, 1.11]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.661569461734576, -0.2903442505059092, -0.3499613200916589]</td>\n",
       "      <td>[0.2621143388360278, 0.37993721962664834, 0.35794844153732386]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4.75, 3.12, 1.32, 0.37]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.47294985742743334, -0.2903442505059092, -0.5485162234219222]</td>\n",
       "      <td>[0.5475866235323341, 0.2552456864888573, 0.19716768997880854]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[6.76, 3.21, 5.29, 1.95]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[-1.0773019594656765, -0.2903442505059092, -0.12457467306811687]</td>\n",
       "      <td>[0.1727272485453165, 0.37943050643351, 0.44784224502117365]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>[4.96, 3.66, 1.45, 0.47]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.4065705910469949, -0.2903442505059092, -0.5216844797286433]</td>\n",
       "      <td>[0.5281608796017102, 0.2630873462235498, 0.20875177417474]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>[6.37, 3.22, 4.94, 1.66]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[-0.891868581752707, -0.2903442505059092, -0.20238672977862548]</td>\n",
       "      <td>[0.20757304550354772, 0.3787997250602226, 0.41362722943622976]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>virginica</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>[4.9, 3.78, 1.37, 0.1]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.5472233429171673, -0.2903442505059092, -0.620961931393775]</td>\n",
       "      <td>[0.5734955869655824, 0.24818703820021012, 0.17831737483420734]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>setosa</td>\n",
       "      <td>setosa</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>[5.32, 3.14, 4.03, 1.17]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.49516006249772526, -0.2903442505059092, -0.3338622738756917]</td>\n",
       "      <td>[0.29391589807666957, 0.3607226849682491, 0.3453614169550813]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>✓</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>[5.82, 2.68, 4.9, 1.43]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.8069822746587445, -0.2903442505059092, -0.26409974027316674]</td>\n",
       "      <td>[0.2274100697453043, 0.3812261949779956, 0.3913637352767001]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>virginica</td>\n",
       "      <td>versicolor</td>\n",
       "      <td>❌</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     features  label  \\\n",
       "0     [6.34, 3.03, 4.29, 1.1]    1.0   \n",
       "1    [6.08, 2.62, 3.93, 1.41]    1.0   \n",
       "2     [5.24, 2.6, 4.74, 1.11]    1.0   \n",
       "3    [4.75, 3.12, 1.32, 0.37]    0.0   \n",
       "4    [6.76, 3.21, 5.29, 1.95]    2.0   \n",
       "..                        ...    ...   \n",
       "595  [4.96, 3.66, 1.45, 0.47]    0.0   \n",
       "596  [6.37, 3.22, 4.94, 1.66]    2.0   \n",
       "597    [4.9, 3.78, 1.37, 0.1]    0.0   \n",
       "598  [5.32, 3.14, 4.03, 1.17]    1.0   \n",
       "599   [5.82, 2.68, 4.9, 1.43]    1.0   \n",
       "\n",
       "                                                        rawPrediction  \\\n",
       "0     [-0.5405590083053458, -0.2903442505059092, -0.3526444944609868]   \n",
       "1     [-0.5466408257513526, -0.2903442505059092, -0.2694660890118225]   \n",
       "2      [-0.661569461734576, -0.2903442505059092, -0.3499613200916589]   \n",
       "3     [0.47294985742743334, -0.2903442505059092, -0.5485162234219222]   \n",
       "4    [-1.0773019594656765, -0.2903442505059092, -0.12457467306811687]   \n",
       "..                                                                ...   \n",
       "595    [0.4065705910469949, -0.2903442505059092, -0.5216844797286433]   \n",
       "596   [-0.891868581752707, -0.2903442505059092, -0.20238672977862548]   \n",
       "597     [0.5472233429171673, -0.2903442505059092, -0.620961931393775]   \n",
       "598  [-0.49516006249772526, -0.2903442505059092, -0.3338622738756917]   \n",
       "599  [-0.8069822746587445, -0.2903442505059092, -0.26409974027316674]   \n",
       "\n",
       "                                                         probability  \\\n",
       "0      [0.2864482846475502, 0.36788587593220956, 0.3456658394202402]   \n",
       "1    [0.27689074407750386, 0.35778046710014444, 0.36532878882235165]   \n",
       "2     [0.2621143388360278, 0.37993721962664834, 0.35794844153732386]   \n",
       "3      [0.5475866235323341, 0.2552456864888573, 0.19716768997880854]   \n",
       "4        [0.1727272485453165, 0.37943050643351, 0.44784224502117365]   \n",
       "..                                                               ...   \n",
       "595       [0.5281608796017102, 0.2630873462235498, 0.20875177417474]   \n",
       "596   [0.20757304550354772, 0.3787997250602226, 0.41362722943622976]   \n",
       "597   [0.5734955869655824, 0.24818703820021012, 0.17831737483420734]   \n",
       "598    [0.29391589807666957, 0.3607226849682491, 0.3453614169550813]   \n",
       "599     [0.2274100697453043, 0.3812261949779956, 0.3913637352767001]   \n",
       "\n",
       "     prediction formatted_prediction predicted_class_name actual_class_name  \\\n",
       "0           1.0                 1.00           versicolor        versicolor   \n",
       "1           2.0                 2.00            virginica        versicolor   \n",
       "2           1.0                 1.00           versicolor        versicolor   \n",
       "3           0.0                 0.00               setosa            setosa   \n",
       "4           2.0                 2.00            virginica         virginica   \n",
       "..          ...                  ...                  ...               ...   \n",
       "595         0.0                 0.00               setosa            setosa   \n",
       "596         2.0                 2.00            virginica         virginica   \n",
       "597         0.0                 0.00               setosa            setosa   \n",
       "598         1.0                 1.00           versicolor        versicolor   \n",
       "599         2.0                 2.00            virginica        versicolor   \n",
       "\n",
       "    correctly_classified  \n",
       "0                      ✓  \n",
       "1                      ❌  \n",
       "2                      ✓  \n",
       "3                      ✓  \n",
       "4                      ✓  \n",
       "..                   ...  \n",
       "595                    ✓  \n",
       "596                    ✓  \n",
       "597                    ✓  \n",
       "598                    ✓  \n",
       "599                    ❌  \n",
       "\n",
       "[600 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique classes: 2\n",
      "Unique classes: ['✓' '❌']\n",
      "Total Records on Dataset: 600\n",
      "Records classified \"✓\": 510/600 = 85.0%\n",
      "Records classified \"❌\": 90/600 = 15.0%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create a Spark ML session\n",
    "spark_ml_session = create_spark_session()\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "data_features, target_classes = load_dataset()\n",
    "\n",
    "# Step 2.1: Load the sample dataset for esternal source\n",
    "dataset_file = \"https://raw.githubusercontent.com/JorgeCardona/recursos/main/datasets/iris_dataset.csv\"\n",
    "data_features, target_classes = load_dataset_from_csv(dataset_file)\n",
    "\n",
    "# Step 3: Split the dataset into training and testing sets\n",
    "(\n",
    "    data_features_train_splitted,\n",
    "    data_features_test_splitted,\n",
    "    target_classes_train_splitted,\n",
    "    target_classes_test_splitted,\n",
    ") = split_dataset_train_testing(data_features, target_classes)\n",
    "\n",
    "# Step 4: Filter the split datasets\n",
    "data_features_train, target_classes_train = get_filtered_dataset(\n",
    "    data_features_train_splitted, target_classes_train_splitted\n",
    ")\n",
    "data_features_test, target_classes_test = get_filtered_dataset(\n",
    "    data_features_test_splitted, target_classes_test_splitted\n",
    ")\n",
    "\n",
    "# Step 5: Create Spark train and avlidation dataframes from the filtered datasets\n",
    "# 5.1 Dataset for Training the Model\n",
    "train_df = create_spark_dataframe(\n",
    "    spark_ml_session, data_features_train, target_classes_train\n",
    ")\n",
    "# 5.2 Dataset for Validating the Model\n",
    "test_df = create_spark_dataframe(\n",
    "    spark_ml_session, data_features_test, target_classes_test\n",
    ")\n",
    "\n",
    "# Step 6: Train a machine learning model\n",
    "model_trained = create_ml_trained_model(train_df)\n",
    "\n",
    "# Step 7: Export the trained model to a specified location\n",
    "model_path = \"/notebooks/spark_ml_model/dataset_iris\"\n",
    "export_spark_model(model_trained, model_path, overwrite=True)\n",
    "\n",
    "# Step 8: Load the trained model from the specified location\n",
    "model = load_spark_model(model_path)\n",
    "\n",
    "# Step 9: Make predictions using the loaded model\n",
    "prediction_result = model_prediction(model, test_df)\n",
    "\n",
    "# Step 10: Evaluate the model's performance on specified evaluation metrics\n",
    "mse_rmse_mae_r2_avaluator(prediction_result)\n",
    "accuracy_f1Score_precision_recall_evaluator(prediction_result)\n",
    "area_under_curve_confusion_matrix_evaluator(prediction_result)\n",
    "\n",
    "# Step 11: Create a Pandas dataframe from the resulting Spark dataframe of predictions\n",
    "df_results = create_pandas_dataframe(spark_dataframe=prediction_result)\n",
    "\n",
    "# Step 12: Close the Spark ML session\n",
    "spark_ml_session.stop()\n",
    "        \n",
    "# Step 13: Check the results\n",
    "display_classification_results(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043a80f-8e0b-4426-99b9-e91b38222c9c",
   "metadata": {},
   "source": [
    "# METRICS ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255dc71-9a92-4af0-a4c7-5f78e74576c1",
   "metadata": {},
   "source": [
    "| Métrica             | Descripción  | Cuando Usar                                                    | Valor   | Explicación del Valor| Fórmula|\n",
    "|---------------------|--------------|----------------------------------------------------------------|---------|-----------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Mean Squared Error (MSE) | La media del error cuadrático entre las predicciones y los valores reales. Un valor bajo indica una mejor predicción. | En problemas de regresión donde se desea penalizar más los errores grandes. Por ejemplo, en la predicción de precios de viviendas. | 15.0%   | El MSE calcula el promedio de los errores al cuadrado entre las predicciones del modelo y los valores reales. Cuanto más bajo sea el valor, más cerca estarán las predicciones del modelo de los valores reales. En este caso, un valor de 15.0% indica que, en promedio, las predicciones del modelo tienen un error cuadrático del 15.0% en relación con los valores reales. | \\( MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 \\)|\n",
    "| Root Mean Squared Error (RMSE) | La raíz cuadrada de la media del error cuadrático entre las predicciones y los valores reales. Un valor bajo indica una mejor predicción. | Similar al MSE, pero proporciona una interpretación más intuitiva, ya que está en la misma escala que la variable objetivo. | 38.73%  | El RMSE es la raíz cuadrada del MSE. Proporciona una medida del error promedio en la misma unidad que la variable de destino. Un RMSE de 38.73% significa que las predicciones del modelo tienden a desviarse en promedio en un 38.73% de los valores reales. | \\( RMSE = \\sqrt{MSE} \\)|\n",
    "| Mean Absolute Error (MAE) | La media del error absoluto entre las predicciones y los valores reales. Un valor bajo indica una mejor predicción. | Cuando se quieren evitar valores atípicos que pueden influir en el MSE. Por ejemplo, en la predicción de la demanda de un producto. | 15.0%   | El MAE calcula la media de las diferencias absolutas entre las predicciones del modelo y los valores reales. Un MAE de 15.0% indica que las predicciones del modelo tienden a desviarse en promedio en un 15.0% de los valores reales. | \\( MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| \\)|\n",
    "| R2 Score            | El porcentaje de variación en la variable objetivo que se explica por la regresión. Un valor alto indica una buena explicación. | Útil cuando se quiere entender cuánta variabilidad del objetivo es explicada por el modelo. Por ejemplo, en la predicción del rendimiento de un motor. | 77.65%  | El R2 Score representa la proporción de la variabilidad en la variable objetivo que es explicada por el modelo. Un valor de 77.65% indica que el modelo es capaz de explicar el 77.65% de la variabilidad en los datos. | \\( R^2 = 1 - \\frac{SSE}{SST} \\)|\n",
    "| Accuracy            | La proporción de instancias correctamente clasificadas. Un valor alto indica una buena precisión.                        | En problemas de clasificación binaria o multiclase donde todas las clases son igualmente importantes. Por ejemplo, en la detección de spam en correos electrónicos. | 85.0%   | La Exactitud es la proporción de instancias correctamente clasificadas por el modelo. Un valor de 85.0% significa que el modelo clasifica correctamente el 85.0% de las instancias. | \\( \\text{Accuracy} = \\frac{\\text{Número de predicciones correctas}}{\\text{Número total de predicciones}} \\)|\n",
    "| F1 Score            | La media aritmética del recall y la precisión. Un valor alto indica una buena precisión y un buen recuerdo.            | Cuando se necesita encontrar un equilibrio entre precisión y recuerdo en problemas de clasificación desequilibrados. Por ejemplo, en la detección de enfermedades en pruebas médicas. | 84.17%  | El F1 Score es una medida del equilibrio entre precisión y recall. Un valor de 84.17% indica un buen equilibrio entre precisión y recall del modelo. | \\( F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\)|\n",
    "| Precision           | La proporción de instancias verdaderamente positivas entre todas las instancias clasificadas como positivas. Un valor alto indica una buena precisión. | Importante cuando el costo de los falsos positivos es alto. Por ejemplo, en la detección de fraudes en transacciones financieras. | 89.8%   | La precisión es la proporción de instancias positivas correctamente identificadas por el modelo entre todas las instancias identificadas como positivas. Un valor de 89.8% indica que el 89.8% de las instancias identificadas como positivas son realmente positivas. | \\( \\text{Precision} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Positivos}} \\)|\n",
    "| Recall              | La proporción de instancias verdaderamente positivas entre todas las instancias reales positivas. Un valor alto indica un buen recuerdo. | Crucial cuando el costo de los falsos negativos es alto. Por ejemplo, en la detección de enfermedades graves. | 85.0%   | El recall es la proporción de instancias positivas correctamente identificadas por el modelo entre todas las instancias positivas reales. Un valor de 85.0% indica que el modelo identifica correctamente el 85.0% de todas las instancias positivas. | \\( \\text{Recall} = \\frac{\\text{Verdaderos Positivos}}{\\text{Verdaderos Positivos} + \\text{Falsos Negativos}} \\)|\n",
    "| Area Under ROC (AUC-ROC)   | El área bajo la curva de recepción-operación, que mide la capacidad del modelo para discriminar entre clases. Un valor alto indica una buena capacidad de discriminación. | Útil cuando se necesita evaluar el desempeño del modelo en todas las configuraciones de umbral de clasificación. Por ejemplo, en la detección de enfermedades en pruebas de laboratorio. | 99.73%  | El área bajo la curva ROC (AUC-ROC) es una medida de la capacidad del modelo para discriminar entre clases. Un valor de 99.73% indica que el modelo tiene una capacidad muy alta para distinguir entre las clases. | Calculado mediante la integración de la curva ROC, que representa la tasa de verdaderos positivos frente a la tasa de falsos positivos en diferentes umbrales de clasificación. | -\n",
    "| Confusion Matrix    | Matriz de confusión que muestra los resultados de la clasificación. | Para evaluar el rendimiento del modelo de clasificación. | [[225.   0.   0.]  [  2. 104.  88.]  [  0.   0. 181.]] | La matriz de confusión muestra el conteo de las instancias clasificadas correctamente e incorrectamente por el modelo en cada clase. En este caso, hay 225 instancias de la clase 1 correctamente clasificadas, 104 instancias de la clase 2 correctamente clasificadas, y 181 instancias de la clase 3 correctamente clasificadas. Además, hay 2 instancias de la clase 1 que fueron clasificadas como clase 2, 88 instancias de la clase 2 que fueron clasificadas como clase 3, y ningún error en la clasificación de la clase 3. | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3606bce-4616-41a7-a4b4-d953ff968b0d",
   "metadata": {},
   "source": [
    "# STOP ZOOKEEPER AND BROKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db5c47e9-ff80-4e5c-bce6-5f59bdc9cfa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: /usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic animals-topic-batch,animals-topic-streaming\n",
      "\n",
      "Executing: /usr/local/kafka/bin/zookeeper-server-stop.sh\n",
      "\n",
      "Executing: /usr/local/kafka/bin/kafka-server-stop.sh\n",
      "\n",
      "[2024-11-17 05:47:34,229] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)\n",
      "[2024-11-17 05:47:34,231] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)\n",
      "[2024-11-17 05:47:34,232] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)\n",
      "[2024-11-17 05:47:34,255] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 17ms (kafka.server.KafkaServer)\n",
      "[2024-11-17 05:47:34,260] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)\n",
      "[2024-11-17 05:47:34,261] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)\n",
      "[2024-11-17 05:47:34,261] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)\n",
      "[2024-11-17 05:47:34,261] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)\n",
      "[2024-11-17 05:47:34,264] INFO [NodeToControllerChannelManager id=2 name=forwarding] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)\n",
      "[2024-11-17 05:47:34,272] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)\n",
      "[2024-11-17 05:47:34,273] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)\n",
      "[2024-11-17 05:47:34,274] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)\n",
      "[2024-11-17 05:47:34,277] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,278] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,278] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,279] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)\n",
      "[2024-11-17 05:47:34,280] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,281] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,281] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,284] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)\n",
      "[2024-11-17 05:47:34,285] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)\n",
      "[2024-11-17 05:47:34,285] INFO [TxnMarkerSenderThread-2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)\n",
      "[2024-11-17 05:47:34,286] INFO [TxnMarkerSenderThread-2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)\n",
      "[2024-11-17 05:47:34,286] INFO [TxnMarkerSenderThread-2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)\n",
      "[2024-11-17 05:47:34,288] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)\n",
      "[2024-11-17 05:47:34,288] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:47:34,289] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,290] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,290] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,290] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,290] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,290] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,291] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)\n",
      "[2024-11-17 05:47:34,292] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)\n",
      "[2024-11-17 05:47:34,292] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)\n",
      "[2024-11-17 05:47:34,293] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)\n",
      "[2024-11-17 05:47:34,293] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)\n",
      "[2024-11-17 05:47:34,293] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)\n",
      "[2024-11-17 05:47:34,294] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)\n",
      "[2024-11-17 05:47:34,295] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)\n",
      "[2024-11-17 05:47:34,295] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)\n",
      "[2024-11-17 05:47:34,295] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,295] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,295] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,296] INFO [ExpirationReaper-2-RemoteFetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,296] INFO [ExpirationReaper-2-RemoteFetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,296] INFO [ExpirationReaper-2-RemoteFetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,297] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,297] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,297] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,298] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,298] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,298] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,299] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,299] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,299] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)\n",
      "[2024-11-17 05:47:34,309] INFO [AddPartitionsToTxnSenderThread-2]: Shutting down (kafka.server.AddPartitionsToTxnManager)\n",
      "[2024-11-17 05:47:34,309] INFO [AddPartitionsToTxnSenderThread-2]: Stopped (kafka.server.AddPartitionsToTxnManager)\n",
      "[2024-11-17 05:47:34,309] INFO [AddPartitionsToTxnSenderThread-2]: Shutdown completed (kafka.server.AddPartitionsToTxnManager)\n",
      "[2024-11-17 05:47:34,310] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)\n",
      "[2024-11-17 05:47:34,311] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)\n",
      "[2024-11-17 05:47:34,311] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)\n",
      "[2024-11-17 05:47:34,311] INFO [zk-broker-2-to-controller-alter-partition-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)\n",
      "[2024-11-17 05:47:34,314] INFO Node to controller channel manager for alter-partition shutdown (kafka.server.NodeToControllerChannelManagerImpl)\n",
      "[2024-11-17 05:47:34,314] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutting down (kafka.server.NodeToControllerRequestThread)\n",
      "[2024-11-17 05:47:34,314] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Stopped (kafka.server.NodeToControllerRequestThread)\n",
      "[2024-11-17 05:47:34,314] INFO [zk-broker-2-to-controller-forwarding-channel-manager]: Shutdown completed (kafka.server.NodeToControllerRequestThread)\n",
      "[2024-11-17 05:47:34,315] INFO Node to controller channel manager for forwarding shutdown (kafka.server.NodeToControllerChannelManagerImpl)\n",
      "[2024-11-17 05:47:34,315] INFO Shutting down. (kafka.log.LogManager)\n",
      "[2024-11-17 05:47:34,317] INFO [kafka-log-cleaner-thread-0]: Shutting down (kafka.log.LogCleaner$CleanerThread)\n",
      "[2024-11-17 05:47:34,317] INFO [kafka-log-cleaner-thread-0]: Shutdown completed (kafka.log.LogCleaner$CleanerThread)\n",
      "[2024-11-17 05:47:34,317] INFO [kafka-log-cleaner-thread-0]: Stopped (kafka.log.LogCleaner$CleanerThread)\n",
      "[2024-11-17 05:47:34,354] INFO [ProducerStateManager partition=__consumer_offsets-35] Wrote producer snapshot at offset 6 with 0 producer ids in 7 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 05:47:34 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:34 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-17 05:47:34,507] INFO [ProducerStateManager partition=animals-topic-batch-0] Wrote producer snapshot at offset 412 with 2 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)\n",
      "[2024-11-17 05:47:34,550] INFO [ProducerStateManager partition=animals-topic-batch-classic-way-0] Wrote producer snapshot at offset 324 with 0 producer ids in 3 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)\n",
      "[2024-11-17 05:47:34,551] WARN Session 0x100017ea8f10000 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)\n",
      "EndOfStreamException: Unable to read additional data from server sessionid 0x100017ea8f10000, likely server has closed socket\n",
      "\tat org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)\n",
      "\tat org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)\n",
      "\tat org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1289)\n",
      "[2024-11-17 05:47:34,621] INFO Shutdown complete. (kafka.log.LogManager)\n",
      "[2024-11-17 05:47:34,626] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)\n",
      "[2024-11-17 05:47:34,627] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)\n",
      "[2024-11-17 05:47:34,627] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)\n",
      "[2024-11-17 05:47:34,627] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 05:47:34 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:34 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-17 05:47:34,754] INFO Session: 0x100017ea8f10000 closed (org.apache.zookeeper.ZooKeeper)\n",
      "[2024-11-17 05:47:34,754] INFO EventThread shut down for session: 0x100017ea8f10000 (org.apache.zookeeper.ClientCnxn)\n",
      "[2024-11-17 05:47:34,754] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)\n",
      "[2024-11-17 05:47:34,755] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:47:34,756] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:47:34,756] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:47:34,756] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:47:34,757] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:47:34,757] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:47:34,757] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:47:34,757] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:47:34,757] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:47:34,757] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:47:34,757] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:47:34,757] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)\n",
      "[2024-11-17 05:47:34,758] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)\n",
      "[2024-11-17 05:47:34,772] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)\n",
      "[2024-11-17 05:47:34,773] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)\n",
      "[2024-11-17 05:47:34,773] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)\n",
      "[2024-11-17 05:47:34,773] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)\n",
      "[2024-11-17 05:47:34,775] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)\n",
      "[2024-11-17 05:47:34,776] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)\n",
      "[2024-11-17 05:47:34,776] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 05:47:34 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:35 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:35,074] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "[2024-11-17 05:47:35,179] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:35 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:35,280] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "[2024-11-17 05:47:35,582] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:35 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:35,985] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:35 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:36 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:36,891] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:36 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:37 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:37,797] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:37 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n"
     ]
    }
   ],
   "source": [
    "commands = [\n",
    "    # Delete Topics\n",
    "    \"/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic animals-topic-batch,animals-topic-streaming\",\n",
    "    # Stop Zookeeper\n",
    "    \"/usr/local/kafka/bin/zookeeper-server-stop.sh\",\n",
    "    # Stop Broker\n",
    "    \"/usr/local/kafka/bin/kafka-server-stop.sh\",\n",
    "]\n",
    "execute_commands(commands=commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c55a4a-ce6c-43aa-bc46-219f8c21af2b",
   "metadata": {},
   "source": [
    "# CLOSE SPARK SESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91c34848-c0ee-42ff-acce-5da36868368b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/17 05:47:38 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:38,702] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:38 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n"
     ]
    }
   ],
   "source": [
    "spark_session.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0f0c7-7b28-455b-8772-f03dbc4ac47d",
   "metadata": {},
   "source": [
    "# IRIS DATASET GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89075290-83f2-4723-9df5-89bcc9c7e9f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datset Shape: (150, 4)\n",
      "Total number of samples: 150\n",
      "Total number of classes: 3\n",
      "Total number of rows or Features: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.67</td>\n",
       "      <td>3.41</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.92</td>\n",
       "      <td>3.33</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.14</td>\n",
       "      <td>3.25</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.99</td>\n",
       "      <td>3.74</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.14</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>6.70</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>6.30</td>\n",
       "      <td>2.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>6.50</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.20</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>6.20</td>\n",
       "      <td>3.40</td>\n",
       "      <td>5.40</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>5.90</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>1.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "0                  4.67              3.41               1.73   \n",
       "1                  4.92              3.33               1.65   \n",
       "2                  5.14              3.25               1.59   \n",
       "3                  4.99              3.74               1.54   \n",
       "4                  5.14              3.37               1.53   \n",
       "...                 ...               ...                ...   \n",
       "2995               6.70              3.00               5.20   \n",
       "2996               6.30              2.50               5.00   \n",
       "2997               6.50              3.00               5.20   \n",
       "2998               6.20              3.40               5.40   \n",
       "2999               5.90              3.00               5.10   \n",
       "\n",
       "      petal width (cm)  class  \n",
       "0                 0.01      0  \n",
       "1                 0.28      0  \n",
       "2                 0.38      0  \n",
       "3                 0.14      0  \n",
       "4                 0.17      0  \n",
       "...                ...    ...  \n",
       "2995              2.30      2  \n",
       "2996              1.90      2  \n",
       "2997              2.00      2  \n",
       "2998              2.30      2  \n",
       "2999              1.80      2  \n",
       "\n",
       "[3000 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-17 05:47:39,607] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:39 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:39 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:40 ERROR MicroBatchExecution: Query [id = 1b46e326-34a0-4c31-99ce-12d253b515f1, runId = eb146b71-afac-4278-94c5-9a4f6cbd7622] terminated with error\n",
      "java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\n",
      "This stopped SparkContext was created at:\n",
      "\n",
      "org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:75)\n",
      "java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:53)\n",
      "java.base/java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:502)\n",
      "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:486)\n",
      "py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "py4j.Gateway.invoke(Gateway.java:238)\n",
      "py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "\n",
      "The currently active SparkContext was created at:\n",
      "\n",
      "(No active SparkContext.)\n",
      "         \n",
      "\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:122)\n",
      "\tat org.apache.spark.SparkContext.broadcastInternal(SparkContext.scala:1654)\n",
      "\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1639)\n",
      "\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:102)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:138)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:129)\n",
      "\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:346)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:548)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:537)\n",
      "\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:575)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)\n",
      "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:207)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:206)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:30)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:732)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:729)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:286)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:427)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:425)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:249)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:67)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:239)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:311)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:289)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "24/11/17 05:47:40 WARN NettyRpcEnv: Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@66b06df3[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@67bee667[Wrapped task = org.apache.spark.rpc.netty.NettyRpcEnv$$anon$1@5e3bc41d]] rejected from java.util.concurrent.ScheduledThreadPoolExecutor@27564190[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]\n",
      "Exception in thread \"stream execution thread for [id = 1b46e326-34a0-4c31-99ce-12d253b515f1, runId = eb146b71-afac-4278-94c5-9a4f6cbd7622]\" org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.sql.execution.streaming.state.StateStoreCoordinatorRef.deactivateInstances(StateStoreCoordinator.scala:119)\n",
      "\tat org.apache.spark.sql.streaming.StreamingQueryManager.notifyQueryTermination(StreamingQueryManager.scala:426)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$3(StreamExecution.scala:360)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.UninterruptibleThread.runUninterruptibly(UninterruptibleThread.scala:77)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:340)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.$anonfun$run$1(StreamExecution.scala:211)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:211)\n",
      "Caused by: org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:176)\n",
      "\tat org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:144)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.askAbortable(NettyRpcEnv.scala:242)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEndpointRef.askAbortable(NettyRpcEnv.scala:554)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:558)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:100)\n",
      "\t... 11 more\n",
      "[2024-11-17 05:47:40,613] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:40 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:40 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:41,618] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:41 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:41 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:42,623] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:42 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:42 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:43,628] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:43 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:43 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:44,634] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:44 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:44 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:45,639] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:45 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:45 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:46,645] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:46 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:46 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:47,551] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:47 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:47 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:48,555] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:48 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:48 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:49,561] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:49 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:49 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:50 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:50,566] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:50 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:51 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:51,571] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:51 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:52 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:52,576] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:52 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "[2024-11-17 05:47:53,481] WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Node may not be available. (org.apache.kafka.clients.NetworkClient)\n",
      "24/11/17 05:47:53 WARN NetworkClient: [AdminClient clientId=adminclient-2] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n",
      "24/11/17 05:47:53 WARN NetworkClient: [Producer clientId=producer-1] Connection to node 2 (63399d325201/172.17.0.2:9092) could not be established. Node may not be available.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# data values\n",
    "dataset_shape = X.shape\n",
    "num_samples = len(X)  # Total number of samples (rows)\n",
    "num_classes = len(np.unique(y))  # Total number of classes (categories)\n",
    "num_features = X.shape[1]\n",
    "\n",
    "print(f\"Datset Shape: {dataset_shape}\")\n",
    "print(f\"Total number of samples: {num_samples}\")\n",
    "print(f\"Total number of classes: {num_classes}\")\n",
    "print(f\"Total number of rows or Features: {num_features}\")\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Generate synthetic samples for each class\n",
    "for index in range(num_classes):\n",
    "    class_data = X[y == index]\n",
    "\n",
    "    # Generate 400 new, synthetic samples based on the class\n",
    "    new_data = []\n",
    "    for index_column in range(num_features):\n",
    "        mean, std = (\n",
    "            class_data[:, index_column].mean(),\n",
    "            class_data[:, index_column].std(),\n",
    "        )\n",
    "        new_values = np.round(np.random.normal(mean, std, (950,)), 2)\n",
    "        new_data.append(new_values)\n",
    "\n",
    "    # Convert the new data to a DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        np.array(new_data).T,\n",
    "        columns=[\n",
    "            \"sepal length (cm)\",\n",
    "            \"sepal width (cm)\",\n",
    "            \"petal length (cm)\",\n",
    "            \"petal width (cm)\",\n",
    "        ],\n",
    "    )\n",
    "    df[\"class\"] = index\n",
    "\n",
    "    # Add the new DataFrame to the list\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "df_complete = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Remove duplicates based on the columns you want to consider unique (e.g., 'sepal_length', 'petal_length', 'sepal_width', 'petal_width')\n",
    "df_unique = df_complete.drop_duplicates(\n",
    "    subset=[\n",
    "        \"sepal length (cm)\",\n",
    "        \"sepal width (cm)\",\n",
    "        \"petal length (cm)\",\n",
    "        \"petal width (cm)\",\n",
    "        \"class\",\n",
    "    ],\n",
    "    keep=\"first\",\n",
    ")\n",
    "\n",
    "# Add the original dataset to df_unique\n",
    "df_original = pd.DataFrame(data=X, columns=iris.feature_names)\n",
    "df_original[\"class\"] = iris.target\n",
    "df_unique = pd.concat([df_unique, df_original], ignore_index=True)\n",
    "\n",
    "df_unique.to_csv(\"iris_dataset.csv\", index=False)\n",
    "df_unique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python - ML - Data Science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
